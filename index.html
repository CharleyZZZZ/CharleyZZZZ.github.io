<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
     Hello World !
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/CharleyZZZZ/CharleyZZZZ.github.io"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">Hello World !</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>

<div id="main">
  <section class="outer">
  <article class="articles">
    
    
    
    
    <article id="post-限流方案" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/05/25/%E9%99%90%E6%B5%81%E6%96%B9%E6%A1%88/"
    >限流方案</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/05/25/%E9%99%90%E6%B5%81%E6%96%B9%E6%A1%88/" class="article-date">
  <time datetime="2021-05-25T09:42:36.000Z" itemprop="datePublished">2021-05-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>在大数据量高并发访问时，经常会出现服务或接口面对暴涨的请求而<strong>不可用</strong>的情况，甚至引发连锁反映导致整个系统崩溃。此时你需要使用的技术手段之一就是限流，当请求达到一定的并发数或速率，就进行等待、排队、降级、拒绝服务等。</p>
<p>限流一般分为俩个维度：</p>
<ul>
<li><strong>时间：</strong> 限流基于某段时间范围或者某个时间点，也就是我们常说的“时间窗口”，比如对每分钟、每秒钟的时间窗口做限定。</li>
<li><strong>资源：</strong> 基于可用资源的限制，比如设定最大访问次数，或最高可用连接数。</li>
</ul>
<p><strong>分类：</strong></p>
<ul>
<li><strong>合法性验证限流</strong>：比如验证码、IP 黑名单等，这些手段可以有效的防止恶意攻击和爬虫采集；</li>
<li><strong>容器限流</strong>：比如 Tomcat、Nginx 等限流手段，其中 Tomcat 可以设置最大线程数（maxThreads），当并发超过最大线程数会排队等待执行；而Nginx提供了两种限流手段：一是控制速率，二是控制并发连接数；</li>
<li><strong>服务端限流</strong>：比如我们在服务器端通过限流算法实现限流，常用的有漏桶算法、令牌桶算法、滑动时间窗口算法等。</li>
</ul>
<h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><h2 id="Tomcat限流"><a href="#Tomcat限流" class="headerlink" title="Tomcat限流"></a>Tomcat限流</h2><p>Tomcat 8.5 版本的最大线程数在 conf/server.xml 配置中，如下所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;connector</span> <span class="string">port="8080" protocol="HTTP/1.1"</span></span><br><span class="line">	<span class="attr">connectionTimeout</span>=<span class="string">"20000"</span></span><br><span class="line">	<span class="attr">maxThreads</span>=<span class="string">"150"/&gt;</span></span><br></pre></td></tr></table></figure>

<p>其中 maxThreads 就是 Tomcat 的最大线程数，当请求的并发大于此值（maxThreads）时，请求就会排队执行，这样就完成了限流的目的。</p>
<p>注意：</p>
<p>maxThreads 的值可以适当的调大一些，Tomcat默认为 150（Tomcat 版本 8.5），但这个值也不是越大越好，要看具体的服务器配置，需要注意的是每开启一个线程需要耗用 1MB 的 JVM 内存空间用于作为线程栈之用，并且线程越多 GC 的负担也越重。</p>
<p>最后需要注意一下，操作系统对于进程中的线程数有一定的限制，Windows 每个进程中的线程数不允许超过 2000，Linux 每个进程中的线程数不允许超过 1000。</p>
<h2 id="Nginx-限流"><a href="#Nginx-限流" class="headerlink" title="Nginx 限流"></a>Nginx 限流</h2><p>Nginx官方版本<strong>限制IP的连接</strong>和<strong>并发</strong>分别有两个模块：</p>
<ul>
<li><code>limit_req_zone</code> 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 “leaky bucket”。</li>
<li><code>limit_req_conn</code> 用来限制同一时间连接数，即并发限制。</li>
</ul>
<h5 id="限制速率"><a href="#限制速率" class="headerlink" title="限制速率"></a>限制速率</h5><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">http</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">limit_req_zone</span> <span class="string">$binary_remote_addr zone=one:10m rate=1r/s;</span></span><br><span class="line">    <span class="attr">server</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="attr">location</span> <span class="string">/search/ &#123;</span></span><br><span class="line">            <span class="attr">limit_req</span> <span class="string">zone=one burst=5 nodelay;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line"><span class="attr">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">limit_req_zone</span> <span class="string">$binary_remote_addr zone=one:10m rate=1r/s;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>第一个参数：<code>$binary_remote_addr</code> 表示通过<code>remote_addr</code>这个标识来做限制，“binary_”的目的是缩写内存占用量，是限制同一客户端ip地址。</li>
<li>第二个参数：<code>zone=one:10m</code>表示生成一个大小为10M，名字为one的内存区域，用来存储访问的频次信息。</li>
<li>第三个参数：<code>rate=1r/s</code>表示允许相同标识的客户端的访问频次，这里限制的是每秒1次，还可以有比如30r/m的。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limit_req zone&#x3D;one burst&#x3D;5 nodelay;</span><br></pre></td></tr></table></figure>

<ul>
<li>第一个参数：<code>zone=one</code> 设置使用哪个配置区域来做限制，与上面<code>limit_req_zone</code> 里的name对应。</li>
<li>第二个参数：<code>burst=5</code>，重点说明一下这个配置，burst爆发的意思，这个配置的意思是设置一个大小为5的缓冲区当有大量请求（爆发）过来时，超过了访问频次限制的请求可以先放到这个缓冲区内。</li>
<li>第三个参数：<code>nodelay</code>，如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回503，如果没有设置，则所有请求会等待排队。</li>
</ul>
<h5 id="限制并发数"><a href="#限制并发数" class="headerlink" title="限制并发数"></a>限制并发数</h5><p>nginx 利用 <code>limit_conn_zone</code> 和<code>limit_conn</code> 两个指令即可控制并发数.</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">limit_conn_zone</span> <span class="string">$binary_remote_addr zone=perip:10m;</span></span><br><span class="line"><span class="attr">limit_conn_zone</span> <span class="string">$server_name zone=perserver:10m;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">server</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">...</span></span><br><span class="line">    <span class="attr">limit_conn</span> <span class="string">perip 10;</span></span><br><span class="line">    <span class="attr">limit_conn</span> <span class="string">perserver 100;</span></span><br><span class="line"><span class="attr">&#125;</span></span><br></pre></td></tr></table></figure>

<p>可以配置多个<code>limit_conn</code>指令。例如，以上配置将限制每个客户端IP连接到服务器的数量，同时限制连接到虚拟服务器的总数。</p>
<h2 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h2><ul>
<li>固定时间窗口限流</li>
<li>滑动时间窗口限流</li>
<li>漏桶算法</li>
<li>令牌桶算法</li>
<li>滑动日志</li>
</ul>
<h4 id="固定时间窗口算法"><a href="#固定时间窗口算法" class="headerlink" title="固定时间窗口算法"></a>固定时间窗口算法</h4><p>维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接受请求的次数。</p>
<ul>
<li>当次数小于限流阀值，就允许访问，并且计数器+1</li>
<li>当次数大于限流阀值，就拒绝访问。</li>
<li>当前时间窗口过去后，计数器清零。</li>
</ul>
<p><strong>临界问题</strong>：假设限流阀值为5，单位时间窗口是1s，如果在单位时间内的前 <strong>0.8-1s</strong> 和 <strong>1-1.2s ** 分别并发 5个请求。虽然 前一秒和后一秒的时间窗口内都没有超过阀值。但是如果算 **0.8-1.2s</strong> ，则并发达到10，已经超过单位时间1s内不超过5个请求的阀值定义了。</p>
<h4 id="滑动时间窗口算法"><a href="#滑动时间窗口算法" class="headerlink" title="滑动时间窗口算法"></a>滑动时间窗口算法</h4><p>滑动时间窗口算法可以解决固定时间窗口限流算法的临界值问题。</p>
<p>它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。</p>
<p>例如单位时间还是1s，滑动窗口算法把其划分成5个小周期，也就是滑动窗口（单位时间）被分成5个小格子。每格表示0.2s。每过0.2s，时间窗口就会往右滑动一格。每个小周期都有一个计数器。</p>
<p>滑动时间窗口算法虽然解决了临界值问题，但是一旦请求达到规则限流值，请求会被直接暴力拒绝。这样我们会损失一部分请求，对于部分场景来说并不合理。</p>
<h4 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h4><p>漏铜算法面对限流更加柔和，并不会直接粗暴的拒绝。</p>
<p>漏桶(Leaky Bucket)算法：请求先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大或者漏桶已满会直接溢，然后就拒绝请求，可以看出漏桶算法能强行限制数据的传输速率。</p>
<ul>
<li><p>定义一个桶的最大量；</p>
</li>
<li><p>记录上次桶刷新的时间和水量，以便后续计算当前桶里面的水；</p>
</li>
<li><p>定义水的流出速率，速率越小，限制流量越小；</p>
</li>
<li><p>每次请求，先检查桶的水量，如果没有达到最大值，往桶里面加水。如果达到最大值则按照相应的拒绝策略拒绝。</p>
</li>
</ul>
<p>在正常流量时，按照固定的速率处理请求是我们想要的，但是应用系统设置限流值并不是按照系统实际可承载最大吞吐量来设定的，系统允许在突发流量时，处理速度加快，只不过系统不应长时间保持高负载，这样才能尽可能的利用系统资源，保证请求尽快被处理。</p>
<h4 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h4><p>面对突发流量时，我们可以使用令牌桶算法限流。</p>
<ul>
<li>有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。</li>
<li>如果令牌数量满了，超过令牌容量的限制，那就丢弃。</li>
<li>系统在接受到一个用户请求时，都会先去令牌桶请求一个令牌，如果拿到令牌则处理这个请求业务。</li>
<li>如果拿不到则直接拒绝这个请求。</li>
</ul>
<blockquote>
<p>笔记来源：<a href="https://blog.csdn.net/wangxy_job/article/details/106313398" target="_blank" rel="noopener">https://blog.csdn.net/wangxy_job/article/details/106313398</a></p>
<p><a href="https://www.cnblogs.com/biglittleant/p/8979915.html" target="_blank" rel="noopener">https://www.cnblogs.com/biglittleant/p/8979915.html</a></p>
<p><a href="https://blog.csdn.net/wangxy_job/article/details/106313383" target="_blank" rel="noopener">https://blog.csdn.net/wangxy_job/article/details/106313383</a></p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%99%90%E6%B5%81/" rel="tag">限流</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-分布式ID生成方案" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/05/25/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88/"
    >分布式ID生成方案</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/05/25/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88/" class="article-date">
  <time datetime="2021-05-25T06:26:53.000Z" itemprop="datePublished">2021-05-25</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>分布式系统中需要全局唯一的ID，就叫 分布式ID。</p>
<ul>
<li>全局唯一</li>
<li>高性能：id生成响应要快，否则会影响系统性能</li>
<li>高可用</li>
<li>好接入：系统设计简单，好接入</li>
<li>趋势递增</li>
</ul>
<h3 id="常用方案"><a href="#常用方案" class="headerlink" title="常用方案"></a>常用方案</h3><ul>
<li><p>UUID</p>
</li>
<li><p>数据库自增ID</p>
</li>
<li><p>分布式数据库自增ID</p>
</li>
<li><p>号段模式</p>
</li>
<li><p>Redis 自增特性</p>
</li>
<li><p>雪花算法（SnowFlake）</p>
</li>
</ul>
<h4 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123; </span><br><span class="line">       String uuid = UUID.randomUUID().toString().replaceAll(<span class="string">"-"</span>,<span class="string">""</span>);</span><br><span class="line">       System.out.println(uuid);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>优点：</p>
<ul>
<li>生成简单，本地生成无网络消耗，具有唯一性</li>
</ul>
<p>缺点：</p>
<ul>
<li>无序字符串，不能递增</li>
<li>无具体业务含义</li>
<li>长度过长</li>
</ul>
<h4 id="数据库自增ID"><a href="#数据库自增ID" class="headerlink" title="数据库自增ID"></a>数据库自增ID</h4><p>基于数据库的<code>auto_increment</code>自增ID完全可以充当<code>分布式ID</code>，具体实现：需要一个单独的MySQL实例用来生成ID，建表结构如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> <span class="string">`SEQ_ID`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> SEQID.SEQUENCE_ID (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">bigint</span>(<span class="number">20</span>) <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> auto_increment, </span><br><span class="line">    <span class="keyword">value</span> <span class="built_in">char</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">default</span> <span class="string">''</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="keyword">id</span>),</span><br><span class="line">) <span class="keyword">ENGINE</span>=MyISAM;</span><br></pre></td></tr></table></figure>

<p><strong>优点：</strong></p>
<ul>
<li>实现简单，ID单调自增，数值类型查询速度快</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>DB单点存在宕机风险，无法扛住高并发场景</li>
</ul>
<h4 id="基于数据库集群自增ID"><a href="#基于数据库集群自增ID" class="headerlink" title="基于数据库集群自增ID"></a>基于数据库集群自增ID</h4><p>前边说了单点数据库方式不可取，那对上边的方式做一些高可用优化，换成主从模式集群。害怕一个主节点挂掉没法用，那就做双主模式集群，也就是两个Mysql实例都能单独的生产自增ID。</p>
<p><strong>问题：多个实例都生成ID，会产生重复ID 的问题，不满足唯一性。</strong></p>
<p><strong>解决方法：设置起始值和自增步长。</strong></p>
<p>MySQL_1 配置：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> @@auto_increment_offset = <span class="number">1</span>;     <span class="comment">-- 起始值</span></span><br><span class="line"><span class="keyword">set</span> @@auto_increment_increment = <span class="number">2</span>;  <span class="comment">-- 步长</span></span><br></pre></td></tr></table></figure>

<p>MySQL_2 配置：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> @@auto_increment_offset = <span class="number">2</span>;     <span class="comment">-- 起始值</span></span><br><span class="line"><span class="keyword">set</span> @@auto_increment_increment = <span class="number">2</span>;  <span class="comment">--</span></span><br></pre></td></tr></table></figure>

<p><strong>优点：</strong></p>
<ul>
<li>解决DB单点问题。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不利于后续扩容（扩容需要修改已有实例的起始值和步长），而且实际上单个数据库自身压力还是大，依旧无法满足高并发场景。</li>
</ul>
<h4 id="号段模式"><a href="#号段模式" class="headerlink" title="号段模式"></a>号段模式</h4><p>号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_generator (</span><br><span class="line">  <span class="keyword">id</span> <span class="built_in">int</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  max_id <span class="built_in">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'当前最大id'</span>,</span><br><span class="line">  step <span class="built_in">int</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'号段的布长'</span>,</span><br><span class="line">  biz_type	<span class="built_in">int</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'业务类型'</span>,</span><br><span class="line">  <span class="keyword">version</span> <span class="built_in">int</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'版本号'</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>biz_type</strong> ：代表不同业务类型</p>
<p><strong>max_id</strong> ：当前最大的可用id</p>
<p><strong>step</strong> ：代表号段的长度</p>
<p><strong>version</strong> ：是一个乐观锁，每次都更新version，保证并发时数据的正确性</p>
<p>等这批号段ID用完，再次向数据库申请新号段，对<code>max_id</code>字段做一次<code>update</code>操作，<code>update max_id= max_id + step</code>，update成功则说明新号段获取成功，新的号段范围是<code>(max_id ,max_id +step]</code>。</p>
<h4 id="基于Redis自增ID"><a href="#基于Redis自增ID" class="headerlink" title="基于Redis自增ID"></a>基于Redis自增ID</h4><p><code>Redis</code>也同样可以实现，原理就是利用<code>redis</code>的 <code>incr</code>命令实现ID的原子性自增。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; set seq_id <span class="number">1</span>     <span class="comment">// 初始化自增ID为1</span></span><br><span class="line">OK</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; incr seq_id      <span class="comment">// 增加1，并返回递增后的数值</span></span><br><span class="line">(integer) <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>用<code>redis</code>实现需要注意一点，要考虑到redis持久化的问题。<code>redis</code>有两种持久化方式<code>RDB</code>和<code>AOF</code></p>
<ul>
<li><code>RDB</code>会定时打一个快照进行持久化，假如连续自增但<code>redis</code>没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。</li>
<li><code>AOF</code>会对每条写命令进行持久化，即使<code>Redis</code>挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致<code>Redis</code>重启恢复的数据时间过长。</li>
</ul>
<h4 id="雪花算法（Snowflake）"><a href="#雪花算法（Snowflake）" class="headerlink" title="雪花算法（Snowflake）"></a>雪花算法（Snowflake）</h4><p><img src="/2021/05/25/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88/incr_id.jpg" alt="雪花算法组成结构"></p>
<p><code>Snowflake</code>生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。</p>
<p>Snowflake ID组成结构：<code>正数位</code>（占1比特）+ <code>时间戳</code>（占41比特）+ <code>机器ID</code>（占5比特）+ <code>数据中心</code>（占5比特）+ <code>自增值</code>（占12比特），总共64比特组成的一个Long类型。</p>
<ul>
<li>第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。</li>
<li>时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69年</li>
<li>工作机器id（10bit）：也被叫做<code>workId</code>，这个可以灵活配置，机房或者机器号组合都可以。</li>
<li>序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID</li>
</ul>
<p><strong>Java版本的<code>Snowflake</code>算法实现：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Twitter的SnowFlake算法,使用SnowFlake算法生成一个整数，然后转化为62进制变成一个短地址URL</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * https://github.com/beyondfengyu/SnowFlake</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SnowFlakeShortUrl</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 起始的时间戳</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> START_TIMESTAMP = <span class="number">1480166465631L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 每一部分占用的位数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> SEQUENCE_BIT = <span class="number">12</span>;   <span class="comment">//序列号占用的位数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> MACHINE_BIT = <span class="number">5</span>;     <span class="comment">//机器标识占用的位数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> DATA_CENTER_BIT = <span class="number">5</span>; <span class="comment">//数据中心占用的位数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 每一部分的最大值</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> MAX_SEQUENCE = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; SEQUENCE_BIT);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> MAX_MACHINE_NUM = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; MACHINE_BIT);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> MAX_DATA_CENTER_NUM = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; DATA_CENTER_BIT);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 每一部分向左的位移</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> MACHINE_LEFT = SEQUENCE_BIT;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> DATA_CENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> TIMESTAMP_LEFT = DATA_CENTER_LEFT + DATA_CENTER_BIT;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> dataCenterId;  <span class="comment">//数据中心</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> machineId;     <span class="comment">//机器标识</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequence = <span class="number">0L</span>; <span class="comment">//序列号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> lastTimeStamp = -<span class="number">1L</span>;  <span class="comment">//上一次时间戳</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">getNextMill</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> mill = getNewTimeStamp();</span><br><span class="line">        <span class="keyword">while</span> (mill &lt;= lastTimeStamp) &#123;</span><br><span class="line">            mill = getNewTimeStamp();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> mill;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">getNewTimeStamp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据指定的数据中心ID和机器标志ID生成指定的序列号</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> dataCenterId 数据中心ID</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> machineId    机器标志ID</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SnowFlakeShortUrl</span><span class="params">(<span class="keyword">long</span> dataCenterId, <span class="keyword">long</span> machineId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (dataCenterId &gt; MAX_DATA_CENTER_NUM || dataCenterId &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"DtaCenterId can't be greater than MAX_DATA_CENTER_NUM or less than 0！"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (machineId &gt; MAX_MACHINE_NUM || machineId &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"MachineId can't be greater than MAX_MACHINE_NUM or less than 0！"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.dataCenterId = dataCenterId;</span><br><span class="line">        <span class="keyword">this</span>.machineId = machineId;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 产生下一个ID</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">long</span> <span class="title">nextId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> currTimeStamp = getNewTimeStamp();</span><br><span class="line">        <span class="keyword">if</span> (currTimeStamp &lt; lastTimeStamp) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Clock moved backwards.  Refusing to generate id"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (currTimeStamp == lastTimeStamp) &#123;</span><br><span class="line">            <span class="comment">//相同毫秒内，序列号自增</span></span><br><span class="line">            sequence = (sequence + <span class="number">1</span>) &amp; MAX_SEQUENCE;</span><br><span class="line">            <span class="comment">//同一毫秒的序列数已经达到最大</span></span><br><span class="line">            <span class="keyword">if</span> (sequence == <span class="number">0L</span>) &#123;</span><br><span class="line">                currTimeStamp = getNextMill();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//不同毫秒内，序列号置为0</span></span><br><span class="line">            sequence = <span class="number">0L</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        lastTimeStamp = currTimeStamp;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (currTimeStamp - START_TIMESTAMP) &lt;&lt; TIMESTAMP_LEFT <span class="comment">//时间戳部分</span></span><br><span class="line">                | dataCenterId &lt;&lt; DATA_CENTER_LEFT       <span class="comment">//数据中心部分</span></span><br><span class="line">                | machineId &lt;&lt; MACHINE_LEFT             <span class="comment">//机器标识部分</span></span><br><span class="line">                | sequence;                             <span class="comment">//序列号部分</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SnowFlakeShortUrl snowFlake = <span class="keyword">new</span> SnowFlakeShortUrl(<span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; (<span class="number">1</span> &lt;&lt; <span class="number">4</span>); i++) &#123;</span><br><span class="line">            <span class="comment">//10进制</span></span><br><span class="line">            System.out.println(snowFlake.nextId());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p>笔记来源：<a href="https://zhuanlan.zhihu.com/p/107939861" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/107939861</a></p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ID/" rel="tag">ID</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag">分布式</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-布隆过滤器" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/04/13/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"
    >布隆过滤器</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/04/13/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" class="article-date">
  <time datetime="2021-04-13T13:15:15.000Z" itemprop="datePublished">2021-04-13</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p><strong>布隆过滤器</strong>本质上是一种<strong>数据结构</strong>，比较巧妙的<strong>概率型数据结构（probabilistic data structure）</strong></p>
<ul>
<li><p><strong>优点</strong>：高效地插入和查询，可以用来告诉你 <strong>“某样东西一定不存在或者可能存在”</strong>。</p>
<p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少。</p>
</li>
<li><p><strong>缺点</strong>：是其返回的<strong>结果是概率性</strong>的，而不是确切的。</p>
</li>
</ul>
<h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>通常判断某个元素是否存在的方式：</p>
<p>可以将值映射到 <strong>HashMap</strong> 的 Key，然后可以在 O(1) 的时间复杂度内返回结果，效率高。但是 HashMap 的实现也有缺点，例如<strong>存储容量占比高</strong>，考虑到负载因子的存在，通常<strong>空间是不能被用满</strong>的，而一旦你的值很多例如上亿的时候，那 HashMap 占据的内存大小就变得很大了。</p>
<p>即：<strong>内存占用大，利用率低。</strong></p>
<p><strong>布隆过滤器数据结构</strong></p>
<p><strong>布隆过滤器</strong>是一个 bit 向量或者说 bit 数组：</p>
<p><img src="/2021/04/13/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/bulong_filter_01.jpg" alt="布隆过滤器"></p>
<p>如果我们要映射一个值到布隆过滤器中，我们需要使用<strong>多个不同的哈希函数</strong>生成<strong>多个哈希值，</strong>并对每个生成的哈希值指向的 bit 位置置成 1。</p>
<p><strong>例如：</strong></p>
<p>针对值 “baidu” 和三个不同的哈希函数分别生成了哈希值 1、4、7，则在1、4、7 位置置成1。</p>
<p>这时，我们再存一个值 “tencent”，假如哈希函数返回 3、4、8 的话，3、4、8 位置置成1。值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了。</p>
<p>现在我们如果想查询 “ali” 这个值是否存在，哈希函数返回了 1、5、8三个值，结果我们发现 5 这个 bit 位上的值为 0，<strong>说明没有任何一个值映射到这个 bit 位上</strong>，因此我们可以<strong>很确定</strong>地说 “ali” 这个值不存在。</p>
<p>但是，如果现在有一个值经过n次哈希函数后，得到的值的位置都为1，那么该值一定存在吗？不一定。</p>
<p><strong>综上：</strong></p>
<p><strong>布隆过滤器可以判断某一个值一定不存在，不一定能判断某一个值一定存在，只能说可能存在。</strong></p>
<p>这个可能的准确性，取决于<strong>哈希函数的个数</strong> 和 <strong>布隆过滤器的长度</strong>。</p>
<p><strong>扩展</strong>：传统的布隆过滤器并不支持删除操作。但是名为 Counting Bloom filter 的变种可以用来<strong>测试元素计数个数是否绝对小于某个阈值</strong>，它支持元素删除。</p>
<h3 id="如何选择哈希函数个数和布隆过滤器长度"><a href="#如何选择哈希函数个数和布隆过滤器长度" class="headerlink" title="如何选择哈希函数个数和布隆过滤器长度"></a>如何选择哈希函数个数和布隆过滤器长度</h3><p><img src="/2021/04/13/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/bulong_filter_02.jpg" alt="布隆过滤器参数选择"></p>
<p>k 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率。</p>
<p>由图可见，<strong>哈希函数个数越多，布隆过滤器越长，误报率越低。</strong></p>
<p>如何选择适合业务的 k 和 m 值，这里直接贴一个公式：</p>
<p><img src="/2021/04/13/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/bulong_filter_03.jpg" alt="参数计算公式"></p>
<p>具体公式推导过程，可自行上网查询。</p>
<h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><ul>
<li><p>利用布隆过滤器减少磁盘 IO 或者网络请求，<strong>一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。</strong></p>
</li>
<li><p>使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。</p>
</li>
<li><p>Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。</p>
</li>
</ul>
<blockquote>
<p>笔记来源：</p>
<p><a href="https://zhuanlan.zhihu.com/p/43263751" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/43263751</a></p>
<p><a href="https://www.cnblogs.com/liyulong1982/p/6013002.html" target="_blank" rel="noopener">https://www.cnblogs.com/liyulong1982/p/6013002.html</a></p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" rel="tag">布隆过滤器</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-Java中一致性hash的实现" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/04/12/Java%E4%B8%AD%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%9A%84%E5%AE%9E%E7%8E%B0/"
    >Java中一致性hash的实现</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/04/12/Java%E4%B8%AD%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%9A%84%E5%AE%9E%E7%8E%B0/" class="article-date">
  <time datetime="2021-04-12T15:12:28.000Z" itemprop="datePublished">2021-04-12</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>前面在《缓存-基础概念》的学习中，关于<a href="http://blogsea.cn/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%80%EF%BC%89-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E8%AE%BE%E8%AE%A1" target="_blank" rel="noopener"><strong>数据分布设计</strong></a>一节，提到关于数据分布算法，通常采用<strong>取模</strong>或者<strong>一致性hash分布</strong>。随后在  <strong>Memcached</strong> 和 <strong>Redis</strong> 章节，也确切提到 例如<strong>Memcached 分拆缓存池</strong>采用一致性<strong>hash</strong>，<strong>Redis</strong> Client 分区方案数据分布方案 采用一致性hash算法等。</p>
<p>那么 一致性hash 算法是如何实现的呢，一起来学习一下。</p>
<h3 id="常规取模哈希"><a href="#常规取模哈希" class="headerlink" title="常规取模哈希"></a>常规取模哈希</h3><p>通常我们所说的最简单的hash算法即为 取模hash （或者 HashMap 中位运算）。</p>
<ul>
<li>第一步通过jdk内置hash方法对请求参数hash运算，得到一个整数</li>
<li>第二步将该整数 i 对服务器台数 n 取模，将请求分散到不同的服务器上</li>
</ul>
<p><strong>缺点</strong>：</p>
<p>当<strong>增减</strong>服务器时，会造成部分数据丢失。例如作为缓存场景来说，新增一台服务器导致变更后取模与变更前取模命中服务器不一致，降低缓存命中率。</p>
<h3 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h3><p>为了解决以上问题，前辈们设计了一致性哈希算法。</p>
<p>hash算法出来的整数有个范围，我们在这个范围内布置三台服务器（范围具体是多少看前面的hash算法）。假设hash的范围是1~300，每台负责一段范围内的请求，比如一台负责(1-100]，一台负责(100-200]，一台负责(200-1]。<strong>这三台server收尾相接覆盖/闭环了所有请求，称为哈希环</strong>。</p>
<p><img src="/2021/04/12/Java%E4%B8%AD%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%9A%84%E5%AE%9E%E7%8E%B0/hash_01.png" alt="哈希环"></p>
<p>如何实现一台服务器接收一个范围的请求？这个时候不用取模了，而是将server也按照hash算法计算一个id值，比如按照他们的ip+port+name拼成的串计算，假设正好分别是 1，100，200，将他们放进一个treeMap里，</p>
<p>Map&lt;Inetger,Node&gt; ，其中Node代表server节点，是自定义的数据结构，比如是一个类，包含ip，port，name等属性。</p>
<p>一个请求过来hash得到的值必属于这三个server的范围，比如一个请求id=N，那么从map里get(N)去找server，</p>
<ul>
<li><p>找到直接转发，</p>
</li>
<li><p>找不到进行如下运算：treemap里有个关键的api，tailMap()，这个接口能够<strong>返回id比N大的map的子集</strong>，然后取子集的第一个节点，就是id=100的节点，通常称为顺时针查找。</p>
<p>当然如果子集为空，这意味着N&gt;200，就取整个map的第一个节点，完成闭环。</p>
</li>
</ul>
<p><strong>优点：</strong></p>
<p>从实现可以看出，如果一个节点挂了，他的流量会顺时针（逆时针实现也是一样的）“导流”到下一个节点，其他节点不受影响。</p>
<p><strong>缺点：</strong></p>
<p>假设各台服务器性能差不多，此时流量突增，一台server由于流量过载而挂掉，那么它的下一台因为承载了2倍的流量，很有可能也会挂掉，依此类推，最后所有的节点都会挂掉，造成“雪崩”！</p>
<h3 id="虚拟节点改进"><a href="#虚拟节点改进" class="headerlink" title="虚拟节点改进"></a>虚拟节点改进</h3><p>如何解决上述问题，可<strong>在其基础上使用hash算法将每台服务器节点分散分布环中</strong>。即每台机器虚拟出多个节点，分散分布于闭环中。</p>
<p><img src="/2021/04/12/Java%E4%B8%AD%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%9A%84%E5%AE%9E%E7%8E%B0/hash_02.png" alt="虚节点改进"></p>
<p>如图，那么当一台服务器挂掉时，其流量将分摊到下一台机器上，（理论上下一台机器存在为同一台机器的可能，但是概率非常小，可将分片数扩大），有效的降低节点雪崩的风险。</p>
<p>综上，一致性哈希算法并不是强一致性，也不是高可用方案，如果server挂了数据丢了就是丢了，除非有恢复手段，它只是一种减少由扩缩容引起的命中率下降的手段。</p>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>通常分布式缓存中使用一致性hash做数据分布。</p>
<p>相对于 普通hash ，一致性hash的用处在于<strong>缓存集群扩容（缩容）时，一致性hash 可以降低缓存命中率下降问题</strong>。(当服务器节点数据较多时，失效部分可以忽略)</p>
<p>举例：缓存服务器有三个节点，现因业务需要新增加一个 节点，分析普通hash 和 一致性hash 缓存命中率变动幅度。</p>
<ul>
<li><p>普通hash，缓存命中率为 1/4, 失效率为 3/4，计算方式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">假设 N*(N+<span class="number">1</span>) 个key ，则只有N个节点 缓存命中，命中率为  N/(N*(N+<span class="number">1</span>)) = <span class="number">1</span>/(N+<span class="number">1</span>)</span><br><span class="line">失效率为：N/(N+<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>一致性hash ，因为 环周长没有变，只新增了 一个节点部分缓存失效，所以 一致性哈希 的缓存命中率为：<code>N/(N+1)</code> ,失效率为： <code>1/(N+1)</code></p>
</li>
</ul>
<blockquote>
<p>笔记参考：<a href="https://blog.csdn.net/flyfeifei66/article/details/82458618" target="_blank" rel="noopener">https://blog.csdn.net/flyfeifei66/article/details/82458618</a></p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hash/" rel="tag">hash</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%B8%80%E8%87%B4%E6%80%A7hash/" rel="tag">一致性hash</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-详解Mysql（二）" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%BA%8C%EF%BC%89/"
    >详解Mysql（二）</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%BA%8C%EF%BC%89/" class="article-date">
  <time datetime="2021-03-15T08:13:28.000Z" itemprop="datePublished">2021-03-15</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="详解Mysql（二）"><a href="#详解Mysql（二）" class="headerlink" title="详解Mysql（二）"></a>详解Mysql（二）</h1><ul>
<li>单库性能优化：硬件优化、Mysql参数优化、Mysql复制原理、经典架构及场景</li>
<li>Mysql高可用</li>
<li>Mysql高扩展</li>
</ul>
<h2 id="单库性能优化"><a href="#单库性能优化" class="headerlink" title="单库性能优化"></a>单库性能优化</h2><p>单库性能优化主要从以下几个方面入手：</p>
<ul>
<li>数据库服务器硬件优化</li>
<li>MYSQL 参数优化</li>
<li>MYSQL 复制</li>
<li>经典架构及应用场景</li>
</ul>
<h3 id="服务器硬件优化"><a href="#服务器硬件优化" class="headerlink" title="服务器硬件优化"></a>服务器硬件优化</h3><h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a><strong>CPU</strong></h4><p>MySQL 5.6 版本后多核支持加强，可以支持到 128 核甚至更多。每个连接对应一个线程，每个并发 Query 只能使用一个核，所以要想提升 SQL 执行效率，单个 SQL 执行尽可能快。在考虑 CPU 的时候，我们应该优先选择高主频 CPU 来加速单条 SQL 语句的执行效率。</p>
<p>MySQL 引入了 <strong>Thread Pool</strong> 功能来提升性能。，线程处理的最小单位是 statement（SQL 语句），一个线程可以处理多个连接的请求。这样，在保证充分利用硬件资源情况下（合理设置线程池大小），可以避免瞬间连接数暴增导致的服务器抖动。</p>
<p><strong>优化点：</strong></p>
<ul>
<li>系统配置选择 Performance Per Watt Optimized（DAPC），发挥最大功耗性能，而不是节能模式（高运算节点禁用），节能模式在低高频性能转换时易出现Bug。</li>
<li>CPU优先选择高主频以提高运算能力；其次选择核数多，可以多线程并发处理和多实例部署。</li>
<li>关闭 C1E（增强型空闲电源管理状态转换）和 C states，DB 服务器不需要节能和省电运行，默认是开启状态，DB 服务器建议关闭以提高 CPU 效率。</li>
<li>数据库服务器选择高主频多核数 CPU 类型，同时开启最大性能和关闭 CPU CIE 和 C States。 高频加速 SQL 执行，多核解决并发。</li>
</ul>
<h4 id="内存"><a href="#内存" class="headerlink" title="内存"></a><strong>内存</strong></h4><p>对于数据库服务器而言优先选择大内存，同时开启最大性能并关闭NUMA。</p>
<h4 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a><strong>磁盘</strong></h4><ul>
<li>RAID 策略选择： Sata SSD、PCIe SSD 无需 RAID，机械硬盘优先选择 RAID10，其次是 RAID5。</li>
<li>RAID CACHE &amp; BBU 选择：购置阵列卡同时配备 CACHE 及 BBU 模块，可提升机械盘 IOPS，定期检查或监控 CACHE 及 BBU 模块的健康状况，确保意外时不至于丢失数据。</li>
<li>磁盘类型选择：优先选择 SSD 或 PCIe SSD，机械盘使用高速硬盘。</li>
<li>读写策略选择：有阵列卡时设置阵列写策略为 WB 或 Force WB with no battery，严禁 WT。同时关闭陈列预读策略，只用作写缓存。</li>
</ul>
<h3 id="MYSQL-参数优化"><a href="#MYSQL-参数优化" class="headerlink" title="MYSQL 参数优化"></a>MYSQL 参数优化</h3><p>分为：</p>
<ul>
<li>系统全局内存参数（<strong>SGA</strong>）</li>
<li>线程全局内存参数（<strong>PGA</strong>）</li>
</ul>
<h4 id="系统全局内存参数（SGA）"><a href="#系统全局内存参数（SGA）" class="headerlink" title="系统全局内存参数（SGA）"></a><strong>系统全局内存参数（SGA）</strong></h4><ul>
<li>innodb_buffer_pool_size ，用于缓存行数据、索引数据，以及事务锁和自适应哈希等。 单机多实例的情况内存建议按实际数据热点数据量的30%规划，单机单实例（独享实例）的情况建议是分配50%～80%。</li>
<li>innodb_buffer_pool_instances，用于提升性能。</li>
<li>innodb_additional_mem_pool_size，用于缓存所有数据字典。</li>
<li>innodb_log_buffer_size ，InnoDB Redo日志缓冲，提高Redo日志写入效率。</li>
<li>key_buffer_size，MyISAM 表索引高速缓冲，提高 MyISAM 表索引读写效率。</li>
<li>query_cache_size，查询缓存，缓存相同SQL查询结果，提高查询结果返回效率，建议禁用。</li>
<li>table_cache &amp;&amp; table_definiton_cache，表空间文件描述符缓存和表定义文件描述符缓存，提供数据表打开效率。</li>
</ul>
<h4 id="线程全局内存参数（PGA）"><a href="#线程全局内存参数（PGA）" class="headerlink" title="线程全局内存参数（PGA）"></a><strong>线程全局内存参数（PGA）</strong></h4><p><img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%BA%8C%EF%BC%89/mysql_11.png" alt="PGA参数"></p>
<h4 id="Log-参数"><a href="#Log-参数" class="headerlink" title="Log 参数"></a><strong>Log 参数</strong></h4><ul>
<li><p>第一个是控制 Redo Log 刷盘策略的 <strong>innodb_flush_log_at_trx_commit</strong>，它有三个取值策略：</p>
<ul>
<li>当取值为 0 ，表示事务提交时，MySQL 不会去处理日志缓存区（Log Buffer）的内容，也不会去处理日志文件的刷盘操作，由 MySQL 的后台 Master 线程每隔 1s 将缓存区的文件刷新到日志文件中。</li>
<li>当取值为 1 ，表示事务提交时，会将日志缓冲区的日志写入文件中，同时会刷新到磁盘中，保证数据库事务完全不会丢失。这种设置影响数据库性能。</li>
<li>当取值为 2，表示事务提交时，会将日志缓存区日志写入到文件中，但是不会刷新到磁盘中。由 MySQL 的后台 Master 线程每隔 1s 将系统缓存的日志文件刷新到磁盘中。</li>
</ul>
</li>
<li><p>第二个参数是控制 Binlog 刷盘策略的 <strong>sync_binlog</strong>，其取值分为 0、1、N（N&gt;1）三类：</p>
<ul>
<li>当取值为 0 时，事务提交时，MySQL 将 Binlog 信息写入 Binlog 文件（OS Cache）中，但是 MySQL不控制 Binlog 的刷磁盘操作，由文件系统自己控制其缓存的刷新。这是最危险的，一旦操作系统宕机，在 Binlog cache 中的所有 Binlog 都会丢失。如果只是数据库宕机，而操作系统未宕机，那么数据库所生成的 Binlog 都不会丢失。</li>
<li>当取值为 1 时，每一个事务提交时，MySQL 都会把 Binlog 刷新到磁盘中。这样，数据库安全性最高，但是性能损耗也是最大的。如果这样设置的话，在数据库或操作系统宕机的情况下，二进制日志中缺少的任何事务也只能处于准备阶段，那么导致服务器自动恢复时，会回滚这些事务，保证无数据丢失。虽然 Binlog 是顺序 IO，但是多个事务同时提交，同样会对 MySQL 和 IO 的性能带来很大影响，不过 MySQL 可以通过 Group Commit 来缓解这种压力。</li>
<li>当取值为 N 时，表示每 N 次事务提交，MySQL 调用文件系统的刷新操作将缓存刷新到磁盘中。如果数据库或操作系统在这个时候宕机，数据库可能会丢失一些事务。</li>
</ul>
</li>
<li><p>innodb_flush_log_at_timeout：每隔 N 秒写入并刷新日志，默认为 1 即每秒 flush一次,可选 [1-2700]。该参数值允许增加 flush 之间的间隔以减少刷新，避免影响二进制日志组提交的性能。</p>
</li>
<li><p>innodb_log_file_size：日志文件大小，建议设置1～2GB。</p>
</li>
<li><p>innodb_log_files_in_group：日志文件组个数。</p>
</li>
</ul>
<h4 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h4><p><img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%BA%8C%EF%BC%89/mysql_12.png" alt="Mysql参数"></p>
<p><img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%BA%8C%EF%BC%89/mysql_13.png" alt="Mysql参数"></p>
<h3 id="MYSQL复制"><a href="#MYSQL复制" class="headerlink" title="MYSQL复制"></a>MYSQL复制</h3><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><ul>
<li>异步复制<ul>
<li>主从异步复制</li>
<li>半同步复制</li>
</ul>
</li>
<li>同步复制<ul>
<li>Galera Cluster</li>
<li>MySQL Group Replication</li>
</ul>
</li>
</ul>
<h4 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h4><h5 id="主从异步复制"><a href="#主从异步复制" class="headerlink" title="主从异步复制"></a>主从异步复制</h5><p><img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%BA%8C%EF%BC%89/mysql_14.png" alt="MYSQL复制原理图"></p>
<p>涉及三个 Thread</p>
<ul>
<li>Master 的 Binlog Dump Thred</li>
<li>Slave 的 I/O Thread </li>
<li>Slave 的 SQL Thread。</li>
</ul>
<p>数据同步过程：</p>
<ul>
<li>master提交完事务后，写入binlog</li>
<li>slave连接到master，获取binlog</li>
<li>master创建dump线程，推送binglog到slave</li>
<li>slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中</li>
<li>slave再开启一个sql线程读取relay log事件并在slave执行，完成同步</li>
<li>slave记录自己的binglog</li>
</ul>
<p>以上整个复制过程都是异步操作，所以主从复制俗称<strong>异步复制</strong>，存在数据延迟。</p>
<h5 id="半同步复制（after-commit）"><a href="#半同步复制（after-commit）" class="headerlink" title="半同步复制（after commit）"></a>半同步复制（after commit）</h5><p>考虑到一个场景，主库正常写入数据并提交事务 T1，但是 Slave1 和 Slave2 由于某种原因（例如网络原因）一直无法接受到 Binlog Dump Thread Event 的推送请求，如果这时候 Master Crash，Slave 提升为 Master 后导致事务 T1 数据丢失。为了提升数据安全，MySQL 让 Master 在某一个时间点等待 Slave 节点的 ACK 消息后才进行事务提交，这就是<strong>半同步复制</strong>的基础。</p>
<p><strong>MySQL Master 将事务写入 Binlog（sync_binlog=1）并推送给 Slave 后主库将事务提交到存储引擎（此时未返回客户端但是其他会话可以访问到事务提交信息），Slave  I/O Thread 将读取的 Binlog 写入到本地 relay log 文件（sync_relay=1）后向 Master 返回 ACK 消息，当主库 Master 等到 Slave 返回的 ACK 消息后 Master 将事务提交成功的结果返回给客户端。</strong></p>
<h5 id="增强半同步-after-sync"><a href="#增强半同步-after-sync" class="headerlink" title="增强半同步 after-sync"></a>增强半同步 after-sync</h5><p>为了提升数据的安全性，MySQL 5.7 引入了<strong>增强半同步 after_sync（无损复制）</strong>，并将其设置为默认的半同步方式来解决数据丢失的问题。</p>
<p><strong>after-sync 是将 Master 等待 ACK 消息放到了 存储引擎提交事务之前，这样就可以保证数据不会丢失，因为 Slave 接受到 event 并写入自身 relay log，之后给Master 回复ACK, 这时Master 引擎才会提交事务，然后返回结果给客户端。</strong></p>
<h4 id="同步复制（准同步）"><a href="#同步复制（准同步）" class="headerlink" title="同步复制（准同步）"></a>同步复制（准同步）</h4><h5 id="Galera-Cluster"><a href="#Galera-Cluster" class="headerlink" title="Galera Cluster"></a><strong>Galera Cluster</strong></h5><p><strong>Galera Cluster</strong>是一个强一致性集群，当集群节点有数据写入时，Group communication 会向组内所有成员广播写集（初步可简单理解为写入的Binlog），所有节点验证通过之后写节点开始提交，其他节点执行写集应用和提交，当出现数据冲突时则写节点执行回滚，其他节点丢弃该写集。</p>
<h5 id="MySQL-Group-Replication-组复制"><a href="#MySQL-Group-Replication-组复制" class="headerlink" title="MySQL Group Replication 组复制"></a><strong>MySQL Group Replication</strong> 组复制</h5><p>MySQL 在 5.7 版本参考 Galera Cluster 的技术实现推出了 MySQL Group Replication（简称 <strong>MGR</strong>）。</p>
<p>MGR 同样是一个<strong>支持多点写入的多主复制架构</strong>，它<strong>基于原生 MySQL 主从复制的基础上</strong>构建组通信层，由 Group Replication 提供一组原子消息并且按照全局顺序进行消息传递，集群任何节点均可写入，但所有写入事务只有在获得<strong>复制组认证</strong>通过（多数派协议 Paxos）后才能进行提交。例如由若干个节点共同组成一个复制组，一个事务的提交必须经过组内大多数节点（N / 2 + 1）决议并通过，才能得以提交。</p>
<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul>
<li><strong>主从复制</strong>：通常适合于轻量级程序、高可用要求不高的业务场景。这类架构中应用程序直连访问 Master 和 Slave 进行读写分离，当 Master 出现故障时由于无法自动切换导致服务受损。因此通常会基于此架构加上 VIP/DNS + Keepalived 及双主复制来做一个简单的高可用切换。</li>
<li><strong>双主复制</strong>：通常为其中一个 Master 提供线上服务，另一个 Master 作为 Standby 供高可用切换（这里的原理为互为主从，通过<strong>keepalived</strong>监控主库状态，做故障切换），Master 下游挂载 Slave 承担读请求。</li>
<li><strong>树形复制</strong>：这类架构通常适用于数据访问策略分层，例如 MySQL Master 和 MySQL Slave 参与线上业务访问及高可用切换，MySQL Statistic 节点提供离线查询、报表慢查和非线上业务访问。</li>
</ul>
<h3 id="海量数据架构设计"><a href="#海量数据架构设计" class="headerlink" title="海量数据架构设计"></a>海量数据架构设计</h3><h4 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h4><ul>
<li><strong>响应时间</strong>：系统对请求做出响应的时间，一般取平均响应时间。</li>
<li><strong>吞吐量</strong>：单位时间内处理的请求数量。</li>
<li><strong>QPS</strong>：每秒处理的查询次数。</li>
<li><strong>TPS</strong>：每秒处理的事务数。</li>
<li><strong>并发用户数</strong>：同时承载正常使用系统功能的用户数量。</li>
</ul>
<p><strong>基本方法：</strong></p>
<ul>
<li>垂直扩展</li>
<li>水平扩展</li>
<li>分布式</li>
</ul>
<h4 id="垂直扩展-Scale-Up"><a href="#垂直扩展-Scale-Up" class="headerlink" title="垂直扩展 Scale-Up"></a>垂直扩展 Scale-Up</h4><p>纵向扩展：也叫垂直扩展，扩展一个点的能力以支撑更多的请求。</p>
<p>主要分为一下4个方向：</p>
<ul>
<li>增强单机硬件性能：CPU、内存、硬盘、网络等</li>
<li>提升单机架构性能：例如增加缓存、增加队列</li>
<li>无锁数据结构：例如业务解耦</li>
<li>分区：分区是指按照一定的规则，把数据库中的一个表分解成多个更小的、更容易管理的部分，分区有利于管理非常大的表。<ul>
<li>分区可以把数据打散存储到不同的文件系统上，和单个磁盘或者文件系统相比，可以存储更多的数据。</li>
<li>优化查询。where 子句包含分区条件时，可以只扫描对应分区，缩小了查询范围。</li>
<li>同时在涉及 count() 和 sum() 等聚合函数时，可以在多个分区上并行处理。</li>
<li>对于已经过期或不需要的数据，可以通过删除分区快速删除。跨多个磁盘来分散数据查询，以获得更大的查询吞吐量。</li>
</ul>
</li>
</ul>
<p>关于分区的问题：</p>
<ul>
<li>一个表最多只能有 1024 个分区，MySQL 5.6 之后支持 8192 个分区。</li>
<li>如果分区字段中有主键或者唯一索引列，那么所有主键列和唯一索引列都必须包含进来，如果表中有主键或唯一索引，那么分区键必须是主键或唯一索引。</li>
<li>MySQL 分区适用于一个表的所有数据和索引，不能只对表数据分区而不对索引分区，也不能只对一个表的部分数据进行分区。</li>
<li>无论使用何种分区类型，不能使用主键/唯一键之外的其他字段进行分区。</li>
<li>分区表中无法使用外键约束。</li>
<li>MySQL 数据库支持的分区类型为水平分区，并不支持垂直分区，因此，MySQL 数据库的分区中索引是局部分区索引，一个分区中既存放了数据又存放了索引，而全局分区是指数据库放在各个分区中，但是所有的数据的索引放在另外一个对象中。</li>
<li>目前 MySQL 不支持对空间类型和临时表类型进行分区。不支持全文索引。</li>
</ul>
<h4 id="水平扩展-Scale-Out"><a href="#水平扩展-Scale-Out" class="headerlink" title="水平扩展 Scale-Out"></a>水平扩展 Scale-Out</h4><p>横向扩展：也叫水平扩展，用更多的节点支撑更大量的请求，达到线性扩充系统的能力。</p>
<ul>
<li><p>主从复制。通过主从复制来扩展从库，从而提升读性能。</p>
</li>
<li><p>分库分表。这个又可以称之为 “ 数据分片（Sharding）”</p>
</li>
<li><p>数据库中间件。例如：使用中间件来达到读写分离的目的。</p>
</li>
<li><p>集群。例如：使用 PXC 或者 MGR 集群来弥补单机性能的不足。</p>
</li>
</ul>
<h4 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h4><p>分布式关系型数据库发展到今天，主要分为两个阵营：</p>
<ul>
<li>基于分布式事务的数据库，以 Google Cloud Spanner 和 PingCAP 的 TiDB 为代表。</li>
<li>基于分布式存储的数据库，以 AWS 的 Aurora 和极数云舟的 ArkDB 为代表。</li>
</ul>
<h4 id="常用数据库架构方案对比"><a href="#常用数据库架构方案对比" class="headerlink" title="常用数据库架构方案对比"></a>常用数据库架构方案对比</h4><p><img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%BA%8C%EF%BC%89/mysql_15.png" alt="常用数据库架构方案对比"></p>
<blockquote>
<p>笔记来源：</p>
<p>周彦伟 老师的 《高性能Mysql实战》课程</p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Mysql/" rel="tag">Mysql</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0/" rel="tag">面试复习</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-详解Mysql（一）" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/"
    >详解Mysql（一）</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/" class="article-date">
  <time datetime="2021-03-15T08:11:09.000Z" itemprop="datePublished">2021-03-15</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="详解Mysql（一）"><a href="#详解Mysql（一）" class="headerlink" title="详解Mysql（一）"></a>详解Mysql（一）</h1><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>Mysql 是一个优秀的开源关系型数据库，目前已成为一线互联网公司通用数据库。</p>
<p><img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_01.png" alt="Mysql演变图"></p>
<p>MySQL 从最初的 1.0、3.1 到后来的 5.0，发生了各种各样的变化。被 Oracle 收购后，MySQL 的版本其实主要有几个分支，除了需要付费的 MySQL 企业版本，还有很多 MySQL 社区版本。</p>
<p>目前主流分支已经更新到8.0 的 MySQL 官方版本。</p>
<p>Percona Server 是 MySQL 的技术支持公司 Percona 推出的非常流行的开源分支版本，其在官方版本的基础上做了一些补丁和优化，同时推出了一些工具。</p>
<p>MariaDB 也是 Mysql的一个分支。</p>
<p>本课学习版本为 mysql 5.7</p>
<h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul>
<li>体积小、速度快，可以在不占用太多资源的情况下提供数据库服务；</li>
<li>开源免费，工具生态完善，用起来没有经济门槛；</li>
<li>简单易用，维护成本低，用起来没有技术门槛；</li>
<li>兼容性好，支持多种操作系统，用起来没有平台门槛；</li>
<li>提供多种 API 接口；支持多种开发语言，用起来没有编程语言门槛；</li>
<li>社区及用户活跃，用起来没有技术支持门槛；</li>
<li>MySQL 支持事务、MVCC、4 种隔离级别等，同时易扩展、集群、高可用等也可以满足一般需求。</li>
</ul>
<h3 id="体系结构与存储引擎"><a href="#体系结构与存储引擎" class="headerlink" title="体系结构与存储引擎"></a>体系结构与存储引擎</h3><h4 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h4><img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_02.png" alt="Mysql体系结构" style="zoom:57%;">

<p><strong>MySQL</strong> 体系结构由 <strong>Client Connectors 层</strong>、<strong>MySQL Server 层</strong>及<strong>存储引擎层</strong>、<strong>物理存储层</strong>四个部分组成。</p>
<ul>
<li><p><strong>Client Connectors层</strong></p>
<p>负责处理客户端的连接请求，与客户端创建连接。目前 MySQL 几乎支持所有的连接类型，例如常见的 JDBC、Python、Go 等。</p>
</li>
<li><p><strong>MySQL Server 层</strong></p>
<p><strong>MySQL Server</strong> 层主要包括 <strong>Connection Pool、Service &amp; utilities、SQL interface、Parser解析器、Optimizer 查询优化器、Caches 缓存等模块</strong>。</p>
<ul>
<li><strong>Connection Pool</strong>：负责处理和存储数据库与客户端创建的连接，一个线程负责管理一个连接。Connection Pool 包括了用户认证模块，就是用户登录身份的认证和鉴权及安全管理，也就是用户执行操作权限校验。</li>
<li><strong>Service &amp; utilities</strong>：是管理服务&amp;工具集，包括备份恢复、安全管理、集群管理服务和工具。</li>
<li><strong>SQL interface</strong>：负责接收客户端发送的各种 SQL 语句，比如 DML、DDL 和存储过程等。</li>
<li><strong>Parser 解析器</strong>：对 SQL 语句进行语法解析生成解析树。</li>
<li><strong>Optimizer 查询优化器</strong>：根据解析树生成执行计划，并选择合适的索引，然后按照执行计划执行 SQL 语言并与各个存储引擎交互。</li>
<li><strong>Caches 缓存</strong>：包括各个存储引擎的缓存部分，比如：InnoDB 存储的 Buffer Pool、MyISAM 存储引擎的 key buffer 等，Caches 中也会缓存一些权限，也包括一些 Session 级别的缓存。</li>
</ul>
</li>
<li><p><strong>存储引擎层</strong></p>
<p>存储引擎包括 <strong>MyISAM</strong>、<strong>InnoDB</strong>，以及支持归档的 Archive 和内存的 Memory 等。MySQL是<strong>插件式的存储引擎</strong>，只要正确定义与 MySQL Server 交互的接口，任何引擎都可以访问MySQL。</p>
</li>
<li><p><strong>物理层存储层</strong></p>
<p>文件的物理存储层，包括二进制日志、数据文件、错误日志、慢查询日志、全日志、redo/undo 日志等。</p>
</li>
</ul>
<h4 id="查询交互过程"><a href="#查询交互过程" class="headerlink" title="查询交互过程"></a>查询交互过程</h4><p>我们用一条 SQL SELECT 语句的执行轨迹来说明客户端与 MySQL 的交互过程</p>
<img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_03.png" alt="Mysql交互过程" style="zoom:67%;">

<p>① 通过客户端/服务器通信协议与 MySQL <strong>建立连接</strong>。</p>
<p>② <strong>查询缓存</strong>，这是 MySQL 的一个可优化查询的地方，如果开启了 Query Cache 且在查询缓存过程中查询到完全相同的 SQL 语句，则将查询结果直接返回给客户端；如果没有开启Query Cache 或者没有查询到完全相同的 SQL 语句则会由解析器进行语法语义解析，并生成解析树。</p>
<p>③ 预处理器<strong>生成新的解析树</strong>。</p>
<p>④ 查询优化器<strong>生成执行计划</strong>。</p>
<p>⑤ 查询执行引擎执行 SQL 语句，此时查询执行引擎会根据 SQL 语句中表的存储引擎类型，以及对应的 API 接口与底层存储引擎缓存或者物理文件的交互情况，<strong>得到查询结果</strong>，由MySQL Server 过滤后将查询结果缓存并返回给客户端。若开启了 Query Cache，这时也会将SQL 语句和结果完整地保存到 Query Cache 中，以后若有相同的 SQL 语句执行则直接返回结果。</p>
<h4 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h4><p>存储引擎是 MySQL 中具体与文件打交道的子系统，它是根据 MySQL AB 公司提供的<strong>文件访问层抽象接口定制的一种文件访问机制</strong>，这种机制就叫作<strong>存储引擎</strong>。</p>
<p>前面说到Mysql 是插件式的存储引擎，只要正确定义与 MySQL Server 交互的接口，任何引擎都可以访问MySQL。所以Mysql支持很多种存储引擎，常用的为 MyISAM、支持事务的 InnoDB、内存类型的 Memory、归档类型的 Archive、列式存储的 Infobright，以及一些新兴的存储引擎等。</p>
<p><strong>在 MySQL 5.6 版本之前，默认的存储引擎都是 MyISAM，但 5.6 版本以后默认的存储引擎就是 InnoDB 了。</strong></p>
<p>我们主要<strong>对比</strong> 这俩种存储引擎的功能。</p>
<img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_05.png" alt="InnoDB和MyISAM对比" style="zoom:67%;">

<blockquote>
<p>图片来自网络</p>
</blockquote>
<ul>
<li>InnoDB 支持 ACID 的事务 4 个特性，而 MyISAM 不支持；</li>
<li>InnoDB 支持 4 种事务隔离级别，默认是可重复读 Repeatable Read 的，MyISAM 不支持；</li>
<li>InnoDB 支持 crash 安全恢复，MyISAM 不支持；InnoDB 支持外键，MyISAM 不支持；</li>
<li>InnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度；</li>
<li>InnoDB 支持 MVCC，MyISAM 不支持；</li>
<li>InnoDB 表最大还可以支持 64TB，支持聚簇索引、支持压缩数据存储，支持数据加密，支持查询/索引/数据高速缓存，支持自适应hash索引、空间索引，支持热备份和恢复等</li>
</ul>
<p><strong>如何选择？</strong></p>
<p>需要事务操作，选InnoDB；</p>
<p>如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果有读，写也挺频繁，请使用InnoDB。</p>
<p>MyISAM适合：(1) 做很多count 的计算；(2) 插入不频繁，查询非常频繁；(3) 没有事务。</p>
<p>InnoDB适合：(1) 可靠性要求比较高，或者要求事务；(2) 表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。</p>
<h3 id="知识点扫盲"><a href="#知识点扫盲" class="headerlink" title="知识点扫盲"></a>知识点扫盲</h3><h4 id="范式与反范式"><a href="#范式与反范式" class="headerlink" title="范式与反范式"></a>范式与反范式</h4><p><strong>范式</strong>是关系数据库理论的基础，也是我们在设计数据库结构过程中所要遵循的规则和指导方法。数据库的设计范式是数据库设计所需要满足的规范。只有理解数据库的设计范式，才能设计出高效率、优雅的数据库。</p>
<p>目前关系数据库有<strong>六种范式</strong>：<strong>第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式（4NF）和第五范式（5NF，还又称完美范式）</strong>。</p>
<p>满足最低要求的叫第一范式，简称 1NF。在第一范式基础上进一步满足一些要求的为第二范式，简称 2NF。其余依此类推。各种<strong>范式呈递次规范</strong>，越高的范式数据库冗余越小。通常所用到的只是前三个范式，即：第一范式（1NF），第二范式（2NF），第三范式（3NF）。</p>
<p><strong>第一范式</strong></p>
<p>第一范式无重复的列，表中的每一列都是拆分的基本数据项，即<strong>列不能够再拆分成其他几列</strong>，强调的是列的原子性.。</p>
<p><strong>第二范式</strong></p>
<p>第二范式属性完全依赖于主键，首先要满足它符合 1NF，另外还需要包含两部分内容：</p>
<ul>
<li>表必须有一个主键；</li>
<li>没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。</li>
</ul>
<p><strong>第三范式</strong></p>
<p>第三范式属性不传递依赖于其他非主属性，首先需要满足 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。</p>
<p>第二范式：非主键列是否依赖主键（包括一列通过某一列间接依赖主键），要是有依赖关系就是第二范式；</p>
<p>第三范式：非主键列是否直接依赖主键，不能是那种通过传递关系的依赖。要是符合这种依赖关系就是第三范式。</p>
<p><strong>优缺点</strong></p>
<p>优点：</p>
<ul>
<li>避免数据冗余，减少维护数据完整性的麻烦；</li>
<li>减少数据库的空间；数据变更速度快。</li>
</ul>
<p>缺点：</p>
<p>按照范式的规范设计的表，等级越高的范式设计出来的表数量越多。获取数据时，表关联过多，性能较差。表的数量越多，查询所需要的时间越多。也就是说所用的范式越高，对数据操作的性能越低。</p>
<p><strong>反范式</strong></p>
<p>范式是普适的规则，满足大多数的业务场景的需求。对于一些特殊的业务场景，范式设计的表，无法满足性能的需求。此时，就需要根据业务场景，在范式的基础之上进行灵活设计，也就是<strong>反范式设计</strong>。</p>
<p>反范式设计主要从三方面考虑：<strong>业务场景；相应时间；字段冗余</strong>。</p>
<p>反范式设计就是用空间来换取时间，提高业务场景的响应时间，减少多表关联。</p>
<h4 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h4><p><strong>ARIES 三原则</strong>，是指 <strong>Write Ahead Logging</strong>（WAL）。</p>
<ul>
<li><p>先写日志后写磁盘，日志成功写入后事务就不会丢失，后续由 checkpoint 机制来保证磁盘物理文件与 Redo 日志达到一致性；</p>
</li>
<li><p>利用 Redo 记录变更后的数据，即 Redo 记录事务数据变更后的值；</p>
</li>
<li><p>利用 Undo 记录变更前的数据，即 Undo 记录事务数据变更前的值，用于回滚和其他事务多版本读。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql &gt;show engine innodb status\G;</span><br></pre></td></tr></table></figure>

<p>该命令的结果里面有详细的 InnoDB 运行态信息，分段记录的，包括内存、线程、信号、锁、事务等，出现问题时从中能分析出具体原因和解决方案。</p>
<h4 id="★-单版本控制-锁"><a href="#★-单版本控制-锁" class="headerlink" title="★     单版本控制 - 锁"></a>★     单版本控制 - 锁</h4><p><strong>锁</strong>用独占的方式来保证在只有一个版本的情况下事务之间相互隔离，所以锁可以理解为单版本控制。</p>
<p>在 MySQL 事务中，锁的实现与隔离级别有关系，在 RR（Repeatable Read）隔离级别下，MySQL 为<strong>了解决幻读的问题，以牺牲并行度为代价，通过 Gap 锁（间隙锁）来防止数据的写入</strong>，而这种锁，因为其并行度不够，冲突很多，经常会引起死锁。现在流行的 Row 模式可以避免很多冲突甚至死锁问题，所以推荐默认使用 Row + RC（Read Committed）模式的隔离级别，可以很大程度上提高数据库的读写并行度。</p>
<p><strong>间隙锁</strong>，即对于不在区间范围内的数据也加锁，例如满足某一条数据的条数是100条，哪些满足条件，但是不存在的数据称为<strong>间隙</strong>，对其加锁叫<strong>间隙锁</strong>，用于防止事务区间内，其他事务插入数据，造成幻读。</p>
<p><strong>共享锁与排他锁</strong></p>
<ul>
<li>共享锁（读锁）：其他事务可以读，但不能写。</li>
<li>排他锁（写锁） ：其他事务不能读取，也不能写。</li>
</ul>
<p><strong>粒度锁</strong></p>
<ul>
<li><p>表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。</p>
<ul>
<li><p>这些存储引擎通过总是一次性同时获取所有需要的锁以及总是按相同的顺序获取表锁来避免死锁。</p>
</li>
<li><p>表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如Web 应用</p>
</li>
</ul>
</li>
<li><p>行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p>
<ul>
<li>最大程度的支持并发，同时也带来了最大的锁开销。</li>
<li>在 InnoDB 中，除单个 SQL 组成的事务外，锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的。</li>
<li>行级锁只在存储引擎层实现，而Mysql服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。</li>
</ul>
</li>
<li><p>页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。</p>
</li>
</ul>
<p><strong>Mysql 中锁粒度对比</strong></p>
<ul>
<li><p>MyISAM 和 MEMORY 存储引擎采用的是<strong>表级锁</strong>（table-level locking）；</p>
</li>
<li><p>BDB 存储引擎采用的是<strong>页面锁</strong>（page-level locking），但也支持表级锁；</p>
</li>
<li><p>InnoDB 存储引擎既支持<strong>行级锁</strong>（row-level locking），也支持表级锁，但默认情况下是采用行级锁。</p>
</li>
</ul>
<p><strong>默认情况下，表锁和行锁都是自动获得的</strong>， 不需要额外的命令。</p>
<p>但是在有的情况下， 用户需要明确地进行锁表或者进行事务的控制， 以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。</p>
<p><strong>InnoDB 引擎中的锁实现</strong></p>
<p>InnoDB 实现了以下两种类型的<strong>行锁</strong>：</p>
<ul>
<li><strong>共享锁</strong>（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。</li>
<li><strong>排他锁</strong>（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。</li>
</ul>
<p>为了允许<strong>行锁和表锁共存</strong>，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是<strong>表锁</strong>：</p>
<ul>
<li><strong>意向共享锁</strong>（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。</li>
<li><strong>意向排他锁</strong>（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。</li>
</ul>
<p><strong>InnoDB加锁方法：</strong></p>
<ul>
<li><p><strong>意向锁</strong>是 InnoDB 自动加的， 不需用户干预。</p>
</li>
<li><p>对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB会自动给涉及数据集加<strong>排他锁</strong>（X)；</p>
</li>
<li><p>对于普通 SELECT 语句，InnoDB 不会加任何锁；事务可以通过以下语句显式给记录集加共享锁或排他锁：</p>
</li>
<li><ul>
<li>共享锁（S）：SELECT * FROM table_name WHERE … <strong>LOCK IN SHARE MODE</strong>。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。</li>
<li>排他锁（X)：SELECT * FROM table_name WHERE … <strong>FOR UPDATE</strong>。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁</li>
</ul>
</li>
</ul>
<p><strong>InnoDB 行锁实现方式：</strong></p>
<ul>
<li>InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！</li>
<li>不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。</li>
<li>只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。</li>
<li>由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。</li>
</ul>
<p><strong>死锁（Deadlock Free）</strong></p>
<ul>
<li><p><strong>死锁产生：</strong></p>
</li>
<li><ul>
<li>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。</li>
<li>当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。</li>
<li>锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。</li>
</ul>
</li>
<li><p><strong>检测死锁：</strong>数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。</p>
</li>
<li><p><strong>死锁恢复：</strong>死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。</p>
</li>
<li><p><strong>外部锁的死锁检测：</strong>发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 <strong>innodb_lock_wait_timeout</strong> 来解决</p>
</li>
<li><p><strong>死锁影响性能：</strong>死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。</p>
</li>
</ul>
<p><strong>优化锁性能的建议</strong></p>
<ul>
<li>尽量使用较低的隔离级别；</li>
<li>精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会</li>
<li>选择合理的事务大小，小事务发生锁冲突的几率也更小</li>
<li>给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁</li>
<li>不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会</li>
<li>尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响。</li>
<li>不要申请超过实际需要的锁级别。</li>
<li>除非必须，查询时不要显示加锁。 MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能；MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。</li>
<li>对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。</li>
</ul>
<p><strong>乐观锁、悲观锁</strong></p>
<ul>
<li><p><strong>乐观锁(Optimistic Lock)</strong>：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。</p>
</li>
<li><p><strong>悲观锁(Pessimistic Lock)</strong>：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。</p>
<p>传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。</p>
</li>
</ul>
<h4 id="多版本控制-MVVC"><a href="#多版本控制-MVVC" class="headerlink" title="多版本控制 - MVVC"></a>多版本控制 - MVVC</h4><p><strong>MVCC (Multi-Version Concurrency Control)</strong>是一种基于多版本的<strong>并发控制协议</strong>，只有在<strong>InnoDB</strong>引擎下存在。MVCC是为了实现事务的隔离性，通过版本号，避免同一数据在不同事务间的竞争，你可以把它当成基于多版本号的一种乐观锁。MVCC最大的好处就是：<strong>读不加锁，读写不冲突</strong>。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能。</p>
<p><strong>注意</strong>：MVCC 只在 <strong>读提交（RC，Read Committed）</strong> 和 <strong>可重复读（RR，Repeatable Read）</strong> 两种隔离级别下工作。</p>
<p><strong>实现机制</strong></p>
<p><strong>InnoDB</strong>在每行数据都增加两个隐藏字段，一个记录<strong>创建的版本号</strong>，一个记录<strong>删除的版本号</strong>。</p>
<p>简单来说,是通过在每行记录后面保存<strong>两个隐藏的列</strong>来实现的,这两个列，分别保存了这个行的创建时间，一个保存的是行的删除时间。这里存储的并不是实际的时间值,而是系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID.</p>
<ul>
<li>InnoDB只会查找版本早于当前事务版本的数据行(也就是,行的系统版本号小于或等于事务的系统版本号)，<strong>这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的.</strong></li>
<li>行的删除版本要么未定义,要么大于当前事务版本号,<strong>这可以确保事务读取到的行，在事务开始之前未被删除.</strong></li>
</ul>
<p>在多版本并发控制中，为了保证数据操作在多线程过程中，保证事务隔离的机制，降低锁竞争的压力，保证较高的并发量。在每开启一个事务时，会生成一个事务的版本号，被操作的数据会生成一条新的数据行（临时），但是在提交前对其他事务是不可见的，对于数据的更新（包括增删改）操作成功，会将这个版本号更新到数据的行中，事务提交成功，将新的版本号更新到此数据行中，这样保证了每个事务操作的数据，都是互不影响的，也不存在锁的问题。</p>
<h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><p><strong>事务</strong>是指作为单个逻辑工作单元执行的一系列操作，这些操作要么全做，要么全不做，是一个不可分割的工作单元。</p>
<p>一个逻辑工作单元要成为事务，在关系型数据库管理系统中，必须满足 4 个特性，即所谓的 <strong>ACID</strong>：</p>
<ul>
<li><strong>一致性</strong>：事务开始之前和事务结束之后，数据库的完整性限制未被破坏。</li>
<li><strong>原子性</strong>：事务的所有操作，要么全部完成，要么全部不完成，不会结束在某个中间环节。</li>
<li><strong>持久性</strong>：事务完成之后，事务所做的修改进行持久化保存，不会丢失。</li>
<li><strong>隔离性</strong>：当多个事务并发访问数据库中的同一数据时，所表现出来的相互关系。</li>
</ul>
<p>ACID 及它们之间的关系如下图所示，比如 4 个特性中有 3 个与 WAL 有关系，都需要通过 Redo、Undo 日志来保证等。</p>
<img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_06.png" alt="ACID关系" style="zoom:75%;">

<p><strong>原子性</strong></p>
<p><strong>MySQL</strong> 是通过 <strong>WAL</strong>（Write Ahead Log）技术来实现。</p>
<p>每一个写事务，都会修改 Buffer Pool，从而产生相应的 Redo 日志，这些日志信息会被记录到 ib_logfiles 文件中。因为 Redo 日志是遵循 Write Ahead Log 的方式写的，所以事务是顺序被记录的。</p>
<p>任何 Buffer Pool 中的页被刷到磁盘之前，都会先写入到日志文件中。</p>
<ul>
<li>如果事务提交了，Buffer Pool 的脏页没有刷盘（刷到磁盘），如何保证改了的数据生效？可使用 Redo 日志恢复出来的数据。</li>
<li>如果事务没有提交，且 Buffer Pool 的脏页被刷盘了，那这个本不应该存在的数据如何消失？需要通过 Undo 来实现，Undo 又是通过 Redo 来保证的，所以最终原子性的保证还是靠 Redo 的 WAL 机制实现的。</li>
</ul>
<p><strong>持久性</strong></p>
<p>是指一个事务一旦提交，它对数据库中数据的改变就应该是永久性。</p>
<p>通过原子性可以保证逻辑上的持久性，通过存储引擎的数据刷盘可以保证物理上的持久性。</p>
<p><strong>隔离性</strong></p>
<p>指的是一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对其他的并发事务是隔离的。</p>
<p><strong>InnoDB</strong> 支持的隔离性有 4 种，隔离性从低到高分别为：<strong>读未提交、读提交、可重复读、可串行化</strong>。</p>
<ul>
<li><strong>读未提交</strong>（RU，Read Uncommitted）。它能读到一个事务的中间过程，违背了 ACID 特性，存在脏读的问题，所以基本不会用到，可以忽略。</li>
<li><strong>读提交</strong>（RC，Read Committed）。它表示如果其他事务已经提交，那么我们就可以看到，这也是一种最普遍适用的级别。但由于一些历史原因，可能 RC 在生产环境中用的并不多。</li>
<li><strong>可重复读</strong>（RR，Repeatable Read），是目前被使用得最多的一种级别。其特点是有 Gap 锁、目前还是默认的级别、在这种级别下会经常发生死锁、低并发等问题。</li>
<li><strong>可串行化</strong>，这种实现方式，其实已经并不是多版本了，又回到了单版本的状态，因为它所有的实现都是通过锁来实现的。</li>
</ul>
<p><strong>一致性</strong></p>
<ul>
<li><strong>约束一致性</strong>：创建表结构时所指定的外键、Check（Mysql不支持）、唯一索引等约束。</li>
<li><strong>数据一致性</strong>：由原子性、持久性、隔离性共同保证。</li>
</ul>
<h4 id="并发事务问题及解决方案"><a href="#并发事务问题及解决方案" class="headerlink" title="并发事务问题及解决方案"></a><strong>并发事务问题及解决方案</strong></h4><p>前面说过通过<strong>单版本控制-锁</strong>以及<strong>多版本控制-MVVC</strong>实现并发事务，同时并发事务处理也会带来一些问题，如：<strong>脏读、不可重复读、幻读。</strong></p>
<ul>
<li><strong>脏读</strong>一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象的叫作”脏读”（Dirty Reads）。</li>
<li><strong>不可重复读</strong>一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫作“ 不可重复读”（Non-Repeatable Reads）。</li>
<li><strong>幻读</strong>一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”（Phantom Reads）。</li>
</ul>
<p>MySQL 数据库是通过<strong>事务隔离级别</strong>来解决上述问题的：</p>
<img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_07.png" alt="事务隔离级别解决并发事务问题" style="zoom:67%;">



<h3 id="设计规范"><a href="#设计规范" class="headerlink" title="设计规范"></a>设计规范</h3><p><strong>基本使用原则：</strong></p>
<ul>
<li>MySQL 数据库只用于数据的存储，不进行数据的复杂计算，不承载业务逻辑，确保存储和计算分离；</li>
<li>查询数据时，尽量单表查询，减少跨库查询和多表关联；</li>
<li>杜绝大事务、大 SQL、大批量、大字段等一系列性能杀手。<ul>
<li>大事务，运行步骤较多，涉及的表和字段较多，容易造成资源的争抢，甚至形成死锁。一旦事务回滚，会导致资源占用时间过长。</li>
<li>大 SQL，复杂的 SQL 意味着过多的表的关联，MySQL 数据库处理关联超过 3 张表以上的 SQL 时，占用资源多，性能低下。</li>
<li>大批量，意味着多条 SQL 一次性执行完成，必须确保进行充分的测试，并且在业务低峰时段或者非业务时段执行。大字段，blob、text 等大字段，尽量少用。必须要用时，尽量与主业务表分离，减少对这类字段的检索和更新。</li>
</ul>
</li>
</ul>
<p><strong>基础规范：</strong></p>
<ul>
<li>必须指定默认存储引擎为 InnoDB，并且禁用 MyISAM 存储引擎。</li>
<li>默认字符集 <code>UTF8mb4</code>，以前版本的 UTF8 是 <code>UTF8mb3</code>，未包含个别特殊字符，新版本的 UTF8mb4 包含所有字符，官方强烈建议使用此字符集。</li>
<li>关闭区分大小写功能。设置<code>lower_case_tables_name=1</code>，即可关闭区分大小写功能，即大写字母 T 和小写字母 t 一样。</li>
<li>存储过程、触发器、视图、event。为了存储计算分离，这类功能尽量在程序中实现。这些功能非常不完整，调试、排错、监控都非常困难，相关数据字典也不完善，存在潜在的风险。一般在生产数据库中，禁止使用。</li>
<li>lob、text、enum、set。这些字段类型，在 MySQL 数据库的检索性能不高，很难使用索引进行优化。如果必须使用这些功能，一般采取特殊的结构设计，或者与程序结合使用其他的字段类型替代。比如：set 可以使用整型（0，1，2，3）、注释功能和程序的检查功能集合替代。</li>
</ul>
<p><strong>命名规范：</strong></p>
<ul>
<li>命名时的字符取值范围为：<code>a~z</code>，<code>0~9</code>和<code>_（下画线）</code></li>
<li>所有表名小写，不允许驼峰式命名；</li>
<li>允许使用 <code>-（横线）</code>和 <code>（空格）</code>；不允许使用其他特殊字符作为名称，减少潜在风险。</li>
<li>数据库库名的命名规则必须遵循“见名知意”的原则，即库名规则为<code>数据库类型代码 + 项目简称 + 识别代码 + 序号</code>。只有一个数据库，则不加序号，否则末尾增加序号；生产库不加识别代码，否则需要增加识别代码 DEV 或 TEST；如果只作历史库，则只需要<code>项目简称 + H + 序号</code>；</li>
<li>单表仅使用 <code>a~z、_</code>；分表名称为<code>表名_编号</code>；</li>
<li>业务表名代表用途、内容：子系统简称_业务含义_后缀。常见业务表类型有：临时表，<code>tmp</code>；备份表，<code>bak</code>；字典表，<code>dic</code>；日志表，<code>log</code>。</li>
<li>字段名精确，遵循“见名知意”的原则，格式：<code>名称_后缀</code>。避免普遍简单、有歧义的名称。用户表中，用户名的字段为 UserName 比 Name 更好。布尔型的字段，以助动词<code>（has/is）</code>开头。用户是否有留言 hasmessage，用户是否通过检查 ischecked 等。</li>
<li>常见后缀：流水号/无意义主键，后缀为 id，比如 task_id；时间，后缀为 time，insert_time。程序账号与数据库名称保持一致。如果所有的程序账号都是 root@‘%’，密码也一样，很容易错连到其他的数据库，造成误操作。</li>
<li>索引命名格式：主要为了区分哪些对象是索引：<code>前缀_表名（或缩写）_字段名（或缩写）</code>；主键必须使用前缀<code>pk_</code>；UNIQUE 约束必须使用前缀<code>uk_</code>；普通索引必须使用前缀<code>idx_</code>。</li>
<li>创建表时显示指定<code>字符集、存储引擎、注释信息</code>等。  不同系统之间，统一规范；不同表之间的相同字段或者关联字段，字段类型/命名要保持一致；库表字符集和前端程序、中间件必须保持一致的 <code>UTF8mb4</code>。</li>
<li>InnoDB表的注意事项：<ul>
<li>主键列，UNSIGNED 整数，使用 auto_increment；禁止手动更新 auto_increment，可以删除。</li>
<li>必须添加 comment 注释。</li>
<li>必须显示指定的 engine。</li>
<li>表必备三字段：id、 xxx_create、 xxx_modified。id 为主键，类型为 unsigned bigint 等数字类型；xxx_create、xxx_modified 的类型均为 datetime 类型，分别记录该条数据的创建时间、修改时间。</li>
</ul>
</li>
</ul>
<p><strong>不同类型表设计规范：</strong></p>
<ul>
<li>备份表，表名必须添加 bak 和日期，主要用于系统版本上线时，存储原始数据，上线完成后，必须及时删除。</li>
<li>临时表，用于存储中间业务数据，定期优化，及时降低表碎片。</li>
<li>日志类表，首先考虑不入库，保存成文件，其次如果入库，明确其生命周期，保留业务需求的数据，定期清理。</li>
<li>大字段表，把主键字段和大字段，单独拆分成表，并且保持与主表主键同步，尽量减少大字段的检索和更新。</li>
<li>大表，根据业务需求，从垂直和水平两个维度进行拆分。<ul>
<li>垂直拆分：按列关联度。</li>
<li>水平拆分：按照时间、地域、范围等；冷热数据（历史数据归档）。</li>
</ul>
</li>
</ul>
<p><strong>字段设计要求：</strong></p>
<ul>
<li>根据业务场景需求，选择合适的类型，最短的长度；确保字段的宽度足够用，但也不要过宽。</li>
<li>尽量所有字段必须为 NOT NULL，空值则指定 default 值，空值难以优化，查询效率低。</li>
<li>表字段数少而精，尽量不加冗余列。</li>
<li>单实例表个数必须控制在 2000 个以内。</li>
<li>单表分表个数必须控制在 1024 个以内。</li>
<li>单表字段数上限控制在 20~50 个。</li>
<li>禁用 ENUM、SET 类型。兼容性不好，性能差。解决方案：使用 TINYINT，在 COMMENT 信息中标明被枚举的含义。<code>is_disable</code> TINYINT UNSIGNED DEFAULT ‘0’ COMMENT ‘0:启用 1:禁用 2:异常’。</li>
</ul>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>数据库索引是一种数据结构，它以额外的写入和存储空间为代价来提高数据库表上数据检索操作的速度。</p>
<p>MySQL 官方对索引（Index）的定义是存储引擎用于快速查找记录的一种数据结构。</p>
<p>索引是物理数据页，数据库页大小（Page Size）决定了一个页可以存储多少个索引行，以及需要多少页来存储指定大小的索引。</p>
<p>索引可以加快检索速度，但同时也降低索引列插入、删除、更新的速度，索引维护需要代价。索引涉及的理论知识有<strong>二分查找法、哈希表及 B+Tree</strong>。</p>
<p><strong>二分查找法</strong></p>
<p>二分查找法也叫作<strong>折半查找法</strong>，它是在有序数组中查找指定数据的搜索算法。</p>
<ul>
<li>优点：等值查询、范围查询性能优秀</li>
<li>缺点：更新数据、新增数据、删除数据维护成本高</li>
</ul>
<p>哈希表 和 B+Tree 在《数据结构与算法》中已有介绍，这里不再赘述。</p>
<h4 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h4><p>对于索引数据结构的选择其本质是贴合当前数据读写的硬件环境选择一个优秀的数据结构进行数据存储及遍历，在数据库中大部分索引都是通过 <strong>B+Tree</strong> 来实现的。当然也涉及其他数据结构，<strong>在 MySQL 中除了 B+Tree 索引外我们还需要关注下 Hash 索引。</strong></p>
<h5 id="Hash索引"><a href="#Hash索引" class="headerlink" title="Hash索引"></a>Hash索引</h5><p><strong>哈希表是数据库中哈希索引的基础，是根据键值 &lt;key,value&gt; 存储数据的结构</strong>。简单说，哈希表是使用哈希函数将索引列计算到桶或槽的数组，实际存储是根据哈希函数将 key 换算成确定的存储位置，并将 value 存放到该数组位置上。访问时，只需要输入待查找的 key，即可通过哈希函数计算得出确定的存储位置并读取数据。</p>
<p>例如：姓名作为 key，通过哈希函数对姓名字段数据进行计算，得到<strong>哈希码</strong>并存放到桶或槽的数组中，同时存放指向真实数据行的<strong>指针</strong>作为 value，形成哈希表。哈希索引只存储哈希值和行指针，不存储实际字段值，所以其结构紧凑，查询速度也非常快。</p>
<p><strong>哈希索引的应用场景是只在对哈希索引列的等值查询才有效。</strong>包括 =、IN()、&lt;=&gt; （安全等于， select null &lt;=&gt; null 和 select null=null 是不一样的结果) ，不支持范围查询。</p>
<p><strong>Hash碰撞</strong></p>
<p><strong>Hash 碰撞</strong>是指不同索引列值计算出相同的哈希码。</p>
<p>对于 Hash 碰撞通用的处理方法是使用链表，将 Hash 冲突碰撞的元素形成一个链表，发生冲突时在链表上进行二次遍历找到数据。这类似于<strong>HashMap</strong> 实现原理。</p>
<p>在 MySQL 中主要有下列三种Hash索引：</p>
<ul>
<li>Memory 存储引擎原生支持的 Hash 索引</li>
<li>InnoDB 自适应哈希索引。</li>
<li>NDB 集群的哈希索引。</li>
</ul>
<p><strong>InnoDB 自适应哈希索引</strong></p>
<p>InnoDB 自适应哈希索引是为了提升查询效率，InnoDB 存储引擎会监控表上各个索引页的查询，<strong>当 InnoDB 注意到某些索引值访问非常频繁时，会在内存中基于 B+Tree 索引再创建一个哈希索引，使得内存中的 B+Tree 索引具备哈希索引的功能，即能够快速定值访问频繁访问的索引页。</strong></p>
<p><strong>为什么要为 B+Tree 索引页二次创建自适应哈希索引？</strong></p>
<p>因为 B+Tree 索引的查询效率取决于 B+Tree 的高度，在数据库系统中通常 B+Tree 的高度为 3～4 层，所以访问数据需要做 3～4 次的查询。而 Hash 索引访问通常一次查找就能定位数据（无 Hash 碰撞的情况），其等值查询场景 Hash 索引的查询效率要优于 B+Tree。</p>
<p>自适应哈希索引的建立使得 InnoDB 存储引擎能自动根据索引页访问的频率和模式自动地为某些热点页建立哈希索引来加速访问。 InnoDB 自适应哈希索引的功能，用户只能选择开启或关闭功能，无法进行人工干涉。</p>
<h5 id="B-Tree-索引"><a href="#B-Tree-索引" class="headerlink" title="B+Tree 索引"></a><strong>B+Tree 索引</strong></h5><p>MySQL 数据库中讨论索引时，如果没有明确指定类型，则默认是指使用 B+Tree 数据结构进行存储，其说法等价于 B+Tree、B-Tree、BTREE（看到创建索引语句为 BTREE 也不要惊讶，等同于 B+Tree）。</p>
<img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_08.png" alt="B+Tree索引" style="zoom:67%;">

<p>B+Tree 索引能够快速访问数据，就是因为存储引擎可以不再需要通过全表扫描来获取数据，而是从索引的根结点（通常在内存中）开始进行二分查找，根节点的槽中都存放了指向子节点的指针，存储引擎根据这些指针能够快速遍历数据。例如，通过页面号为 20 的根节点可以快速得知 Key&lt;10 的数据在 pageno 33 的页面，key在 [10,16) 范围的数据在 pageno 56 的页面。 叶子节点存放的 &lt;key+data&gt; ，对于真正要存放哪些数据还得取决于该 B+Tree 是<strong>聚簇索引（Clustered Index）</strong>还是<strong>辅助索引（Secondary Index）</strong>。</p>
<h4 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h4><p><strong>在 MySQL 中，索引是在存储引擎层而非服务器层实现</strong>。</p>
<p>在 MySQL 中不同存储引擎间支持的常见索引类型有：</p>
<ul>
<li>哈希索引（Memory/InnoDB adaptive Hash index/NDB）   —  InnoDB 支持</li>
<li>B+Tree 索引（MyISAM/InnoDB）—  InnoDB 支持</li>
<li>全文索引（MyISAM/InnoDB）—  InnoDB 支持</li>
<li>空间索引（MyISAM R-Tree）</li>
<li>分形树索引（TokuDB Fractal Tree Index）</li>
</ul>
<p>索引<strong>通常可以分为两大类</strong>：</p>
<ul>
<li><p><strong>主键索引（聚簇索引）</strong>：<strong>聚簇索引并不是一种单独的索引类型，而是一种数据存储方式</strong>，它表示表中的数据按照主键顺序存储，是索引组织表。InnoDB 的聚簇索引就是按照主键顺序构建 B+Tree，B+Tree 的叶子节点就是行记录，<strong>数据行和主键值紧凑地存储在一起。 这也意味着 InnoDB 的主键索引就是数据表本身，它按主键顺序存放了整张表的数据。</strong></p>
<p>对于没有指定主键的表，InnoDB 会自己<strong>选择合适字段为主键</strong>，<strong>顺序为：显式主键，第一个唯一索引（要求唯一索引所有列都非 NULL）；内置的 6 字节 ROWID（隐藏列）。</strong></p>
</li>
<li><p><strong>辅助索引（非聚簇索引）</strong>：也叫作二级索引，只是根据索引列构建 B+Tree，但在 B+Tree 的每一行都存了主键信息，加速回表操作。 聚簇索引占用的空间就是整个表数据量的大小，而二级索引会比聚簇索引小很多， 通常创建辅助索引就是为了提升查询效率。</p>
</li>
</ul>
<p>根据索引<strong>列个数和功能描述不同</strong>索引也可以分为：</p>
<ul>
<li><strong>联合索引</strong>：联合索引是指在多个字段联合组建索引的。</li>
<li><strong>覆盖索引</strong>：<strong>一个索引包含了所有需要查询的字段的值，就称为覆盖索引</strong>。当通过索引即可查询到所有记录，不需要回表到聚簇索引时，这类索引也叫作覆盖索引。主键查询是天然的覆盖索引，联合索引可以是覆盖索引。通常在查看执行计划时， Extra 列为 Using index 则表示优化器使用了覆盖索引。</li>
</ul>
<p><strong>通常建议优先考虑使用覆盖索引，这是因为如果 SQL 需要查询辅助索引中不包含的数据列时，就需要先通过辅助索引查找到主键值，然后再回表通过主键查询到其他数据列（即回表查询），需要查询两次。而覆盖索引能从索引中直接获取查询需要的所有数据，从⽽避免回表进行二次查找，节省IO，效率较⾼。</strong></p>
<h4 id="索引基础知识"><a href="#索引基础知识" class="headerlink" title="索引基础知识"></a>索引基础知识</h4><ul>
<li><p><strong>谓词</strong>：谓词本身就是条件表达式，通俗讲就是过滤字段，例如：select * from user where user_name=’zhangsan’ and age = 18;  </p>
<ul>
<li>简单谓词：user_name 和 age。</li>
<li>组合谓词：user_name and age</li>
</ul>
</li>
<li><p><strong>过滤因子</strong>：过滤因子直接描述了谓词的选择性，表示满足谓词条件的记录行数所占比例，过滤因子越小意味着能过滤越多数据，你需要在这类谓词字段上创建索引。</p>
<ul>
<li><strong>简单谓词的过滤因子 = 谓词结果集的数量 / 表总行数</strong></li>
<li><strong>组合谓词的过滤因子 = 谓词 1 的过滤因子 × 谓词 2 的过滤因子</strong> </li>
</ul>
</li>
<li><p><strong>基数（Cardinality）</strong>：基数是<strong>某个键值去重后的行数</strong>， 索引列不重复记录数量的预估值，MySQL 优化器会依赖于它。</p>
</li>
<li><p><strong>选择率</strong>：<strong>= 基数 / 表总行数</strong>，选择率越接近 1 则越适合创建索引，例如主键和唯一键的选择率都是 1。</p>
</li>
<li><p><strong>回表</strong>：回表是指无法通过索引扫描访问所有数据，需要回到主表进行数据扫描并返回。</p>
</li>
<li><p><strong>Cardinality</strong>：Cardinality 能快速告知字段的选择性，高选择性字段有利于创建索引。优化器在选择执行计划时会依赖该信息，通常这类信息也叫作统计信息，数据库中对于统计信息的采集是在存储引擎层进行的。</p>
<p>执行 <code>show index from table_name</code> 会看到 Cardinality，同时也会触发 MySQL 数据库对 Cardinaltiy 值的统计。</p>
</li>
</ul>
<h4 id="索引使用细节"><a href="#索引使用细节" class="headerlink" title="索引使用细节"></a>索引使用细节</h4><ul>
<li><p>创建索引后通过查看执行 SQL 语句的执行计划即可知道 SQL 语句是否走索引。执行计划重点关注跟索引相关的关键项，有 type、possible_keys、key、key_len、ref、Extra 等。</p>
<img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_09.png" alt="查看执行计划" style="zoom:67%;">

<ul>
<li><strong>possible_keys</strong> 表示查询可能使用的索引</li>
<li><strong>key</strong>表示真正实际使用的索引</li>
<li><strong>key_len</strong> 表示使用索引字段的长度</li>
</ul>
</li>
<li><p>当索引选择联合索引时，通过<strong>计算 key_len 来了解有效索引长度对索引优化非常重要</strong>，key_len 表示得到结果集所使用的选择索引的长度[字节数]，不包括 order by。key_len 计算规则从两个方面考虑：</p>
<ul>
<li>索引字段的<strong>数据类型</strong>：根据索引字段的定义可以分为<strong>变长</strong>（比如 Varchar，除了是否为空的标记外，还需要有长度信息，需要占用 2 个字节）和<strong>定长</strong>（比如 char、int、datetime，需要有是否为空的标记，这个标记需要占用 1 个字节）两种数据类型；</li>
<li>字段所使用的<strong>字符集</strong>：表所使用的字符集，不同的字符集计算的 key_len 不一样，例如，GBK 编码的是一个占用 2 个字节大小的字符，UTF8 编码的是一个占用 3 个字节大小的字符。</li>
</ul>
</li>
</ul>
<p>举例：</p>
<ul>
<li><strong>Varchr(10) 变长字段且允许 NULL</strong>：10*(Character Set：utf8=3，gbk=2，latin1=1) + 1（标记是否为 NULL 需要 1 个字节）+ 2（变长字段存储长度信息需要 2 个字节）。</li>
<li><strong>Varchr(10) 变长字段且不允许 NULL</strong>：10*(Character Set：utf8=3，gbk=2，latin1=1) + 2（变长字段存储长度信息需要2个字节），非空不再需要占用字节来标记是否为空。</li>
<li><strong>Char(10) 固定字段且允许 NULL</strong>：10*(Character Set：utf8=3，gbk=2，latin1=1) + 1（标记是否为 NULL 需要 1 个字节）。 *</li>
<li><strong>Char(10) 固定字段且不允许 NULL</strong>：10*(Character Set：utf8=3，gbk=2，latin1=1)，非空不再需要占用字节来标记是否为空。</li>
</ul>
<p><strong>最左前缀匹配原则</strong></p>
<p>通过 key_len 计算也帮助我们了解索引的最左前缀匹配原则。</p>
<p>最左前缀匹配原则是指在使用 B+Tree 联合索引进行数据检索时，MySQL 优化器会读取谓词（过滤条件）并按照联合索引字段创建顺序一直向右匹配直到遇到范围查询或非等值查询后停止匹配，此字段之后的索引列不会被使用，这时计算 key_len 可以分析出联合索引实际使用了哪些索引列。</p>
<h4 id="索引设计"><a href="#索引设计" class="headerlink" title="索引设计"></a>索引设计</h4><ul>
<li><p>首先<strong>定位由于索引不合适或缺少索引而导致的慢查询</strong>。慢查询日志分析，抓出运行慢的 SQL 进行分析，也可以借助第三方工具例如 Arkcontrol 慢查询分析系统进行慢查询采集和分析。在分析慢查询时进行参数最差输入，同时，对 SQL 语句的谓词进行过滤因子、基数、选择率和 SQL 查询回表情况的分析。</p>
</li>
<li><p><strong>设计索引</strong>。创建索引规范：</p>
<ul>
<li>单张表的索引数量不超过 5 个，单个索引中的字段数不超过 5 个。</li>
<li>表必需有主键，推荐使⽤ UNSIGNED 自增列作为主键。</li>
<li>唯一键由 3 个以下字段组成，并且在字段都是整形时，可使用唯一键作为主键。</li>
<li>禁止冗余索引、禁止重复索引，索引维护需要成本，新增索引时优先考虑基于现有索引进行 rebuild。</li>
<li>联表查询时，JOIN 列的数据类型必须相同，并且要建⽴索引。</li>
<li>不在低基数列上建⽴索引。</li>
</ul>
</li>
<li><p>创建<strong>索引策略</strong>：</p>
<ul>
<li>优先为搜索列、排序列、分组列创建索引，必要时加入查询列创建覆盖索引；</li>
<li>计算字段列基数和选择率，选择率越接近于 1 越适合创建索引；</li>
<li>索引选用较小的数据类型（整型优于字符型），字符串可以考虑前缀索引；</li>
<li>不要建立过多索引，优先基于现有索引调整顺序；</li>
<li>参与比较的字段类型保持匹配并创建索引。例如“性别”。 在低基数列上创建的索引查询相比全表扫描不一定有性能优势，特别是当存在回表成本时。</li>
<li>选择区分度（选择率）大的列建立索引。组合索引中，区分度（选择率）大的字段放在最前面。</li>
<li>对过长的 Varchar 段建立索引。建议优先考虑前缀索引，或添加 CRC32 或 MD5 伪列并建⽴索引。 </li>
<li>合理创建联合索引，(a,b,c) 相当于 (a) 、(a,b) 、(a,b,c)。 </li>
<li>合理使用覆盖索引减少IO，避免排序。</li>
</ul>
</li>
<li><p><strong>调优索引</strong></p>
<p>分析执行计划；更新统计信息（Analyze Table）；Hint优化，方便调优（FORCE INDEX、USE INDEX、IGNORE INDEX、STRAIGHT_JOIN）；检查连接字段数据类型、字符集；避免使用类型转换；关注 optimizer_switch，重点关注索引优化特性 MRR（Multi-Range Read）和 ICP（Index Condition Pushdown）。</p>
</li>
</ul>
<h3 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h3><p>首先需要了解查询优化器处理 SQL 的全过程。以 SELECT 的 SQL 的执行过程为例：</p>
<img src="/2021/03/15/%E8%AF%A6%E8%A7%A3Mysql%EF%BC%88%E4%B8%80%EF%BC%89/mysql_10.png" alt="Mysql SQL执行过程" style="zoom:80%;">

<ul>
<li>客户端发送一条 SELECT 查询给服务器；</li>
<li>服务器先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段；</li>
<li>服务器进行 SQL 解析、预处理、再由查询优化器生成对应的执行计划；</li>
<li>MySQL 根据优化器生成的执行计划，调用存储引擎的 API 来执行查询；</li>
<li>将结果返回给客户端，同时也会放入查询缓存中。</li>
</ul>
<p><strong>MySQL</strong> 采用<strong>基于开销的优化器</strong>，以确定处理查询的最佳方式，也就是说<strong>执行查询之前，都会先选择一条自以为最优的方案。</strong></p>
<h4 id="执行计划分析"><a href="#执行计划分析" class="headerlink" title="执行计划分析"></a><strong>执行计划分析</strong></h4><ul>
<li><strong>查看 SQL 执行计划</strong>：<ul>
<li>explain SQL；</li>
<li>desc 表名；</li>
<li>show create table 表名。</li>
</ul>
</li>
<li><strong>通过 Profile 定位 QUERY 代价消耗</strong>：<ul>
<li>set profiling=1；</li>
<li>执行 SQL；</li>
<li>show profiles; </li>
<li>获取 Query_ID。</li>
<li>show profile for query Query_ID; </li>
<li>查看详细的 profile 信息。</li>
</ul>
</li>
<li><strong>通过 Optimizer Trace 表查看 SQL 执行计划树</strong>：<ul>
<li>set session optimizer_trace=’enabled=on’；</li>
<li>执行 SQL；</li>
<li>查询 information_schema.optimizer_trace 表，获取 SQL 查询计划树；</li>
<li>set session optimizer_trace=‘enabled=off’；开启此项影响性能，记得用后关闭。</li>
</ul>
</li>
</ul>
<p><strong>MySQL</strong> 可以通过设置一些参数，将<strong>运行时间长或者非索引查找的 SQL 记录到慢查询文件</strong>中。可以分析慢查询文件中的 SQL，有针对性的进行优化。</p>
<ul>
<li>参数 slow_query_log，表示是否开启慢查询日志，ON 或者 1 表示开启，OFF 或者 0 表示关闭。</li>
<li>参数 long_query_time，设置慢查询的阈值，MySQL 5.7 版本支持微秒级。</li>
<li>参数 slow_query_log_file，慢查询文件的存放路径。</li>
<li>参数 log_queries_not_using_indexes，表示是否将非索引查找的 SQL 也记录到慢查询文件中。</li>
<li>参数 log_throttle_queries_not_using_indexes，表示每分钟记录到慢查询文件中未使用索引的 SQL 语句上限，0 表示没限制。</li>
<li>参数 max_execution_time，用来控制 SELECT 语句的最大执行时间，单位毫秒，超过此值MySQL 自动 kill 掉该查询。</li>
</ul>
<p>分析慢查询常用的工具有：</p>
<ul>
<li>explain；</li>
<li>Mysqldumpslow，官方慢查询分析工具；</li>
<li><strong>pt-query-digest</strong>，Percona 公司开源的慢查询分析工具；</li>
<li>vc-mysql-sniffer，第三方的慢查询抓取工具；</li>
<li>pt-kill，Percona 公司开源的慢查询 kill 工具，常用于生产环境的过载保护。</li>
</ul>
<h4 id="SQL优化"><a href="#SQL优化" class="headerlink" title="SQL优化"></a>SQL优化</h4><p>考虑因素：</p>
<ul>
<li><strong>全表扫描还是索引扫描</strong>。对于小表来说，二者 IO 调用次数和返回时间相差不大；但对于大表，如果全表扫描，那么查询返回的时间就会很长，就需要使用索引扫描加快查询速度。但同时应该考虑索引数量不宜过多。</li>
<li>如何创建索引，在哪些列上建立索引。</li>
<li>创建索引以后，尽量不要过频修改。</li>
<li>SQL 中关联列字段类型不一致或者传入的参数类型与字段类型不匹配的情况，这样就会导致无法使用索引；</li>
<li>索引列上使用函数也不会涉及索引。</li>
<li>全模糊匹配的查询无法使用索引。</li>
<li>order by/group by 的 SQL 涉及排序，尽量在索引中包含排序字段，并让排序字段的排序顺序与索引列中的顺序相同，这样可以避免排序或减少排序次数。</li>
<li>复杂查询还是简单查询。</li>
</ul>
<blockquote>
<p>笔记来源：</p>
<p>Mysql锁总结：<a href="https://zhuanlan.zhihu.com/p/29150809" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29150809</a></p>
<p>周彦伟 老师的 《高性能Mysql实战》课程</p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Mysql/" rel="tag">Mysql</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0/" rel="tag">面试复习</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-消息队列" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/03/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"
    >消息队列</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/03/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" class="article-date">
  <time datetime="2021-03-15T08:09:05.000Z" itemprop="datePublished">2021-03-15</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><ul>
<li>JMS（Java消息服务规范）：特点、消息模型、消费方式、编程模型</li>
<li>使用场景：应用解耦合、服务通信、异步任务、削峰填谷、消息广播</li>
<li>消息协议：JMS、AMQP</li>
<li>常用队列：RabbitMQ、ActiveMQ、RocketMQ、Kafka（优劣对比）</li>
</ul>
<h2 id="Java-消息服务接口（JMS）"><a href="#Java-消息服务接口（JMS）" class="headerlink" title="Java 消息服务接口（JMS）"></a>Java 消息服务接口（JMS）</h2><blockquote>
<p><strong>JMS</strong> 即 <strong>Java消息服务（Java Message Service）应用程序接口</strong>，是一个<a href="https://baike.baidu.com/item/Java平台" target="_blank" rel="noopener">Java平台</a>中关于面向<a href="https://baike.baidu.com/item/消息中间件/5899771" target="_blank" rel="noopener">消息中间件</a>（MOM）的<a href="https://baike.baidu.com/item/API/10154" target="_blank" rel="noopener">API</a>，用于在两个应用程序之间，或<a href="https://baike.baidu.com/item/分布式系统/4905336" target="_blank" rel="noopener">分布式系统</a>中发送消息，进行<a href="https://baike.baidu.com/item/异步通信/2273903" target="_blank" rel="noopener">异步通信</a>。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。</p>
<p>《百度百科》</p>
</blockquote>
<p><strong>JMS</strong>只是 <strong>Java EE</strong> 中定义的一组标准 <strong>API</strong>，它自身并不是一个消息服务系统，它是消息传送服务的一个<strong>抽象</strong>，也就是说它定义了消息传送的接口而并没有具体实现。</p>
<p>JMS其实就是一个<code>Java</code>业界的<code>标准规范</code>而已，提供了一些编程接口给第三方去实现。包括消息产生、发送、读取、接收等。像<code>ActiveMQ</code>、<code>RocketMQ</code>之类的框架都是针对这个标准去实现的。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li><strong>异步</strong>：规范（标准）指出：消息的发送应该是异步的、非阻塞的。也就是说消息的发送者发送完消息后就直接返回了，不需要等待接收者返回后才能返回，发送者和接收者可以说是互不影响，减轻或消除系统瓶颈，实现系统之间去除耦合，提高系统的整体可伸缩性和灵活性。</li>
<li><strong>可靠</strong>：JMS保证消息只会递送一次。</li>
</ul>
<h3 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h3><ul>
<li><strong>Point-to-Point(P2P)（点对点）</strong></li>
<li><strong>Publish/Subscribe(Pub/Sub) （发布/订阅模式）</strong></li>
</ul>
<h4 id="Point-to-Point-P2P"><a href="#Point-to-Point-P2P" class="headerlink" title="Point-to-Point(P2P)"></a>Point-to-Point(P2P)</h4><p><img src="/2021/03/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/message_queue_01.png" alt="点对点消息模型"></p>
<p>在<strong>P2P通信模式</strong>中，应用程序由消息队列，发送方，接收方组成。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。</p>
<ul>
<li>每个消息只有一个消费者；</li>
<li>发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列；</li>
<li>发送方不管是否在发送消息，接收方都可以从消息队列中去读消息；</li>
<li>接收方在接收完消息之后，需要向消息队列应答成功。</li>
</ul>
<h4 id="Publish-Subscribe-Pub-Sub"><a href="#Publish-Subscribe-Pub-Sub" class="headerlink" title="Publish/Subscribe(Pub/Sub)"></a>Publish/Subscribe(Pub/Sub)</h4><img src="/2021/03/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/message_queue_02.png" alt="订阅发布模型" style="zoom:115%;">



<p>在<strong>发布/订阅消息模型</strong>中，发布者发布一个消息，该消息通过<strong>topic</strong>传递给所有的客户端。</p>
<p>该模式下，发布者与订阅者都是匿名的，即发布者与订阅者都不知道对方是谁。并且可以动态的发布与订阅<strong>Topic</strong>。<strong>Topic</strong>主要用于保存和传递消息，且会一直保存消息直到消息被传递给客户端。</p>
<ul>
<li>一个消息可以传递个多个订阅者；</li>
<li>发布者与订阅者具有时间约束，针对某个主题（<strong>Topic</strong>）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。</li>
<li>为了缓和这样严格的时间相关性，<strong>JMS</strong>允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。</li>
</ul>
<h3 id="消息的消费方式"><a href="#消息的消费方式" class="headerlink" title="消息的消费方式"></a>消息的消费方式</h3><ul>
<li><strong>同步</strong>：消费者通过调用<code>receive</code>方法显式地从<code>Destination</code>中获取消息。该<code>receive</code>方法在消息到达之前会一直阻塞，或者如果消息没有在指定的时间限制内到达，则可以超时。</li>
<li><strong>异步</strong>：使用异步方式接收消息的话，消息订阅者需注册一个消息监听者，类似于事件监听器，只要消息到达，JMS服务提供者会通过调用监听器的<code>onMessage()</code>递送消息</li>
</ul>
<h3 id="JMS编程模型"><a href="#JMS编程模型" class="headerlink" title="JMS编程模型"></a>JMS编程模型</h3><p><strong>ConnectionFactory</strong></p>
<p>创建 Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。</p>
<p><strong>Destination</strong></p>
<p>Destination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的Destination是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的Destination也是某个队列或主题（即消息来源）。</p>
<p>所以，Destination实际上就是两种类型的对象：Queue、Topic可以通过JNDI来查找Destination。</p>
<p><strong>Connection</strong></p>
<p>Connection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。</p>
<p><strong>Session</strong></p>
<p>Session是我们操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当我们需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。</p>
<p><strong>消息的生产者</strong></p>
<p>消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。</p>
<p><strong>消息消费者</strong></p>
<p>消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。</p>
<p><strong>MessageListener</strong></p>
<p>消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。</p>
<h2 id="消息中间件"><a href="#消息中间件" class="headerlink" title="消息中间件"></a>消息中间件</h2><p>消息队列中间件是分布式系统中重要的组件，主要解决<strong>应用解耦，异步消息，流量削锋</strong>等问题，实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，RocketMQ，Kafka等。</p>
<h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p>RabbitMQ于2007年发布，是一个在<strong>AMQP</strong>(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。</p>
<h4 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h4><ol>
<li>可靠性：提供了多种技术可以让你在性能和可靠性之间进行权衡。这些技术包括持久性机制、投递确认、发布者证实和高可用性机制；</li>
<li>灵活的路由：消息在到达队列前是通过交换机进行路由的。RabbitMQ为典型的路由逻辑提供了多种内置交换机类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做RabbitMQ的插件来使用；</li>
<li>消息集群：在相同局域网中的多个RabbitMQ服务器可以聚合在一起，作为一个独立的逻辑代理来使用；</li>
<li>队列高可用：队列可以在集群中的机器上进行镜像，以确保在硬件问题下还保证消息安全；</li>
<li>支持多种协议：支持多种消息队列协议；</li>
<li>支持多种语言：用Erlang语言编写，支持只要是你能想到的所有编程语言；</li>
<li>管理界面：RabbitMQ有一个易用的用户界面，使得用户可以监控和管理消息Broker的许多方面；</li>
<li>跟踪机制：如果消息异常，RabbitMQ 提供消息跟踪机制，使用者可以找出发生了什么；</li>
<li>插件机制：提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。</li>
</ol>
<h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ol>
<li>由于Erlang语言的特性，消息队列性能较好，支持高并发；</li>
<li>健壮、稳定、易用、跨平台、支持多种语言、文档齐全；</li>
<li>有消息确认机制和持久化机制，可靠性高；</li>
<li>高度可定制的路由；</li>
<li>管理界面较丰富，在互联网公司也有较大规模的应用，社区活跃度高。</li>
</ol>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ol>
<li>尽管结合 Erlang 语言本身的并发优势，性能较好，但是不利于做二次开发和维护；</li>
<li>实现了代理架构，意味着消息在发送到客户端之前可以在中央节点上排队。此特性使得RabbitMQ易于使用和部署，但是使得其运行速度较慢，因为中央节点 增加了延迟，消息封装后也比较大；需要学习比较复杂的接口和协议，学习和维护成本较高。</li>
</ol>
<h3 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h3><p>ActiveMQ是由Apache出品，ActiveMQ是一个完全支持JMS1.1和J2EE 1.4规范的JMS Provider实现。它非常快速，支持多种语言的客户端和协议，而且可以非常容易的嵌入到企业的应用环境中，并有许多高级功能。</p>
<h4 id="主要特性-1"><a href="#主要特性-1" class="headerlink" title="主要特性"></a>主要特性</h4><ol>
<li>服从JMS规范：JMS 规范提供了良好的标准和保证，包括：同步 或 异步 的消息分发，一次和仅一次的消息分发，消息接收和订阅等等。遵从JMS规范的好处在于，不论使用什么JMS实现提供者，这些基础特性都是可用的；</li>
<li>连接灵活性：ActiveMQ提供了广泛的连接协议，支持的协议有：HTTP/S，IP多播，SSL，TCP，UDP等等。对众多协议的支持让ActiveMQ拥有了很好的灵活性；</li>
<li>支持的协议种类多：OpenWire、STOMP、REST、XMPP、AMQP；</li>
<li>持久化插件和安全插件：ActiveMQ提供了多种持久化选择。而且，ActiveMQ的安全性也可以完全依据用户需求进行自定义鉴权和授权；</li>
<li>支持的客户端语言种类多：除了Java之外，还有：C/C++，.NET，Perl，PHP，Python，Ruby；</li>
<li>代理集群：多个ActiveMQ代理可以组成一个集群来提供服务；</li>
<li>异常简单的管理：ActiveMQ是以开发者思维被设计的。所以，它并不需要专门的管理员，因为它提供了简单又使用的管理特性。有很多中方法可以监控ActiveMQ不同层面的数据，包括使用在JConsole或者在ActiveMQ的WebConsole中使用JMX。通过处理JMX的告警消息，通过使用命令行脚本，甚至可以通过监控各种类型的日志。</li>
</ol>
<h5 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h5><ol>
<li>跨平台(JAVA编写与平台无关，ActiveMQ几乎可以运行在任何的JVM上)；</li>
<li>可以用JDBC：可以将数据持久化到数据库。虽然使用JDBC会降低ActiveMQ的性能，但是数据库一直都是开发人员最熟悉的存储介质；</li>
<li>支持JMS规范：支持JMS规范提供的统一接口;</li>
<li>支持自动重连和错误重试机制；</li>
<li>有安全机制：支持基于shiro，jaas等多种安全配置机制，可以对Queue/Topic进行认证和授权；</li>
<li>监控完善：拥有完善的监控，包括WebConsole，JMX，Shell命令行，Jolokia的RESTful API；</li>
<li>界面友善：提供的WebConsole可以满足大部分情况，还有很多第三方的组件可以使用，比如hawtio；</li>
</ol>
<h5 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h5><ol>
<li>社区活跃度不及RabbitMQ高；</li>
<li>根据其他用户反馈，会出莫名其妙的问题，会丢失消息；</li>
<li>目前重心放到activemq6.0产品Apollo，对5.x的维护较少；</li>
<li>不适合用于上千个队列的应用场景；</li>
</ol>
<h3 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h3><p>RocketMQ出自阿里的开源产品，用Java语言实现，在设计时参考了Kafka，并做出了自己的一些改进，消息可靠性上比Kafka更好。RocketMQ在阿里内部被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。</p>
<h4 id="主要特性-2"><a href="#主要特性-2" class="headerlink" title="主要特性"></a>主要特性</h4><ol>
<li>基于 队列模型：具有高性能、高可靠、高实时、分布式等特点；</li>
<li>Producer、Consumer、队列都支持分布式；</li>
<li>Producer向一些队列轮流发送消息，队列集合称为Topic。Consumer如果做广播消费，则一个Consumer实例消费这个Topic对应的所有队列；如果做集群消费，则多个Consumer 实例平均消费这个Topic对应的队列集合；</li>
<li>能够保证严格的消息顺序；</li>
<li>提供丰富的消息拉取模式；</li>
<li>高效的订阅者水平扩展能力；</li>
<li>实时的消息订阅机制；</li>
<li>亿级消息堆积 能力；</li>
<li>较少的外部依赖。</li>
</ol>
<h5 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h5><ol>
<li>单机支持1万以上持久化队列；</li>
<li>RocketMQ的所有消息都是持久化的，先写入系统PAGECACHE，然后刷盘，可以保证内存与磁盘都有一份数据，而访问时，直接从内存读取。</li>
<li>模型简单，接口易用（JMS的接口很多场合并不太实用）；</li>
<li>性能非常好，可以允许大量堆积消息在Broker中；</li>
<li>支持多种消费模式，包括集群消费、广播消费等；</li>
<li>各个环节分布式扩展设计，支持主从和高可用；</li>
<li>开发度较活跃，版本更新很快。</li>
</ol>
<h5 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h5><ol>
<li>支持的 客户端语言不多，目前是Java及C++，其中C++还不成熟；</li>
<li>RocketMQ社区关注度及成熟度也不及前两者；</li>
<li>没有Web管理界面，提供了一个 CLI (命令行界面) 管理工具带来查询、管理和诊断各种问题；</li>
<li>没有在MQ核心里实现JMS等接口；</li>
</ol>
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p>Apache Kafka是一个分布式消息发布订阅系统。它最初由LinkedIn公司基于独特的设计实现为一个分布式的日志提交系统(a distributed commit log)，之后成为Apache项目的一部分。Kafka性能高效、可扩展良好并且可持久化。它的分区特性，可复制和可容错都是其不错的特性。</p>
<h4 id="主要特性-3"><a href="#主要特性-3" class="headerlink" title="主要特性"></a>主要特性</h4><ol>
<li>快速持久化：可以在O(1)的系统开销下进行消息持久化；</li>
<li>高吞吐：在一台普通的服务器上既可以达到10W/s的吞吐速率；</li>
<li>完全的分布式系统：Broker、Producer和Consumer都原生自动支持分布式，自动实现负载均衡；</li>
<li>支持同步和异步复制两种高可用机制；</li>
<li>支持数据批量发送和拉取；</li>
<li>零拷贝技术(zero-copy)：减少IO操作步骤，提高系统吞吐量；</li>
<li>数据迁移、扩容对用户透明；</li>
<li>无需停机即可扩展机器；</li>
<li>其他特性：丰富的消息拉取模型、高效订阅者水平扩展、实时的消息订阅、亿级的消息堆积能力、定期删除机制；</li>
</ol>
<h5 id="优点-3"><a href="#优点-3" class="headerlink" title="优点"></a>优点</h5><ol>
<li>客户端语言丰富：支持Java、.Net、PHP、Ruby、Python、Go等多种语言；</li>
<li>高性能：单机写入TPS约在100万条/秒，消息大小10个字节；</li>
<li>提供完全分布式架构，并有replica机制，拥有较高的可用性和可靠性，理论上支持消息无限堆积；</li>
<li>支持批量操作；</li>
<li>消费者采用Pull方式获取消息。消息有序，通过控制能够保证所有消息被消费且仅被消费一次；</li>
<li>有优秀的第三方KafkaWeb管理界面Kafka-Manager；</li>
<li>在日志领域比较成熟，被多家公司和多个开源项目使用。</li>
</ol>
<h5 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h5><ol>
<li>Kafka单机超过64个队列/分区时，Load时会发生明显的飙高现象。队列越多，负载越高，发送消息响应时间变长；</li>
<li>使用短轮询方式，实时性取决于轮询间隔时间；</li>
<li>消费失败不支持重试；</li>
<li>支持消息顺序，但是一台代理宕机后，就会产生消息乱序；</li>
<li>社区更新较慢。</li>
</ol>
<p><img src="/2021/03/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/message_queue_03.png" alt="消息中间件对比图"></p>
<blockquote>
<p>笔记来源：</p>
<p><a href="https://www.cnblogs.com/jaycekon/p/6220200.html" target="_blank" rel="noopener">https://www.cnblogs.com/jaycekon/p/6220200.html</a></p>
<p><a href="https://my.oschina.net/blogByRzc/blog/3012251" target="_blank" rel="noopener">https://my.oschina.net/blogByRzc/blog/3012251</a></p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag">消息队列</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0/" rel="tag">面试复习</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-缓存（三）-Redis" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/"
    >缓存（三）- Redis</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/" class="article-date">
  <time datetime="2021-03-15T07:49:36.000Z" itemprop="datePublished">2021-03-15</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="缓存之Redis（三）"><a href="#缓存之Redis（三）" class="headerlink" title="缓存之Redis（三）"></a>缓存之Redis（三）</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote>
<p>Redis（Remote Dictionary Server )，即远程字典服务，是一个开源的使用ANSI <a href="https://baike.baidu.com/item/C语言" target="_blank" rel="noopener">C语言</a>编写、支持网络、可基于内存亦可持久化的日志型、Key-Value<a href="https://baike.baidu.com/item/数据库/103728" target="_blank" rel="noopener">数据库</a>，并提供多种语言的API。它的所有数据结构都存在内存中，可以用作缓存、数据库和消息中间件。</p>
<p>一个 Redis 实例可以有多个存储数据的字典，客户端可以通过 select 来选择字典即 DB 进行数据存储。</p>
<p>– 百度百科</p>
</blockquote>
<p><strong>特性</strong>：</p>
<ul>
<li><p>同为 key-value 存储组件，Memcached 只能支持<strong>二进制字节块</strong>这一种数据类型。而 Redis 的数据类型却丰富的多，它具有 <strong>8 种核心数据类型</strong>，每种数据类型都有一系列操作指令对应。</p>
</li>
<li><p>Redis <strong>性能很高</strong>，单线程压测可以达到 10~11w 的 QPS。单线程性能高是因为没有线程切换，线程间通信，线程竞争，不需要加锁，没有上下文切换开销，所有数据操作都是在内存中操作，所以 Redis 的性能很高。</p>
</li>
<li><p><strong>可持久化</strong>，提供俩种持久化方式：</p>
<ul>
<li>快照方式：将某时刻所有数据都写入硬盘的 <strong>RDB</strong> 文件</li>
<li>追加文件方式：即将所有写命令都以追加的方式写入硬盘的 <strong>AOF</strong> 文件，AOF 文件会随时间流逝变得越来越大，此时，可以通过 bgrewriteaof 指令，对 AOF 进行重写，只保留数据的最后内容，来大大缩减 AOF 的内容。</li>
</ul>
<p>线上 Redis 一般会<strong>同时使用</strong>两种方式，通过开启 appendonly 及关联配置项，将写命令及时追加到 AOF 文件，同时在每日流量低峰时，通过 bgsave 保存当时所有内存数据快照。 </p>
</li>
<li><p>Redis <strong>支持复制</strong>特性：master-多slave，读写分离，把所有写操作落在 Redis 的 master，所有读操作随机落在 Redis 的多个 slave 。</p>
</li>
<li><p>Redis <strong>支持支持 Lua脚本</strong>：Redis 自 2.6 版本开始支持 Lua，通过支持 client 端自定义的 Lua 脚本，Redis 可以减少网络开销，提升处理性能，还可以把脚本中的多个操作作为一个整体来操作，实现原子性更新。</p>
</li>
<li><p>Redis 还<strong>支持事务</strong>，在 multi 指令后，指定多个操作，然后通过 exec 指令一次性执行，中途如果出现异常，则不执行所有命令操作，否则，按顺序一次性执行所有操作，执行过程中不会执行任何其他指令。</p>
</li>
<li><p>Redis 还<strong>支持 Cluster 特性</strong>，可以通过自动或手动方式，将所有 key 按哈希分散到不同节点，在容量不足时，还可以通过 Redis 的迁移指令，把其中一部分 key 迁移到其他节点。</p>
</li>
</ul>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_20.png" alt="Redis特性" style="zoom:47%;">

<h2 id="Redis-数据类型"><a href="#Redis-数据类型" class="headerlink" title="Redis 数据类型"></a>Redis 数据类型</h2><p> 8 种核心数据类型：</p>
<ul>
<li><strong>string 字符串类型；</strong></li>
<li><strong>list 列表类型；</strong></li>
<li><strong>set 集合类型；</strong></li>
<li><strong>sorted set 有序集合类型；</strong></li>
<li><strong>hash 类型；</strong></li>
<li>bitmap 位图类型； </li>
<li>geo 地理位置类型；</li>
<li>HyperLogLog 基数统计类型。</li>
</ul>
<h3 id="string-字符串"><a href="#string-字符串" class="headerlink" title="string 字符串"></a><strong>string 字符串</strong></h3><p><strong>string</strong> 是 <strong>Redis</strong> 的最<strong>基本数据类型</strong>。可以把它理解为 Mc 中 key 对应的 value 类型。</p>
<ul>
<li><p>string 类型是二进制安全的，即 string 中可以包含任何数据。</p>
</li>
<li><p>Redis 中的普通 string 采用 <strong>raw encoding</strong> 即原始编码方式，该编码方式会<strong>动态扩容</strong>，并通过<strong>提前预分配</strong>冗余空间，来减少内存频繁分配的开销。</p>
</li>
<li><p>在字符串长度小于 1MB 时，按所需长度的 2 倍来分配，超过 1MB，则按照每次额外增加 1MB 的容量来预分配。</p>
</li>
<li><p>Redis 中的<strong>数字也存为 string 类型</strong>，但编码方式跟普通 string 不同，数字<strong>采用整型编码</strong>，字符串内容直接设为整数值的二进制字节序列。</p>
</li>
<li><p>在存储普通字符串，序列化对象，以及计数器等场景时，都可以使用 Redis 的字符串类型，字符串数据类型对应使用的指令包括 set、get、mset、incr、decr 等。</p>
</li>
</ul>
<h3 id="list-列表"><a href="#list-列表" class="headerlink" title="list 列表"></a><strong>list 列表</strong></h3><p>Redis 的 list 列表，是一个<strong>快速双向链表</strong>，存储了一系列的 string 类型的字串值。</p>
<ul>
<li><p>list 中的元素<strong>按照插入顺序排列</strong>。</p>
</li>
<li><p>插入元素的方式，可以通过 <strong>lpush</strong> 将一个或多个元素插入到列表的<strong>头部</strong>，也可以通过 <strong>rpush</strong> 将一个或多个元素插入到队列<strong>尾部</strong>，还可以通过 <strong>lset、linsert</strong> 将元素插入到<strong>指定位置或指定元素的前后</strong>。</p>
</li>
<li><p>list 列表的获取，可以通过 lpop、rpop 从对头或队尾弹出元素，如果队列为空，则返回 nil。</p>
<p>还可以通过 Blpop、Brpop 从队头/队尾阻塞式弹出元素，如果 list 列表为空，没有元素可供弹出，则持续阻塞，直到有其他 client 插入新的元素。这里阻塞弹出元素，可以设置过期时间，避免无限期等待。</p>
<p>list 列表还可以通过 LrangeR 获取队列内指定范围内的所有元素。Redis 中，list 列表的偏移位置都是基于 0 的下标，偏移量也可以是负数。</p>
</li>
<li><p>对于<strong>常规的 pop、push 元素，性能很高，时间复杂度为 O(1)</strong>，因为是列表直接追加或弹出。但对于通过<strong>随机插入、随机删除，以及随机范围获取</strong>，需要轮询列表确定位置，<strong>性能就比较低下</strong>了。</p>
</li>
<li><p>feed timeline（是一种把信息根据时间顺序排序呈现给订阅用户进行消费的形式） 存储时，由于 feed id 一般是递增的，可以直接存为 list，用户发表新 feed，就直接追加到队尾。另外消息队列、热门 feed 等业务场景，都可以使用 list 数据结构。</p>
</li>
</ul>
<h3 id="set-集合"><a href="#set-集合" class="headerlink" title="set 集合"></a><strong>set 集合</strong></h3><p>set 是 string 类型的<strong>无序集合</strong>，set 中的元素是唯一的，即 set 中<strong>不会出现重复的元素</strong>。Redis 中的集合一般是通过 <strong>dict 哈希表实现</strong>的，所以插入、删除，以及查询元素，可以根据元素 hash 值直接定位，时间复杂度为 O(1)。</p>
<p>除了常规的添加、删除、查找元素外，常用 set 指令：</p>
<ul>
<li><p><strong>sismember</strong> 指令判断该 key 对应的 set 数据结构中，是否存在某个元素，如果存在返回 1，否则返回 0；</p>
</li>
<li><p><strong>sdiff</strong> 指令来对多个 set 集合执行差集；</p>
</li>
<li><p><strong>sinter</strong> 指令对多个集合执行交集；</p>
</li>
<li><p><strong>sunion</strong> 指令对多个集合执行并集；</p>
</li>
<li><p><strong>spop</strong> 指令弹出一个随机元素；</p>
</li>
<li><p><strong>srandmember</strong> 指令返回一个或多个随机元素。</p>
</li>
</ul>
<p>set 集合的特点是查找、插入、删除特别高效，时间复杂度为 O(1)，所以在社交系统中，可以用于存储关注的好友列表，用来判断是否关注，还可以用来做好友推荐使用。另外，还可以利用 set 的唯一性，来对服务的来源业务、来源 IP 进行精确统计。</p>
<h3 id="sorted-set-zset-有序集合"><a href="#sorted-set-zset-有序集合" class="headerlink" title="sorted set (zset) 有序集合"></a><strong>sorted set (zset) 有序集合</strong></h3><p>Redis 中的 sorted set <strong>有序集合</strong>也称为 <strong>zset</strong>，有序集合同 set 集合类似，也是 string 类型元素的集合，且所有元素不允许重复。</p>
<p>有序集合中，每个元素都会关联一个 double 类型的 score 分数值。<strong>有序集合通过这个 score 值进行由小到大的排序</strong>。有序集合中，元素不允许重复，但 score 分数值却允许重复。</p>
<p>除了常规的添加、删除、查找元素外，还可以通过以下指令对 sorted set 进行操作：</p>
<ul>
<li>zscan 指令：按顺序获取有序集合中的元素；</li>
<li>zscore 指令：获取元素的 score 值；</li>
<li>zrange指令：通过指定 score 返回指定 score 范围内的元素；</li>
<li>在某个元素的 score 值发生变更时，还可以通过 zincrby 指令对该元素的 score 值进行加减。</li>
<li>通过 zinterstore、zunionstore 指令对多个有序集合进行取交集和并集，然后将新的有序集合存到一个新的 key 中，如果有重复元素，重复元素的 score 进行相加，然后作为新集合中该元素的 score 值。</li>
</ul>
<p>zset 有序集合的特点是：<strong>所有元素按 score 排序，而且不重复；查找、插入、删除非常高效，时间复杂度为 O(1)。</strong></p>
<p>因此，可以用有序集合来统计排行榜，实时刷新榜单，还可以用来记录学生成绩，从而轻松获取某个成绩范围内的学生名单，还可以用来对系统统计增加权重值，从而在 dashboard 实时展示。</p>
<h3 id="hash-哈希"><a href="#hash-哈希" class="headerlink" title="hash 哈希"></a><strong>hash 哈希</strong></h3><p>Redis 中的哈希实际是 <strong>field 和 value 的一个映射表</strong>。</p>
<p>hash 数据结构的特点是在单个 key 对应的哈希结构内部，可以记录多个键值对，即 field 和 value 对，value 可以是任何字符串。而且<strong>这些键值对查询和修改很高效</strong>。</p>
<p>所以可以用 hash 来存储具有多个元素的复杂对象，然后分别修改或获取这些元素。</p>
<p>hash 结构中的一些重要指令:</p>
<ul>
<li>hmset 指令批量插入多个 field、value 映射；</li>
<li>hmget 指令获取多个 field 对应的 value 值；</li>
<li>hexists 指令判断某个 field 是否存在；</li>
<li>如果 field 对应的 value 是整数，还可以用 hincrby 来对该 value 进行修改。</li>
</ul>
<p>最后了解一下 Redis 中剩下的三个数据类型：<strong>bitmap 位图</strong>、<strong>GEO 地理位置</strong>、<strong>hyperLogLog 基数统计</strong></p>
<ul>
<li><p><strong>bitmap 位图</strong>：Redis 中的 bitmap 位图是一串连续的二进制数字，底层实际是基于 string 进行封装存储的，按 bit 位进行指令操作的。</p>
<p>bitmap 位图的特点是按位设置、求与、求或等操作很高效，而且存储成本非常低，用来存对象标签属性的话，一个 bit 即可存一个标签。</p>
<p>可以用 bitmap，存用户最近 N 天的登录情况，每天用 1 bit，登录则置 1。个性推荐在社交应用中非常重要，可以对新闻、feed 设置一系列标签，如军事、娱乐、视频、图片、文字等，用 bitmap 来存储这些标签，在对应标签 bit 位上置 1。对用户，也可以采用类似方式，记录用户的多种属性，并可以很方便的根据标签来进行多维度统计。bitmap 位图的重要指令包括：setbit、 getbit、bitcount、bitfield、 bitop、bitpos 等。</p>
</li>
<li><p><strong>GEO 地理位置</strong>：Redis 在 3.2 版本之后增加了对 GEO 地理位置的处理功能。Redis 的 GEO 地理位置本质上是基于 sorted set 封装实现的。在存储分类 key 下的地理位置信息时，需要对该分类 key 构建一个 sorted set 作为内部存储结构，用于存储一系列位置点。</p>
<p>Redis 的 GEO 地理位置数据结构，应用场景很多，比如查询某个地方的具体位置，查当前位置到目的地的距离，查附近的人、餐厅、电影院等。GEO 地理位置数据结构中，重要指令包括 geoadd、geopos、geodist、georadius、georadiusbymember 等。</p>
</li>
<li><p><strong>hyperLogLog 基数统计</strong>：Redis 的 hyperLogLog 是用来做基数统计的数据类型，当输入巨大数量的元素做统计时，只需要很小的内存即可完成。HyperLogLog 不保存元数据，只记录待统计元素的估算数量，这个估算数量是一个带有 0.81% 标准差的近似值，在大多数业务场景，对海量数据，不足 1% 的误差是可以接受的。</p>
<p>在大中型系统中，统计每日、每月的 UV 即独立访客数，或者统计海量用户搜索的独立词条数，都可以用 hyperLogLog 数据类型来进行处理。</p>
</li>
</ul>
<h2 id="Redis的设计原则"><a href="#Redis的设计原则" class="headerlink" title="Redis的设计原则"></a>Redis的设计原则</h2><h3 id="Redis-协议"><a href="#Redis-协议" class="headerlink" title="Redis 协议"></a><strong>Redis 协议</strong></h3><p><strong>RESP</strong>（Redis Serialization Protocol）<strong>Redis 序列化协议</strong>， 是一种二进制安全协议，<strong>可以供 Redis 或其他任何 Client-Server 使用</strong>。在 Redis 内部，还会基于 RESP 进一步扩展细节。该协议的设计是为了方便以一种统一的风格和原则来设计和使用Redis指令。</p>
<h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><p><strong>Redis 序列化协议的设计原则有三个</strong>：</p>
<ul>
<li>第一是实现简单；</li>
<li>第二是可快速解析；</li>
<li>第三是便于阅读。</li>
</ul>
<p><strong>Redis 协议的请求响应模型有三种：</strong> </p>
<ul>
<li><strong>ping-pong 模式</strong>：即 client 发送一个请求，server 回复一个响应，一问一答的访问模式。</li>
<li><strong>pipeline 模式</strong>：即 client 一次连续发送多个请求，然后等待 server 响应，server 处理完请求后，把响应返回给 client。</li>
<li><strong>pub/sub 模式</strong>：即发布订阅模式，client 通过 subscribe 订阅一个 channel，然后 client 进入订阅状态，静静等待。当有消息产生时，server 会持续自动推送消息给 client，不需要 client 的额外请求。而且客户端在进入订阅状态后，只可接受订阅相关的命令如 SUBSCRIBE、PSUBSCRIBE、UNSUBSCRIBE 和 PUNSUBSCRIBE，除了这些命令，其他命令一律失效。</li>
</ul>
<p><strong>Redis 请求指令格式类型有 2 种：</strong></p>
<ul>
<li><strong>inline cmd 内联命令格式</strong>：使用 inline cmd 内联格式，只需要用空格分隔请求指令及参数，简单快速，一个简单的例子如 mget key1 key2\r\n。</li>
<li><strong>Array 数组格式</strong>：以 * 开头，随后跟一个数组长度 N，然后以回车换行结尾；然后后面跟随 N 个数组元素。</li>
</ul>
<p><strong>Redis 协议的响应格式有 5 种：</strong></p>
<ul>
<li><strong>simple strings 简单字符串类型</strong>：以 + 开头，后面跟字符串，以 CRLF（即 \r\n）结尾。这种类型不是二进制安全类型，字符串中不能包含 \r 或者 \n。例如：+OK\r\n 。</li>
<li><strong>错误响应</strong>：Redis 协议将错误作为一种专门的类型，格式同简单字符串类型，唯一不同的是以 -（减号）开头。Redis 内部实现对 Redis 协议做了进一步规范，减号后面一般先跟 ERR 或者 WRONGTYPE，然后再跟其他简单字符串，最后以 CRLF（回车换行）结束。</li>
<li><strong>Integer 整数类型</strong>：整数类型以 ：开头，后面跟字符串表示的数字，最后以回车换行结尾。Redis 中许多命令都返回整数，但整数的含义要由具体命令来确定。比如，对于 incr 指令，：后的整数表示变更后的数值；</li>
<li><strong>bulk strings 字符串块类型</strong>：字符串块分<strong>头部和真正字符串内容</strong>两部分。字符串块用于表示二进制安全的字符串，最大长度可以支持 512MB。<ul>
<li>字符串块类型的头部， 为 $ 开头，随后跟真正字符串内容的字节长度，然后以 CRLF 结尾。</li>
<li>字符串块的头部之后，跟随真正的字符串内容，最后以 CRLF 结束字符串块。</li>
</ul>
</li>
<li><strong>Arrays 数组类型</strong>：如果一个命令需要返回多条数据就需要用数组格式类型，另外，前面提到 client 的请求命令也是主要采用这种格式。以 * 开头，随后跟一个数组长度 N，然后以回车换行结尾；然后后面跟随 N 个数组元素，每个数组元素的类型，可以是 Redis 协议中除内联格式外的任何一种类型。</li>
</ul>
<h4 id="协议分类"><a href="#协议分类" class="headerlink" title="协议分类"></a><strong>协议分类</strong></h4><p>Redis 协议主要分为 16 种，<strong>其中 8 种协议对应前面我们讲到的 8 种数据类型</strong>，你选择了使用什么数据类型，就使用对应的响应操作指令即可。</p>
<p>剩下 8 种协议如下：</p>
<ul>
<li><strong>pub-sub 发布订阅协议</strong>，client 可以订阅 channel，持续等待 server 推送消息。</li>
<li><strong>事务协议</strong>，事务协议可以用 multi 和 exec 封装一些列指令，来一次性执行。</li>
<li><strong>脚本协议</strong>，关键指令是 eval、evalsha 和 script等。</li>
<li><strong>连接协议</strong>，主要包括权限控制，切换 DB，关闭连接等。</li>
<li><strong>复制协议</strong>，包括 slaveof、role、psync 等。</li>
<li><strong>配置协议</strong>，config set/get 等，可以在线修改/获取配置。</li>
<li><strong>调试统计协议</strong>，如 slowlog，monitor，info 等。</li>
<li><strong>其他内部命令</strong>，如 migrate，dump，restore 等。</li>
</ul>
<h3 id="Redis-client-的使用及改进"><a href="#Redis-client-的使用及改进" class="headerlink" title="Redis client 的使用及改进"></a><strong>Redis client 的使用及改进</strong></h3><p>由于 Redis 使用广泛，几乎所有主流语言都有对 Redis 开发了对应的 client。 Java 语言中，广泛使用的有 Jedis、Redisson 等。</p>
<ul>
<li><strong>Jedis</strong>：它的优势是轻量，简洁，便于集成和改造，它支持连接池，提供指令维度的操作，几乎支持 Redis 的所有指令，但它不支持读写分离。</li>
<li><strong>Redisson</strong>： 基于 Netty 实现，非阻塞 IO，性能较高，而且支持异步请求和连接池，还支持读写分离、读负载均衡，它内建了 tomcat Session ，支持 spring session 集成，但 redisson 实现相对复杂。</li>
</ul>
<p>在新项目启动时，如果只是简单的 Redis 访问业务场景，可以直接用 Jedis，甚至可以简单封装 Jedis，实现 master-slave 的读写分离方案。如果想直接使用读写分离，想集成 spring session 等这些高级特性，也可以采用 redisson。 </p>
<p>Redis client 在使用中，需要根据业务及运维的需要，进行相关改进。在 client 访问异常时，可以增加<strong>重试策略</strong>，在访问某个 slave 异常时，需要重试其他 slave 节点。需要增加对 <strong>Redis 主从切换、slave 扩展</strong>的支持，比如采用守护线程定期扫描 master、slave 域名，发现 IP 变更，及时切换连接。</p>
<p>对于多个 slave 的访问，还需要增加<strong>负载均衡</strong>策略。最后，Redis client 还可以与配置中心、Redis 集群管理平台整合，从而实时感知及协调 Redis 服务的访问。</p>
<h2 id="Redis-系统架构"><a href="#Redis-系统架构" class="headerlink" title="Redis 系统架构"></a>Redis 系统架构</h2><img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_21.png" alt="Redis系统架构" style="zoom:80%;">

<p>Redis 组件的系统架构如图所示，主要包括：</p>
<ul>
<li><strong>事件处理模块</strong>：Redis 中的事件处理模块，采用的是作者自己开发的 ae 事件驱动模型，可以进行<strong>高效的网络 IO 读写、命令执行，以及时间事件处理</strong>。    </li>
<li><strong>数据存储及管理模块</strong>：Redis 的内存数据都存在 redisDB 中。</li>
<li><strong>用于系统扩展的主从复制/集群管理模块</strong>：主从复制，Redis cluster 集群。</li>
<li><strong>为插件化功能扩展的 Module System 模块</strong>：Redis 在 4.0 版本之后引入了 Module System 模块，可以方便使用者，在不修改核心功能的同时，进行插件化功能开发。使用者可以将新的 feature 封装成动态链接库，Redis 可以在启动时加载，也可以在运行过程中随时按需加载和启用。</li>
</ul>
<h3 id="Redis-事件驱动模型"><a href="#Redis-事件驱动模型" class="headerlink" title="Redis 事件驱动模型"></a><strong>Redis 事件驱动模型</strong></h3><p>Redis 是一个事件驱动程序，但和 Memcached 不同的是，Redis 并没有采用 libevent 或 libev 这些开源库，而是<strong>直接开发了一个新的事件循环组件</strong>。Redis 作者给出的理由是，尽量减少外部依赖，而自己开发的事件模型也足够简洁、轻便、高效，也更易控制。</p>
<p>Redis 的事件驱动模型机制封装在 aeEventLoop 等相关的结构体中，网络连接、命令读取执行回复，数据的持久化、淘汰回收 key 等，几乎所有的核心操作都通过 ae 事件模型进行处理。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_22.png" alt="Redis事件驱动模型" style="zoom:80%;">

<p><strong>Redis 的事件驱动模型处理 2 类事件：</strong></p>
<ul>
<li><strong>文件事件</strong>，如连接建立、接受请求命令、发送响应等；</li>
<li><strong>时间事件</strong>，如 Redis 中定期要执行的统计、key 淘汰、缓冲数据写出、rehash等。</li>
</ul>
<h4 id="文件事件"><a href="#文件事件" class="headerlink" title="文件事件"></a>文件事件</h4><p>Redis 的文件事件采用典型的 <strong>Reactor 模式</strong>进行处理。    </p>
<p><strong>处理机制分为 4 部分：</strong></p>
<ul>
<li><p><strong>连接 socket</strong>；</p>
</li>
<li><p><strong>IO 多路复用程序</strong>：Redis 封装了 4 种多路复用程序；每种封装实现都提供了相同的 API 实现。<strong>编译时，会按照性能和系统平台，选择最佳的 IO 多路复用函数作为底层实现</strong>，选择顺序是，首先尝试选择 Solaries 中的 evport，如果没有，就尝试选择 Linux 中的 epoll，否则就选择大多 UNIX 系统都支持的 kqueue，最终就会选择 select 作为底层实现方案。</p>
</li>
<li><p><strong>文件事件分派器</strong>：Redis 中的文件事件分派器是 aeProcessEvents 函数。<strong>它会首先计算最大可以等待的时间，然后利用 aeApiPoll 等待文件事件的发生。</strong>如果在等待时间内，一旦 IO 多路复用程序产生了事件通知，则会立即轮询所有已产生的文件事件，并将文件事件放入 aeEventLoop 中的 aeFiredEvents 结构数组中。</p>
<p>这里会涉及将多路复用中的事件类型，转换为 Redis 的 ae 事件驱动模型中的事件类型。</p>
<p>aeProcessEvents 在获取到触发的事件后，会根据事件类型，将文件事件 dispatch 派发给对应事件处理函数。如果同一个 socket，同时有读事件和写事件，Redis 派发器会首先派发处理读事件，然后再派发处理写事件。</p>
</li>
<li><p><strong>事件处理器</strong>；Redis 中文件事件函数的注册和处理主要分为 3 种。</p>
<ul>
<li><strong>连接处理器 acceptTcpHandler</strong>：Redis 在启动时，在 initServer 中对监听的 socket 注册读事件，事件处理器为 acceptTcpHandler，该函数在有新连接进入时，会被派发器派发读任务。</li>
<li><strong>请求处理器 readQueryFromClient</strong>：连接函数在创建 client 时，会对新连接 socket 注册一个读事件，该读事件的事件处理器就是 readQueryFromClient。</li>
<li><strong>命令回复处理器 sendReplyToClient</strong>：当 redis需要发送响应给client时，Redis 事件循环中会对client的连接socket注册写事件，这个写事件的处理函数就是sendReplyToClient。</li>
</ul>
</li>
</ul>
<p><strong>协议命令解析及处理：</strong></p>
<ul>
<li><p>请求命令进入，触发 IO 读事件后。client 会从连接文件描述符读取请求，并存入 client 的 query buffer 中。</p>
</li>
<li><p>client 读取完请求命令后，则根据 query buff 进行协议解析。协议解析时，首先查看协议的首字符。</p>
<ul>
<li>如果是 *，则解析为字符块数组类型，即 MULTIBULK。</li>
<li>否则请求解析为 INLINE 类型。INLINE 类型是以 CRLF 结尾的单行字符串，协议命令及参数以空格分隔。</li>
</ul>
</li>
<li><p>协议解析完毕后，将请求参数个数存入 client 的 argc 中，将请求的具体参数存入 client 的 argv 中。</p>
</li>
</ul>
<p><strong>对于 quit 指令</strong>，直接返回 OK，设置 flag 为回复后关闭连接。</p>
<p><strong>对于非 quit 指令</strong>，以 client 中 argv[0] 作为命令，从 server 中的命令表中找到对应的 redisCommand。如果没有找到 redisCommand，则返回未知 cmd 异常。如果找到 cmd，则开始执行 redisCommand 中的 proc 函数，进行具体命令的执行。在命令执行完毕后，将响应写入 client 的写缓冲。并按配置和部署，将写指令分发给 aof 和 slaves。同时更新相关的统计数值。</p>
<h4 id="时间事件"><a href="#时间事件" class="headerlink" title="时间事件"></a>时间事件</h4><p><strong>Redis 中的时间事件分为 2 类：</strong></p>
<ul>
<li><strong>单次时间事件</strong>，即执行完毕后，该时间事件就结束了。</li>
<li><strong>周期性事件</strong>，在事件执行完毕后，会继续设置下一次执行的事件，从而在时间到达后继续执行，并不断重复。</li>
</ul>
<p><strong>时间事件主要有 5 个属性：</strong></p>
<ul>
<li><p><strong>事件 ID</strong>：Redis 为时间事件创建全局唯一 ID，该 ID 按从小到大的顺序进行递增。</p>
</li>
<li><p><strong>执行时间 when_sec 和 when_ms</strong>：精确到毫秒，记录该事件的到达可执行时间。</p>
</li>
<li><p><strong>时间事件处理器 timeProc</strong>：在时间事件到达时，Redis 会调用相应的 timeProc 处理事件。</p>
</li>
<li><p><strong>关联数据 clientData</strong>：在调用 timeProc 时，需要使用该关联数据作为参数。</p>
</li>
<li><p><strong>链表指针 prev 和 next</strong>：它用来将时间事件维护为双向链表，便于插入及查找所要执行的时间事件。</p>
</li>
</ul>
<p>时间事件的处理是在事件循环中的 aeProcessEvents 中进行。</p>
<p><strong>执行过程</strong>：</p>
<ul>
<li>首先<strong>遍历所有的时间事件</strong>。比较事件的时间和当前时间，找出可执行的时间事件。</li>
<li>然后执行时间事件的 <strong>timeProc 函数</strong>。</li>
<li>执行完毕后，对于周期性时间，设置时间新的执行时间；对于单次性时间，设置事件的 ID为 -1，后续在事件循环中，下一次执行 aeProcessEvents 的时候从链表中删除。</li>
</ul>
<h3 id="数据存储及管理模块"><a href="#数据存储及管理模块" class="headerlink" title="数据存储及管理模块"></a>数据存储及管理模块</h3><p>Redis 中所有数据都保存在 DB 中，<strong>一个 Redis 默认最多支持 16 个 DB</strong>。Redis 中的每个 DB 都对应一个 redisDb 结构，即每个 Redis 实例，默认有 16 个 redisDb。用户访问时，<strong>默认使用的是 0 号 DB</strong>，可以通过 select $dbID 在不同 DB 之间切换。</p>
<h4 id="redisDb"><a href="#redisDb" class="headerlink" title="redisDb"></a>redisDb</h4><p>redisDb 结构分为五个部分：</p>
<ul>
<li><strong>dict 主字典</strong>：用来存储当前 DB 中的所有数据，它将 key 和各种数据类型的 value 关联起来，该 dict 也称 key space。</li>
<li><strong>expires 过期字典</strong>：用来存储过期时间 key，存的是 key 与过期时间的映射。</li>
<li><strong>blocking_keys 阻塞字典</strong>：存储的是处于阻塞状态的 key 及 client 列表。例如：在执行 Redis 中 list 的阻塞命令 blpop、brpop 或者 brpoplpush 时，如果对应的 list 列表为空，Redis 就会将对应的 client 设为阻塞状态，同时将该 client 添加到 DB 中 blocking_keys 这个阻塞 dict。</li>
<li><strong>ready_keys 解除阻塞字典</strong>：当有其他调用方在向某个 key 对应的 list 中增加元素时，Redis 会检测是否有 client 阻塞在这个 key 上，即检查 blocking_keys 中是否包含这个 key，如果有则会将这个 key 加入 read_keys 这个 dict 中。</li>
<li><strong>watched_keys 监控字典</strong>：当 client 使用 watch 指令来监控 key 时，这个 key 和 client 就会被保存到 watched_keys 这个 dict 中。</li>
</ul>
<p>redisDb 中可以保存所有的数据类型，而 Redis 中所有数据类型都是存放在一个叫 <strong>redisObject</strong> 的结构中。</p>
<h4 id="dict"><a href="#dict" class="headerlink" title="dict"></a><strong>dict</strong></h4><p><strong>Redis 中的数据实际是存在 DB 中的 2 个核心 dict 字典中的</strong>。实际上 dict 也是 Redis 的一种使用广泛的内部数据结构。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_24.png" alt="dict数据结构" style="zoom:90%;">

<p><strong>Redis 中的 dict，类似于 Memcached 中 hashtable。</strong>都可以用于 key 或元素的快速插入、更新和定位。</p>
<p>dict 字典中，有一个长度为 2 的哈希表数组，日常访问用 0 号哈希表，如果 0 号哈希表元素过多，则分配一个 2 倍 0 号哈希表大小的空间给 1 号哈希表，然后进行逐步迁移，rehashidx 这个字段就是专门用来做标志迁移位置的。</p>
<p>在哈希表操作中，<strong>采用单向链表来解决 hash 冲突问题</strong>。dict 中还有一个重要字段是 type，它用于保存 hash 函数及 key/value 赋值、比较函数。</p>
<p>dictht 中的 table 是一个 hash 表数组，每个桶指向一个 dictEntry 结构。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_25.png" alt="dictht结构" style="zoom:67%;">

<p>其中 <strong>key 是 sds 字符串</strong>（简单动态字符串，本质是一个 char<em>，内部通过 sdshdr 进行管理。），v*</em>alue 为存储各种数据类型的 redisObject 结构**。</p>
<h4 id="redisObject"><a href="#redisObject" class="headerlink" title="redisObject"></a>redisObject</h4><img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_23.png" alt="redisObject结构" style="zoom:80%;">

<p><strong>redisObject 由 5 个字段组成：</strong></p>
<ul>
<li><strong>type</strong>：即 Redis 对象的数据类型，目前支持 7 种 type 类型，如上图；</li>
<li><strong>encoding</strong>：Redis 对象的内部编码方式，即内部数据结构类型，目前支持 10 种编码方式，如图；</li>
<li><strong>LRU</strong>：存储的是淘汰数据用的 LRU 时间或 LFU 频率及时间的数据。</li>
<li><strong>refcount</strong>：记录 Redis 对象的引用计数，用来表示对象被共享的次数，共享使用时加 1，不再使用时减 1，当计数为 0 时表明该对象没有被使用，就会被释放，回收内存。</li>
<li><strong>ptr</strong>：它指向对象的内部数据结构。比如一个代表 string 的对象，它的 ptr 可能指向一个 sds 或者一个 long 型整数。</li>
</ul>
<h4 id="ziplist"><a href="#ziplist" class="headerlink" title="ziplist"></a><strong>ziplist</strong></h4><p>为了<strong>节约内存，并减少内存碎片</strong>，Redis 设计了 ziplist 压缩列表内部数据结构。</p>
<p>压缩列表是<strong>一块连续的内存空间</strong>，可以连续存储多个元素，没有冗余空间，是一种连续内存数据块组成的<strong>顺序型内存结构</strong>。</p>
<p>由于 ziplist 是连续紧凑存储，没有冗余空间，所以插入新的元素需要 realloc 扩展内存，所以如果 ziplist 占用空间太大，realloc 重新分配内存和拷贝的开销就会很大，所以 ziplist <strong>不适合存储过多元素，也不适合存储过大的字符串。</strong> </p>
<p>因此只有在元素数和 value 数都不大的时候，ziplist 才作为 hash 和 zset 的内部数据结构。其中 ：</p>
<ul>
<li><strong>hash</strong> 使用 ziplist 作为内部数据结构的限制时，元素数默认不超过 512 个，value 值默认不超过 64 字节。可以通过修改配置来调整 hash_max_ziplist_entries 、hash_max_ziplist_value 这两个阀值的大小。</li>
<li><strong>zset 有序集合</strong>，使用 ziplist 作为内部数据结构的限制元素数默认不超过 128 个，value 值默认不超过 64 字节。可以通过修改配置来调整 zset_max_ziplist_entries 和 zset_max_ziplist_value 这两个阀值的大小。</li>
</ul>
<h4 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a><strong>quicklist</strong></h4><p>Redis 在 3.2 版本之后引入 quicklist，用以替换 linkedlist。</p>
<p>因为 linkedlist 每个节点有前后指针，要占用 16 字节，而且每个节点独立分配内存，很容易加剧内存的碎片化。而 ziplist 由于紧凑型存储，增加元素需要 realloc，删除元素需要内存拷贝，天然不适合元素太多、value 太大的存储。</p>
<p>而 quicklist 快速列表应运而生，它是一个<strong>基于 ziplist 的双向链表</strong>。将数据分段存储到 ziplist，然后将这些 ziplist 用双向指针连接。</p>
<p><strong>快速列表从头尾读写数据很快，时间复杂度为 O(1)。也支持从中间任意位置插入或读写元素，但速度较慢，时间复杂度为 O(n)。</strong>快速列表当前主要作为 <strong>list 列表的内部数据结构</strong>。</p>
<h4 id="zskiplist"><a href="#zskiplist" class="headerlink" title="zskiplist"></a><strong>zskiplist</strong></h4><p>跳跃表 zskiplist 是一种<strong>有序数据结构，它通过在每个节点维持多个指向其他节点的指针，从而可以加速访问</strong>。（联想到Java中的SkipList）</p>
<p>跳跃表支持平均 O(logN) 和最差 O(n) 复杂度的节点查找。</p>
<p>在大部分场景，跳跃表的效率和平衡树接近，但跳跃表的实现比平衡树要简单，所以不少程序都用跳跃表来替换平衡树。</p>
<p>如果 <strong>sorted set（zset） 类型</strong>的元素数比较多或者元素比较大，Redis 就会选择跳跃表来作为 sorted set有序集合的内部数据结构。</p>
<p><strong>总结：8种数据类型对应哪些内部数据结构？</strong></p>
<ul>
<li>string 字符串，Redis 主要采用 sds 来进行存储。</li>
<li>list 列表，Redis 采用 quicklist 进行存储。</li>
<li>set 集合类型，Redis 采用 dict 来进行存储。</li>
<li>sorted set 有序集合类型<ul>
<li>如果元素数小于 128 且元素长度小于 64，则使用 ziplist 存储，</li>
<li>否则使用 zskiplist 存储。</li>
</ul>
</li>
<li>哈希类型<ul>
<li>如果元素数小于 512，并且元素长度小于 64，则用 ziplist 存储，</li>
<li>否则使用 dict 字典存储。</li>
</ul>
</li>
<li>hyperloglog，采用 sds 简单动态字符串存储。</li>
<li>geo<ul>
<li>如果位置数小于 128，则使用 ziplist 存储，</li>
<li>否则使用 zskiplist 存储。</li>
</ul>
</li>
<li>bitmap，采用 sds 简单动态字符串存储。</li>
</ul>
<h3 id="主从复制-集群管理模块"><a href="#主从复制-集群管理模块" class="headerlink" title="主从复制\集群管理模块"></a>主从复制\集群管理模块</h3><h4 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h4><p>为了避免单点故障，数据存储需要进行多副本构建。同时由于 Redis 的核心操作是单线程模型的，单个 Redis 实例能处理的请求 TPS 有限。因此 Redis 自面世起，基本就提供了复制功能，而且对复制策略不断进行优化。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_26.png" alt="主从复制架构图" style="zoom:75%;">

<ul>
<li>Redis 的一个 master 可以挂载多个 slave，而 slave 下还可以挂载多个 slave，形成<strong>多层嵌套结构</strong>。</li>
<li>所有写操作都在 master 实例中进行，master 执行完毕后，将写指令分发给挂在自己下面的 slave 节点。实现同步。</li>
<li>主库 master 和从库 slave 之间通过复制 id 进行匹配，避免 slave 挂到错误的 master。</li>
<li>写操作在master，读操作可以分摊到所有slave节点，<strong>读写分离</strong>，这样整个 master-slave 组合，读写能力都可以得到大幅提升。</li>
<li>master 在分发写请求时，同时会将写指令复制一份存入<strong>复制积压缓冲</strong>，这样当 slave 短时间断开重连时，只要 slave 的<strong>复制位置点</strong>仍然在复制积压缓冲，则可以从之前的复制位置点之后继续进行复制，提升复制效率。</li>
</ul>
<p><strong>Redis复制分为2类：</strong></p>
<ul>
<li><p><strong>全量复制（同步）</strong>：master 会将内存数据通过 bgsave 落地到 <strong>rdb</strong>，同时，将构建 内存快照期间 的写指令，存放到复制缓冲中，当 rdb 快照构建完毕后，master 将 <strong>rdb 和复制缓冲队列中的数据</strong>全部发送给 slave，slave 完全重新创建一份数据。</p>
<p>这个过程，耗时，耗性能，耗带宽，对系统性能和资源资源的访问都影响比较大。在 Redis 2.8 之前，Redis 基本只支持全量复制。</p>
</li>
<li><p><strong>增量复制（同步）</strong>：master 只发送 slave 上次复制位置之后的写指令，不用构建 rdb，而且传输内容非常有限，对 master、slave 的负荷影响很小，对带宽的影响可以忽略，整个系统受影响非常小。</p>
</li>
</ul>
<h4 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h4><p>通过上面的学习，我们知道<strong>复制功能可以 N 倍提升 Redis 节点的读性能</strong>，而集群则可以通过<strong>分布式方案来 N 倍提升 Redis 的写性能</strong>。除了提升性能之外，Redis 集群还可以提供更大的容量，提升资源系统的可用性。</p>
<p><strong>Redis 集群的分布式方案主要有 3 种</strong>：</p>
<ul>
<li><strong>Client 端分区方案</strong></li>
<li><strong>Proxy 分区方案</strong></li>
<li><strong>Redis Cluster 分区方案</strong></li>
</ul>
<h5 id="Client-端分区"><a href="#Client-端分区" class="headerlink" title="Client 端分区"></a>Client 端分区</h5><p><strong>Client 端分区方案</strong>就是由 Client 决定数据被存储到哪个 Redis 分片，或者由哪个 Redis 分片来获取数据。它的核心思想是<strong>通过哈希算法将不同的 key 映射到固定的 Redis 分片节点上</strong>。</p>
<ul>
<li>对于单个 key 请求，Client 直接对 key 进行哈希后，确定 Redis 分片，然后进行请求。</li>
<li>而对于一个请求附带多个 key 的场景，Client 会首先将这些 key 按哈希分片进行分类，从而将一个请求分拆为多个请求，然后再分别请求不同的哈希分片节点。</li>
</ul>
<p>Client 通过哈希算法将数据进行分布,<strong>一般采用的哈希算法是:</strong></p>
<ul>
<li><strong>取模哈希;</strong></li>
<li><strong>一致性哈希</strong>;</li>
<li><strong>区间分布哈希</strong>：实际是一种取模哈希的变种，取模哈希是哈希并取模计算后，按哈希值来分配存储节点，而区间哈希是在哈希计算后，将哈希划分为多个区间，然后将这些区间分配给存储节点。如哈希后分 1024 个哈希点，然后将 0-511 作为分片 1，将 512-1023 作为分片 2。</li>
</ul>
<p><strong>问题：</strong>对于 Client 端分区，由于 Redis 集群有多个 master 分片，同时每个 master 下挂载多个 slave，每个 Redis 节点都有独立的 IP 和端口。如果 master 异常需要切换 master，或读压力过大需要扩展新的 slave，这些都会涉及集群存储节点的变更，需要 Client 端做连接切换。</p>
<p><strong>解决方案</strong>：为了避免 Client 频繁变更 IP 列表，可以采用 DNS 的方式来管理集群的主从。对 Redis 集群的每个分片的主和从均采用不同 DNS 域名。Client 通过域名解析的方式获取域名下的所有 IP，然后来访问集群节点。</p>
<p>在 DNS 访问模式下，Client 需要异步定时探测主从域名，如果发现 IP 变更，及时与新节点建立连接，并关闭老连接。</p>
<p><strong>优缺点</strong></p>
<ul>
<li><strong>优点</strong>：Client 端分区方案的优点在于分区逻辑简单，配置简单，Client 节点之间和 Redis 节点之间均无需协调，灵活性强。而且 Client 直接访问对应 Redis 节点，没有额外环节，性能高效。</li>
<li><strong>缺点</strong>：但该方案扩展不便。在 Redis 端，只能成倍扩展，或者预先分配足够多的分片。在 Client 端，每次分片后，业务端需要修改分发逻辑，并进行重启。</li>
</ul>
<h5 id="Proxy-端分区"><a href="#Proxy-端分区" class="headerlink" title="Proxy 端分区"></a>Proxy 端分区</h5><p>Proxy 端分区方案是指 Client 发送请求给 Proxy 请求代理组件，Proxy 解析 Client 请求，并将请求分发到正确的 Redis 节点，然后等待 Redis 响应，最后再将结果返回给 Client 端。</p>
<ul>
<li>对于单个 key 请求，Proxy 直接对 key 进行哈希后，确定 请求路由，然后进行请求。</li>
<li>如果一个请求包含多个 key，Proxy 需要将请求的多个 key，按分片逻辑分拆为多个请求，然后分别请求不同的 Redis 分片，接下来等待Redis响应，在所有的分拆响应到达后，再进行聚合组装，最后返回给 Client。</li>
</ul>
<p><strong>如果系统运行中，主从变更或发生扩缩容，也只需由 Proxy 变更完成，业务 Client 端基本不受影响。</strong></p>
<p><strong>常见的 Proxy 端分区方案有2种：</strong></p>
<ul>
<li>基于 Twemproxy 的简单分区方案：Twitter 开源的一个组件，支持 Redis 和 Memcached 协议访问的代理组件。Twemproxy 实现简单、稳定性高，在一些访问量不大且很少发生扩缩的业务场景中，可以很好的满足需要。但由于 Twemproxy 是单进程单线程模型的，对包含多个 key 的 mutli 请求，由于需要分拆请求，然后再等待聚合，处理性能较低。可单独详细了解。</li>
<li>基于Codis 的可平滑数据迁移的分区方案：Codis 是一个较为成熟的分布式 Redis 解决方案。对于业务 Client 访问，连接 Codis-proxy 和连接单个 Redis 几乎没有区别。Codis 底层除了会自动解析分发请求之外，还可以在线进行数据迁移，使用非常方便。</li>
</ul>
<p>以上俩种方案可自行了解。</p>
<p><strong>优缺点</strong></p>
<ul>
<li><strong>优点</strong>：使 Client 访问逻辑和 Redis 分布逻辑解耦，业务访问便捷简单。在资源发生变更或扩缩容时，只用修改数量有限的 Proxy 即可，数量庞大的业务 Client 端不用做调整。</li>
<li><strong>缺点</strong>：访问时请求需要经过 Proxy 中转，访问多跳了一级，性能会存在损耗，一般损耗会达到 5~15% 左右。另外多了一个代理层，整个系统架构也会更复杂。</li>
</ul>
<h5 id="Redis-Cluster-分区"><a href="#Redis-Cluster-分区" class="headerlink" title="Redis Cluster 分区"></a><strong>Redis Cluster 分区</strong></h5><p>Redis 社区版在 3.0 后开始引入 Cluster 策略，一般称之为 Redis-Cluster 方案。</p>
<p><strong>Redis-Cluster 按 slot 进行数据的读写和管理，一个 Redis-Cluster 集群包含 16384 个 slot。每个 Redis 分片负责其中一部分 slot。</strong>在集群启动时，<strong>按需将所有 slot 分配到不同节点，在集群系统运行后，按 slot 分配策略，将 key 进行 hash 计算</strong>，并路由到对应节点 访问。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%89%EF%BC%89-Redis/cache_27.png" alt="Redis-Cluster结构" style="zoom:90%;">

<p><strong>在 Redis-Cluster 集群中，key 的访问需要 smart client 配合。</strong></p>
<ul>
<li>Client 首先发送请求给 Redis 节点，Redis 在接受并解析命令后，会对 key 进行 hash 计算以确定 slot 槽位。计算公式是对 key 做 crc16 哈希，然后对 16383 进行按位与操作。</li>
<li>如果 Redis 发现 key 对应的 slot 在本地，则直接执行后返回结果。</li>
<li>如果 Redis 发现 key 对应的 slot 不在本地，会返回 moved 异常响应，并附带 key 的 slot，以及该 slot 对应的正确 Redis 节点的 host 和 port。</li>
<li>Client 根据响应解析出正确的节点 IP 和端口，然后把请求重定向到正确的 Redis，即可完成请求。为了加速访问，Client 需要缓存 slot 与 Redis 节点的对应关系，这样可以直接访问正确的节点，以加速访问性能。   </li>
</ul>
<p><strong>Redis Cluster 是一个去中心化架构</strong>，每个节点记录全部 slot 的拓扑分布。</p>
<p><strong>Redis Cluster 下的不同 Redis 分片节点通过 gossip 协议进行互联</strong>，使用 gossip 的优势在于，该方案无中心控制节点，这样，更新不会受到中心节点的影响，可以通过通知任意一个节点来进行管理通知。</p>
<p><strong>Redis Cluster 支持还支持slot 迁移</strong>。随着业务访问模型的变化，Redis 部分节点可能会出现压力过大、访问不均衡的现象，此时可以将 slot 在 Redis 分片节点内部进行迁移，以均衡访问。如果业务不断发展，数据量过大、TPS过高，还可以将 Redis 节点的部分 slot 迁移到新节点，增加 Redis-Cluster 的分片，对整个 Redis 资源进行扩容，已提升整个集群的容量及读写能力。</p>
<p><strong>Redis-Cluster 提供了灵活的节点扩缩容方案</strong>，可以在不影响用户访问的情况下，动态为集群增加节点扩容，或下线节点为集群缩容。</p>
<p>对于线上应用，还需要<strong>为slot节点增加从库，以增加读写能力及可用性</strong>。在节点上增加从库，需要注意的是，不能使用非集群模式下的 slaveof 指令，而要使用 cluster replication，才能完成集群分片节点下的 slave 添加。另外，对于集群模式，slave 只能挂在分片 master 上，slave 节点自身不能再挂载 slave。</p>
<p>Redis 社区官方在源代码中也提供了 <strong>redis-trib.rb，作为 Redis Cluster 的管理工具</strong>。该工具用 Ruby 开发，所以在使用前，需要安装相关的依赖环境。redis-trib 工具通过封装前面所述的 Redis 指令，从而支持<strong>创建集群、检查集群、添加删除节点、在线迁移 slot</strong> 等各种功能。</p>
<p><strong>优缺点</strong></p>
<ul>
<li><p><strong>优点</strong>：由社区官方实现，并有 Redis-trib 集群工具，上线和使用起来比较便捷。同时它支持在线扩缩，可以随时通过工具查看集群的状态。</p>
</li>
<li><p><strong>缺点</strong>：</p>
<ul>
<li>数据存储和集群逻辑耦合，代码逻辑复杂，容易出错。</li>
<li>Redis 节点要存储 slot 和 key 的映射关系，需要额外占用较多内存，特别是对 value size 比较小、而key相对较大的业务，影响更是明显。</li>
<li>key 迁移过程是阻塞模式，迁移大 value 会导致服务卡顿。而且，迁移过程，先获取 key，再迁移，效率低。</li>
<li>Cluster 模式下，集群复制的 slave 只能挂载到 master，不支持 slave 嵌套，会导致 master 的压力过大，无法支持那些，需要特别多 slave、读 TPS 特别大的业务场景。</li>
</ul>
</li>
</ul>
<h3 id="拓展知识"><a href="#拓展知识" class="headerlink" title="拓展知识"></a>拓展知识</h3><h4 id="Redis-持久化"><a href="#Redis-持久化" class="headerlink" title="Redis 持久化"></a>Redis 持久化</h4><p><strong>Redis</strong> 持久化是一个将<strong>内存数据转储到磁盘的过程</strong>。</p>
<p><strong>Redis</strong> 目前支持 <strong>RDB、AOF，以及混合存储三种模式</strong>。</p>
<h5 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h5><p><strong>Redis</strong> 的 <strong>RDB</strong> 持久化是以<strong>快照的方式</strong>将内存数据存储到磁盘。</p>
<p>在需要进行 RDB 持久化时，Redis 会将内存中的<strong>所有数据以二进制的格式落地</strong>，每条数据存储的<strong>内容包括过期时间、数据类型、key，以及 value。</strong>当 Redis 重启时，如果 appendonly 关闭，则会读取 RDB 持久化生成的二进制文件进行数据恢复。</p>
<p><strong>触发构建 RDB 的场景：</strong></p>
<ul>
<li>通过 <strong>save 或 bgsave 命令</strong>进行主动 RDB 快照构建。</li>
<li>利用<strong>配置 save m n</strong> 来进行自动快照生成。它是指在 m 秒中，如果插入或变更 n 个 key，则自动触发 bgsave。这个配置可以设置多个配置行，以便组合使用。</li>
<li><strong>主从复制</strong>，如果从库需要进行全量复制，此时主库也会进行 bgsave 生成一个 RDB 快照。</li>
<li><strong>执行 flushall 清空所有数据，或执行 shutdown 关闭服务</strong>时，也会触发 Redis 自动构建 RDB 快照。</li>
</ul>
<p><strong>save 和 bgsave 命令对比：</strong></p>
<ul>
<li><strong>save</strong>：是在主进程中进行 RDB 持久化的，持久化期间 Redis 处于<strong>阻塞</strong>状态，不处理任何客户请求，所以一般使用较少。</li>
<li><strong>bgsave</strong>：是 fork 一个<strong>子进程</strong>，然后在子进程中构建 RDB 快照，构建快照的过程不直接影响用户的访问，但仍然会增加机器负载。线上 Redis 快照备份，一般会选择凌晨低峰时段，通过 bgsave 主动触发进行备份。</li>
</ul>
<p><strong>RDB 快照文件主要由 3 部分组成：</strong></p>
<ul>
<li><p><strong>RDB 头部</strong>，主要包括 RDB 的版本，以及 Redis 版本、创建日期、占用内存等辅助信息。</p>
</li>
<li><p><strong>RedisDB 的数据</strong>。存储每个 RedisDB 时，会首先记录当前 RedisDB 的DBID，然后记录主 dict 和 expire dict 的记录数量，最后再轮询存储每条数据记录。</p>
<p>存储数据记录时，如果数据有过期时间，首先记录过期时间。如果 Redis 的 maxmemory_policy 过期策略采用 LRU 或者 LFU，还会将 key 对应的 LRU、LFU 值进行落地，最后记录数据的类型、key，以及 value。</p>
</li>
<li><p><strong>RDB 的尾部</strong>。RDB 尾部，首先存储 Redis 中的 Lua 脚本等辅助信息。然后存储 EOF 标记，即值为 255 的字符。最后存 RDB 的 cksum。</p>
</li>
</ul>
<p><strong>优缺点</strong></p>
<ul>
<li><p><strong>优点</strong>：RDB 采用二进制方式存储内存数据，文件小，且启动时恢复速度快。</p>
</li>
<li><p><strong>缺点</strong>：</p>
<ul>
<li><p>二进制存储，可读性差，而且由于格式固定，不同版本之间可能存在兼容性问题。</p>
</li>
<li><p>构建 RDB 时，一个快照文件只能存储，构建时刻的内存数据，无法记录之后的数据变更。构建 RDB 的过程，即便在子进程中进行，但仍然属于 CPU 密集型的操作，而且每次落地全量数据，耗时也比较长，不能随时进行，特别是不能在高峰期进行。</p>
</li>
</ul>
</li>
</ul>
<h5 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h5><p>Redis 的 AOF 持久化是<strong>以命令追加的方式进行数据落地</strong>的。</p>
<p>通过打开 appendonly 配置，Redis 将每一个写指令追加到磁盘 AOF 文件，从而及时记录内存数据的最新状态。这样即便 Redis 被 crash 或异常关闭后，再次启动，也可以通过加载 AOF，来恢复最新的全量数据，基本不会丢失数据。</p>
<p>AOF 文件中<strong>存储的协议是写指令的 multibulk 格式</strong>，这是 Redis 的标准协议格式，所以<strong>不同的 Redis 版本均可解析并处理，兼容性很好</strong>。</p>
<p>但是，由于 Redis 会记录所有写指令操作到 AOF，大量的中间状态数据，甚至被删除的过期数据，都会存在 AOF 中，<strong>冗余度很大</strong>，而且每条指令还需通过加载和执行来进行数据恢复，<strong>耗时会比较大</strong>。</p>
<p><strong>AOF 数据的落地流程:</strong></p>
<ul>
<li>Redis 在处理完写指令后，首先将写指令<strong>写入 AOF 缓冲</strong>，</li>
<li>然后通过 server_cron 定期将 AOF 缓冲<strong>写入文件缓冲</strong>。</li>
<li>最后按照配置策略进行 fsync，将文件缓冲的数据真正同步<strong>写入磁盘</strong>。</li>
</ul>
<p><strong>Redis 通过 appendfsync 来设置三种不同的同步文件缓冲策略</strong>：</p>
<ul>
<li>第一种配置策略是 <strong>no</strong>，即 Redis 不主动使用 fsync 进行文件数据同步落地，而是由操作系统的 write 函数去确认同步时间，在 Linux 系统中大概每 30 秒会进行一次同步，如果 Redis 发生 crash，就会造成大量的数据丢失。</li>
<li>第二种配置策略是 <strong>always</strong>，即每次将 AOF 缓冲写入文件，都会调用 fsync 强制将内核数据写入文件，安全性最高，但性能上会比较低效，而且由于频繁的 IO 读写，磁盘的寿命会大大降低。</li>
<li>第三种配置策略是 <strong>everysec</strong>。即每秒通过 BIO 线程进行一次 fsync。这种策略在安全性、性能，以及磁盘寿命之间做较好的权衡，可以较好的满足线上业务需要。</li>
</ul>
<p>随着时间的推移，AOF 持续记录所有的写指令，<strong>AOF 会越来越大</strong>，而且会充斥大量的中间数据、过期数据，为了减少无效数据，提升恢复时间，<strong>可以定期对 AOF 进行 rewrite 操作</strong>。</p>
<ul>
<li>执行 bgrewiretaof 命令来进行</li>
<li>配置重写策略进行</li>
</ul>
<p><strong>AOF 进行 rewrite 流程：</strong></p>
<ul>
<li>首先会 fork 一个子进程。子进程轮询所有 <strong>RedisDB 快照</strong>，<strong>将所有内存数据转为 cmd，并写入临时文件</strong>。</li>
<li>在子进程 rewriteaof 时，主进程可以继续执行用户请求，执行完毕后将<strong>写指令写入旧的 AOF 文件和 rewrite 缓冲（增量数据指令）。</strong></li>
<li>子进程将 <strong>RedisDB 中数据落地完毕后</strong>，通知主进程。主进程从而<strong>将 AOF rewite 缓冲数据写入 AOF 临时文件</strong>，然后用新的 AOF 文件替换旧的 AOF 文件，最后通过 BIO 线程异步关闭旧的 AOF 文件。（<strong>即快照 + 增量数据</strong>）</li>
</ul>
<p><strong>优缺点</strong></p>
<ul>
<li><p><strong>优点</strong>：</p>
<ul>
<li>可以记录全部的最新内存数据，最多也就是 1-2 秒的数据丢失。</li>
<li>AOF 通过 Redis 协议来追加记录数据，兼容性高，而且可以持续轻量级的保存最新数据。</li>
<li>因为是直接通过 Redis 协议存储，可读性也比较好。</li>
</ul>
</li>
<li><p><strong>缺点</strong>：随着时间的增加，冗余数据增多，文件会持续变大，而且数据恢复需要读取所有命令并执行，恢复速度相对较慢。（定期rewrite）</p>
</li>
</ul>
<h5 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h5><p>Redis 在 4.0 版本之后，引入了混合持久化方式，而且在 5.0 版本后默认开启。</p>
<p>混合模式一体化使用 RDB 和 AOF，综合 RDB 和 AOF 的好处。即可包含全量数据，加载速度也比较快。可以使用 aof-use-rdb-preamble 配置来明确打开混合持久化模式。</p>
<p>混合持久化也是通过 bgrewriteaof 来实现的。当启用混合存储后，进行 bgrewriteaof 时，主进程首先依然是 fork 一个子进程，<strong>子进程首先将内存数据以 RDB 的二进制格式写入 AOF 临时文件中。然后，再将落地期间缓冲的新增写指令，以命令的方式追加到临时文件</strong>。</p>
<p><strong>优缺点</strong></p>
<ul>
<li><p>优点：包含全量数据，加载速度快。</p>
</li>
<li><p>缺点：头部的 RDB 格式兼容性和可读性较差。</p>
</li>
</ul>
<h4 id="Redis-BIO异步处理大任务"><a href="#Redis-BIO异步处理大任务" class="headerlink" title="Redis BIO异步处理大任务"></a><strong>Redis BIO异步处理大任务</strong></h4><p><strong>Redis</strong> 在运行过程中，不可避免的会产生一些运行慢的、容易引发阻塞的任务，而 Redis 的核心处理线程是单进程单线程模型，所有命令的接受与处理、数据淘汰等都在主线程中进行，这些任务处理速度非常快。如果核心单线程还要处理那些慢任务，在处理期间，势必会阻塞用户的正常请求，导致服务卡顿。</p>
<p>为此，<strong>Redis</strong> 引入了 <strong>BIO 后台线程</strong>，专门处理那些慢任务，从而保证和提升主线程的处理能力。</p>
<p><strong>Redis</strong> 的 BIO 线程采用<strong>生产者-消费者模型。主线程是生产者，生产各种慢任务，然后存放到任务队列中。</strong>BIO 线程是消费者，从队列获取任务并进行处理。</p>
<p>Redis 启动时，会创建<strong>三个任务队列，并对应构建 3 个 BIO 线程，三个 BIO 线程与 3 个任务队列之间一一对应</strong>，三个任务分别是：</p>
<ul>
<li><strong>close 关闭文件任务</strong>：rewriteaof 完成后，主线程需要关闭旧的 AOF 文件，就向 close 队列插入一个旧 AOF 文件的关闭任务。由 close 线程来处理。</li>
<li><strong>fysnc 任务</strong>：Redis 将 AOF 数据缓冲写入文件内核缓冲后，需要定期将系统内核缓冲数据写入磁盘，此时可以向 fsync 队列写入一个同步文件缓冲的任务，由 fsync 线程来处理。</li>
<li><strong>lazyfree 任务</strong>：Redis 在需要淘汰元素数大于 64 的聚合类数据类型时，如列表、集合、哈希等，就往延迟清理队列中写入待回收的对象，由 lazyfree 线程后续进行异步回收。</li>
</ul>
<p><strong>BIO 线程的整个处理流程：</strong></p>
<ul>
<li>当主线程有慢任务需要异步处理时。就会向对应的任务队列提交任务。提交任务时，首先申请内存空间，构建 BIO 任务。然后对队列锁进行加锁，在队列尾部追加新的 BIO 任务，最后尝试唤醒正在等待任务的 BIO 线程。</li>
<li>BIO 线程启动时或持续处理完所有任务，发现任务队列为空后，就会阻塞，并等待新任务的到来。当主线程有新任务后，主线程会提交任务，并唤醒 BIO 线程。BIO 线程随后开始轮询获取新任务，并进行处理。当处理完所有 BIO 任务后，则再次进入阻塞，等待下一轮唤醒。</li>
</ul>
<h4 id="Redis-多线程"><a href="#Redis-多线程" class="headerlink" title="Redis 多线程"></a>Redis 多线程</h4><p>Redis 自问世以来，广受好评，应用广泛。但相比， Memcached 单实例压测 TPS 可以高达百万，线上可以稳定跑 20-40 万而言，Redis 的单实例压测 TPS 不过 10-12 万，线上一般最高也就 2-4 万，<strong>仍相差一个数量级</strong>。</p>
<p>Redis 慢的<strong>主要原因是单进程单线程模型。</strong>虽然一些重量级操作也进行了分拆，如 RDB 的构建在子进程中进行，文件关闭、文件缓冲同步，以及大 key 清理都放在 BIO 线程异步处理，但还远远不够。</p>
<p>虽然可以通过<strong>多部署几个 Redis 实例来达到类似多线程的效果</strong>。但多实例部署则<strong>带来了运维复杂的问题</strong>，而且单机多实例部署，会相互影响，进一步增大运维的复杂度。</p>
<p>因此，Redis 即将在 6.0 版本引入多线程模型。Redis 的多线程模型，分为主线程和 IO 线程。</p>
<p>拭目以待….</p>
<blockquote>
<p>笔记来源：陈波 老师的 《300分钟吃透分布式缓存》课程</p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Redis/" rel="tag">Redis</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BC%93%E5%AD%98/" rel="tag">缓存</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0/" rel="tag">面试复习</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-缓存（二）-Memcached" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/"
    >缓存（二）- Memcached</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/" class="article-date">
  <time datetime="2021-03-15T07:42:58.000Z" itemprop="datePublished">2021-03-15</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="缓存（二）-Memcached"><a href="#缓存（二）-Memcached" class="headerlink" title="缓存（二）- Memcached"></a>缓存（二）- Memcached</h1><ul>
<li>特点：高性能、多线程、异步IO、KV存储、没有持久化</li>
<li>系统架构：多线程网络模型、哈希表、LRU、slab内存管理</li>
<li>基于libevent的多线程网络模型：主线程与工作线程分工</li>
<li>哈希表：原理，哈希扩容、哈希冲突</li>
<li>LRU淘汰策略：失效、删除</li>
<li>Slab内存管理机制：结构、内存分配流程</li>
<li>Mc协议指令：常见指令</li>
<li>Mc 常见问题及解决方案：Mc常用架构</li>
</ul>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote>
<p>Memcached 是一个高性能、分布式内存对象缓存系统，本质上是通用的，但目的是为了通过减轻数据库负载来加快动态网络应用的速度。</p>
<p>Memcached 是一个内存键值存储，用于存储来自数据库调用、API调用或页面渲染结果的小块任意数据（字符串、对象）。</p>
<p>Memcached 简单而强大。它简单的设计促进了快速部署，易于开发，并解决了大型数据缓存所面临的许多问题。其API可用于大多数流行的语言。</p>
<p>– 引自网络</p>
</blockquote>
<p><strong>Memcached</strong> 简称 <strong>Mc</strong>，特性有：</p>
<ul>
<li>是一个典型的<strong>内存型缓存组件</strong>，这就意味着：<ul>
<li>Mc 一旦重启就会丢失所有的数据。</li>
<li><strong>高性能</strong>，单节点压测性能能达到<strong>百万级的 QPS</strong>。</li>
</ul>
</li>
<li>Mc 采用<strong>多线程处理请求，由一个主线程和任意多个工作线程协作，从而充分利用多核，提升 IO 效率</strong>。</li>
<li>Mc 的<strong>访问协议很简单</strong>，只 有 get/set/cas/touch/gat/stats 等有限的几个命令。这跟它的存储结构也有关系。</li>
<li>Mc 的<strong>存储结构也很简单</strong>，只存储简单的 key/value 键值对，而且对 value 直接以<strong>二进制方式存储</strong>，不识别内部存储结构。</li>
<li>Mc的<strong>服务节点运行简单</strong>，不同 Mc 节点之间互不通信，由 client 自行负责管理数据分布（由 client 对 key 进行 Hash 后分布和协同）。</li>
</ul>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_05.png" alt="Memcached系统架构" style="zoom:80%;">

<p>Mc 的系统架构主要包括：</p>
<ul>
<li><strong>网络处理模块</strong>；</li>
<li><strong>多线程处理模块</strong>；</li>
<li><strong>哈希表</strong>；</li>
<li><strong>淘汰策略：LRU</strong>；</li>
<li><strong>slab 内存分配模块</strong> 。</li>
</ul>
<p>接下来我们分别了解各个模块。</p>
<h3 id="基于libevent的多线程网络IO模型"><a href="#基于libevent的多线程网络IO模型" class="headerlink" title="基于libevent的多线程网络IO模型"></a>基于libevent的多线程网络IO模型</h3><p>Mc 基于 <strong>Libevent</strong> 实现<strong>多线程网络 IO 模型</strong>。Mc 的 <strong>IO 处理线程分主线程和工作线程</strong>，每个线程各有一个 event_base，来监听网络事件。</p>
<ul>
<li><strong>主线程</strong>：负责监听及建立连接。</li>
<li><strong>工作线程</strong>：负责对建立的连接进行网络 IO 读取、命令解析、处理及响应。</li>
</ul>
<p><strong>作业流程：</strong></p>
<p>Mc 主线程在监听端口时，当有连接到来，<strong>主线程 accept 该连接</strong>，并将连接调度给工作线程。调度处理逻辑：主线程先<strong>将 fd 封装成一个 CQ_ITEM 结构，并存入新连接队列中，然后轮询一个工作线程，并通过管道向该工作线程发送通知。</strong>主线程的这个处理逻辑主要在<strong>状态机</strong>中执行，对应的连接状态为 <strong>conn_listening</strong>。</p>
<p>工作线程监听到主线程的管道通知后，会从连接队列弹出一个新连接，然后就会创建一个 <strong>conn</strong> 结构体，注册该 <strong>conn</strong> 读事件，然后继续监听该连接上的 IO 事件。后续这个连接有命令进来时，工作线程会读取 <strong>client</strong> 发来的命令，进行解析并处理，最后返回响应。工作线程的主要处理逻辑也是在<strong>状态机</strong>中。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_06.png" alt="IO工作流程" style="zoom:67%;">

<p><strong>状态机</strong></p>
<p>上面说到的<strong>状态机</strong>是由<strong>主线程和工作线程共享</strong>，实际是采用 <strong>switch-case</strong> 来实现的。switch 连接的 state，然后<strong>根据连接的不同状态，执行不同的逻辑操作</strong>，并进行状态转换。</p>
<p><img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_07.png" alt="状态机"></p>
<p><strong>主线程在状态机中只处理 conn_listening 状态，负责 accept 新连接和调度新连接给工作线程。状态机中其他状态处理基本都在工作线程中进行。</strong></p>
<p><strong>工作线程的状态机处理逻辑</strong>，包括刚建立 conn 连接结构体时进行的一些<strong>重置操作</strong>，然后<strong>注册读事件</strong>，在有数据进来时，<strong>读取网络数据</strong>，并进行<strong>解析并处理</strong>。如果是读取指令或统计指令，至此就基本处理完毕，接下来将响应写入连接缓冲。如果是更新指令，在进行初步处理后，还会继续<strong>读取 value 部分</strong>，再进行<strong>存储或变更</strong>，待变更完毕后<strong>将响应写入连接缓冲</strong>。最后<strong>再将响应写给 client</strong>。响应 client 后，连接会再次<strong>重置连接状态</strong>，等待<strong>进入下一次的命令处理循环</strong>中。</p>
<p><strong>工作线程状态事件及处理逻辑详解</strong>：</p>
<ul>
<li><p><strong>conn_new_cmd</strong>：主线程通过调用 <strong>dispatch_conn_new</strong>，把新连接调度给工作线程后，<strong>worker</strong> 线程创建 <strong>conn</strong> 对象，这个连接初始状态就是 <strong>conn_new_cmd</strong>。除了通过新建连接进入 <strong>conn_new_cmd</strong> 状态之外，如果连接命令处理完毕，准备接受新指令时，也会将连接的状态设置为 <strong>conn_new_cmd</strong> 状态。 </p>
</li>
<li><p><strong>conn_parse_cmd</strong>：工作线程处理完 <strong>conn_new_cmd</strong> 状态的主要逻辑后，如果读缓冲区有数据可以读取，则进入 <strong>conn_parse_cmd</strong> 状态，否则就会进入到 <strong>conn_waiting</strong> 状态，等待网络数据进来。</p>
</li>
<li><p><strong>conn_waiting</strong>：连接进入 conn_waiting 状态后，处理逻辑很简单，直接通过 update_event 函数注册读事件即可，之后会将连接状态更新为 conn_read。</p>
</li>
<li><p><strong>conn_read</strong>：当工作线程监听到网络数据进来，连接就进入 conn_read 状态。对 conn_read 的处理，是通过 try_read_network 从 socket 中读取网络数据。如果读取失败，则进入 conn_closing 状态，关闭连接。如果没有读取到任何数据，则会返回 conn_waiting，继续等待 client 端的数据到来。如果读取数据成功，则会将读取的数据存入 conn 的 rbuf 缓冲，并进入 conn_parse_cmd 状态，准备解析 cmd。</p>
</li>
<li><p><strong>conn_parse_cmd</strong>：conn_parse_cmd 状态的处理逻辑就是解析命令。工作线程首先通过 try_read_command 读取连接的读缓冲，并通过 \n 来分隔数据报文的命令。如果命令首行长度大于 1024，关闭连接，这就意味着 key 长度加上其他各项命令字段的总长度要小于 1024字节。当然对于 key，Mc 有个默认的最大长度，key_max_length，默认设置为 250字节。校验完毕首行报文的长度，接下来会在 process_command 函数中对首行指令进行处理。 process_command 用来处理 Mc 的所有协议指令，所以这个函数非常重要。process_command 会首先按照空格分拆报文，确定命令协议类型，分派给 process_XX_command 函数处理。 Mc 的命令协议从直观逻辑上可以分为获取类型、变更类型、其他类型。但从实际处理层面区分，则可以细分为 get 类型、update 类型、delete 类型、算术类型、touch 类型、stats 类型，以及其他类型。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_08.png" alt="命令协议" style="zoom:50%;">

<p>注意 conn_parse_cmd 的状态处理，只有读取到 \n，有了完整的命令首行协议，才会进入 process_command，否则会跳转到 conn_waiting，继续等待客户端的命令数据报文。在 process_command 处理中，如果是获取类命令，在获取到 key 对应的 value 后，则跳转到 conn_mwrite，准备写响应给连接缓冲。而对于 update 变更类型的指令，则需要继续读取 value 数据，此时连接会跳转到 conn_nread 状态。在 conn_parse_cmd 处理过程中，如果遇到任何失败，都会跳转到 conn_closing 关闭连接。</p>
</li>
<li><p><strong>complete_nread</strong>：对于 update 类型的协议指令，从 conn 继续读取 value 数据。读取到 value 数据后，会调用 complete_nread，进行数据存储处理；数据处理完毕后，向 conn 的 wbuf 写响应结果。然后 update 类型处理的连接进入到 conn_write 状态。</p>
</li>
<li><p><strong>conn_write</strong>：连接 conn_write 状态处理逻辑很简单，直接进入 conn_mwrite 状态。或者当 conn 的 iovused 为 0 或对于 udp 协议，将响应写入 conn 消息缓冲后，再进入 conn_mwrite 状态。</p>
</li>
<li><p><strong>conn_mwrite</strong>：进入 conn_mwrite 状态后，工作线程将通过 transmit 来向客户端写数据。如果写数据失败，跳转到 conn_closing，关闭连接退出状态机。如果写数据成功，则跳转到 conn_new_cmd，准备下一次新指令的获取。</p>
</li>
<li><p><strong>conn_closing</strong>：最后一个 conn_closing 状态，前面提到过很多次，在任何状态的处理过程中，如果出现异常，就会进入到这个状态，关闭连接，这个连接也就 Game Over了。</p>
</li>
</ul>
<p>总结Mc 对<strong>命令的处理全过程</strong>：</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_09.png" alt="Mc命令处理全流程" style="zoom:67%;">



<h3 id="LRU淘汰策略"><a href="#LRU淘汰策略" class="headerlink" title="LRU淘汰策略"></a>LRU淘汰策略</h3><p>Mc 作为缓存组件，意味着 Mc 中只能存储访问最频繁的热数据，一旦存入数据超过内存限制，就需要对 Mc 中的冷 key 进行淘汰工作。</p>
<p>Mc 中的 key 基本都会有过期时间，在 key 过期后，出于性能考虑，<strong>Mc 并不会立即删除过期的 key，而是由维护线程逐步清理，只有这个失效的 key 被访问时，才会进行删除，从而回收存储空间</strong>。</p>
<p>所以Mc的内存回收工作分为俩阶段：<strong>失效 和 删除</strong></p>
<h4 id="失效"><a href="#失效" class="headerlink" title="失效"></a><strong>失效</strong></h4><p><strong>失效方式分为俩种</strong>：</p>
<ul>
<li><p><strong>过期失效</strong>：指 key 在 expire 时间之后的过期</p>
</li>
<li><p><strong>flush_all 失效</strong>：如果缓存数据写入异常，出现大量脏数据，而又没有简单的办法快速找出所有的脏数据，可以用 flush_all <strong>立即让所有数据失效</strong>，通过 key 重新从 DB 加载的方式来保证数据的正确性。</p>
<p>该指令也可以通过 flush_all 指令后面加一个 expiretime 参数，可以让多个 Mc 在<strong>某个时间同时失效</strong>所有的 key。也可以将全局 setting 中的 oldest_live 设为指定 N 秒后的时间戳，即 N 秒后失效（<strong>延迟失效</strong>）；</p>
</li>
</ul>
<h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p><strong>删除分为三种</strong>：</p>
<ul>
<li><p><strong>惰性删除</strong>：失效的 key 被访问时，才会进行删除，从而回收存储空间。</p>
</li>
<li><p><strong>内存分配失败，LRU 同步淘汰</strong>：当需要对 Item 进行<strong>内存分配申请时，如果内存已全部用完</strong>，且该 Item 对应的slabclass 没有空闲的 chunk 可用，申请失败，则会对 LRU 队尾进行同步扫描，回收过期失效的 key，如果没有失效的 key，则会强制删除一个 key。</p>
</li>
<li><p>LRU 维护线程<strong>异步删除</strong>：不定期扫描 4 个 LRU 队列，对过期 key/value 进行异步淘汰。</p>
<p>在 key 进行读取、插入或变更时，<strong>同步进行 key 淘汰回收</strong>，并不是一种高效的办法，因为淘汰回收操作相比请求处理，也是一个重量级操作，<strong>会导致 Mc 性能大幅下降</strong>。因此 Mc 额外增加了一个 LRU 维护线程，对过期失效 key 进行回收。</p>
</li>
</ul>
<p>前面讲到，Mc 有 64 个 slabclass，其中 1-63 号 slabclass 用于存取 Item 数据。实际上，为了管理过期失效数据，<strong>1-63 号 slabclass 还分别对应了 4 个 LRU（双向链表），分布是 TEMP、HOT、WARM、COLD LRU。所以这就总共有 63*4 = 252 个 LRU。LRU 维护线程，会按策略间断 sleep，待 sleep 结束，就开始对 4 个 LRU 进行队尾清理工作。</strong></p>
<p><strong>四种 LRU 回收和迁移的要点如下：</strong></p>
<ul>
<li>Mc 在新写入 key 时，如果 key 的过期时间小于 61s，就会直接插入到 TEMP LRU 中，大于61s，就会直接插入到 HOT LRU。</li>
<li>LRU 维护线程处理时，TEMP LRU 是在独立循环中进行，其他三个 LRU 在另外一个循环中进行，如果 HOT、WARM、COLD LRU 清理或移动的 keys 数为 0，则那个 500 次的大循环就立即停止。</li>
<li>TEMP LRU 没有长度限制，且不进行队列内部的搬运和队列间的迁移，确保处理性能。</li>
<li><strong>TEMP LRU 回收</strong>：首先会对 TEMP LRU 队尾进行 500 次轮询，然后在每次轮询时，会进行 5 次小循环。小循环时，首先检查 key是否过期失效，如果失效则进行回收淘汰，然后继续小循环；如果遇到一个没失效的 key，则回收该 key 并退出 TEMP LRU 的清理工作。如果 TEMP LRU 队尾 key 全部失效，维护线程一次可以回收 500*5 共 2500 个失效的 key。</li>
<li><strong>HOT LRU 回收</strong>：同样500次大循环，5次小循环，遇到<ul>
<li>失效key则回收</li>
<li>非失效key,如果key状态是<ul>
<li>ACTIVE，则迁移至<strong>WARM LRU</strong></li>
<li>非 ACTIVE，如果 HOT LRU <strong>内存占用超过限制</strong>，则迁移到 <strong>COLD LRU</strong></li>
</ul>
</li>
</ul>
</li>
<li><strong>WARN LRU 回收</strong>：前提是 HOT LRU 中回收和迁移的 keys 数为 0才会进行， 同样500次大循环，5次小循环，遇到<ul>
<li>失效key则回收</li>
<li>非失效key,如果key状态是<ul>
<li>ACTIVE，则迁移至 <strong>LRU 头部</strong></li>
<li>非 ACTIVE，如果 WARN LRU <strong>内存占用超过限制</strong>，则迁移到 <strong>COLD LRU</strong></li>
</ul>
</li>
</ul>
</li>
<li><strong>COLD LRU 回收</strong>：前提是 WARN LRU 中回收和迁移的 keys 数为 0才会进行， 同样500次大循环，5次小循环，遇到<ul>
<li>失效key则回收</li>
<li>非失效key,如果key状态是<ul>
<li>ACTIVE，则迁移至 <strong>WARN LRU 头部</strong></li>
<li>非 ACTIVE，不处理，直接返回</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="slab内存管理机制"><a href="#slab内存管理机制" class="headerlink" title="slab内存管理机制"></a>slab内存管理机制</h3><p>Mc 内存分配采用 slab 机制，slab 机制可以规避内存碎片，是 Mc 能持续高性能进行数据读写的关键。</p>
<p>Mc 在启动时，会构建长度为 64 的 slabclass 数组，其中 0 号 slabclass 用于 slab 的重新分配，1~63 号 slabclass 存储数据 Item。</p>
<ul>
<li><p>Mc 在分配内存时，<strong>先将内存按固定大小划分成 slab，然后再将不同 slab 分拆出固定 size 的 chunk。</strong>虽然 slab 内的 chunk 大小相同，但不同 slab 的 chunk size 并不同，Mc 会按照一个固定比例，使划分的 chunk size 逐步增大，从而满足不同大小 key/value 存储的需要。</p>
</li>
<li><p><strong>一组具有相同 chunk size 的所有 slab，就组成一个 slabclass</strong>。不同 slabclass 的 chunk size 按递增因子一次增加。Mc 就通过 slabclass 来管理一组 slab 内的存储空间的。最后一个 slabclass（即 63 号 slabclass）的 chunk size 会直接设为最大的 chunk size，默认是 0.5MB。</p>
</li>
<li><p><strong>每个 slabclass 内部有一个 freelist</strong> ，包含这组 slab 里所有空闲的 chunk，当需要存储数据时，从这个 freelist 里面快速分配一个 chunk 做存储空间。当 Item 数据淘汰剔除时，这个 Item 所在的 chunk 又被回收至这个 freelist。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_11.png" alt="slabclass结构" style="zoom:67%;">
</li>
<li><p>当需要空间分配时，<strong>如果 Mc 有空闲空间，则从 slabclass 的 freelist 分配；如果没有空闲空间，则从对应 slabclass id 对应的 LRU 中剔除一个 Item，来复用这个 Item 的空间</strong>。</p>
</li>
<li><p>在查找或变更一个 key 时，首先要定位这个 key 所在的存储位置。<strong>Mc 是通过哈希表 Hashtable 来定位 key 的</strong>。</p>
</li>
<li><p>Mc 内部是<strong>通过 LRU 来管理存储 Item 数据</strong>的，当内存不足时，会从 LRU 队尾中剔除一个过期或最不活跃的 key，供新的 Item 使用。</p>
</li>
</ul>
<p>Mc 的存储空间分配是以 slab 为单位的，每个 slab 的默认大小时 1MB。因此在存数据时，<strong>Mc 的内存最小分配单位是 1MB。</strong></p>
<p><strong>Item</strong></p>
<p>Mc 中，slabclass 中的 chunk 会首先用 Item 结构体进行初始化，然后存到 freelist 链表中，待需要分配给数据存储时，再从 freelist 中取出，存入 key/value，以及各种辅助属性，然后再存到 LRU 链表及 Hashtable 中。</p>
<p>Item 结构体，首先有两个 <strong>prev、next 指针</strong>，在分配给待存储数据之前，这两个指针用来串联 freelist 链表，在分配之后，则用来串联所在的 LRU 链表。接下来是一个 <strong>h_next 指针</strong>，用来在分配之后串联哈希表的桶单向链表。Item 结构体还存储了<strong>过期时间、所属 slabclass id，key 长度、cas 唯一 id 值</strong>等，最后在 Item 结构体尾部，存储了 <strong>key、flag、value 长度，以及 value block 数据</strong>。在 value 之后的 chunk 空间，就被浪费掉了。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_12.png" alt="item结构" style="zoom:67%;">

<p>Item 在空闲期间，即<strong>初始分配时以及被回收后，都被 freelist 管理</strong>。</p>
<p>在<strong>存储期间，被哈希表、LRU 管理</strong>。</p>
<p><strong>数据分配流程：</strong></p>
<ul>
<li><strong>计算</strong>：当需要存储 key/value 数据时，首先根据 key/value size，以及 Item 结构体的 size，<strong>计算</strong>出存储这个 key/value 需要的字节数，然后根据这个字节数选择一个能存储的 chunk size 最小的 slabclass。</li>
<li><strong>分配</strong>：再从这个 slabclass 的 freelist 分配一个空闲的 chunk 给这个 key/value 使用。<ul>
<li>如果 <strong>freelist 为空</strong>，首先尝试为该 slabclass <strong>新分配一个 slab</strong>，如果 slab 分配成功，则将 slab 按 size 分拆出一些 chunk，通过 Item 结构初始化后填充到 freelist。</li>
<li>如果 <strong>slab 分配失败</strong>，则通过 LRU <strong>淘汰失效的 Item 或强行剔除一个正常的 Item</strong>，然后这些 Item 也会填充到 freelist。当 freelist 有 Item 时，即可分配给 key/value。这个过程会重试 10 次，直到分配到 Item 位置。</li>
</ul>
</li>
<li><strong>存入哈希表</strong>：当对 key/value 分配 Item 成功，并写入数据后，接下来就会将这个 Item 存入哈希表。</li>
<li><strong>存入LRU</strong>：然后这个 Item 还会被存入 LRU，Mc 会根据这个 key 的过期时间进行判断，如果过期时间小于 61s，则存入 TEMP LRU，否则存入 HOT LRU。</li>
</ul>
<p>如果最终分配失败，则会回复一个 <strong>SERVER_ERROR</strong> 响应，通知 <strong>client</strong> 存储失败。</p>
<h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><p><strong>背景</strong></p>
<p>Mc 将数据存储在 Item 中，然后这些 Item 会被 slabclass 的 4 个 LRU 管理。<strong>这些 LRU 都是通过双向链表实现数据记录的。双向链表在进行增加、删除、修改位置时都非常高效，但其获取定位 key 的性能非常低下，只能通过链表遍历来实现。</strong></p>
<p>因此，<strong>Mc 还通过 Hashtable，也就是哈希表，来记录管理这些 Item</strong>，通过对 key 进行哈希计算，从而快速定位和读取这些 key/value 所在的 Item。</p>
<img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%BA%8C%EF%BC%89-Memcached/cache_10.png" alt="HashTable作用" style="zoom:67%;">

<p>哈希表也称散列表，可以通过把 key 映射到哈希表中的一个位置来快速访问记录，定位 key 的时间复杂度只有 O(1)。Mc 的哈希表实际是一个一维指针数组，数组的每个位置称作一个 bucket，即一个桶。性能考虑的需要，Mc 的哈希表的长度设置为 2 的 N 次方。Mc 启动时，默认会构建一个拥有 6.4万 个桶的哈希表，随着新 key 的不断插入，哈希表中的元素超过阀值后，会对哈希表进行扩容，最大可以构建 2 的 32 次方个桶的哈希表。</p>
<p>用 哈希表就存在<strong>哈希冲突</strong>的问题，这里Mc 是通过<strong>单向链表</strong>解决hash冲突的。</p>
<p><strong>哈希表扩容</strong></p>
<p>当 Mc 的哈希表中，Item 数量大于 1.5 倍的哈希桶数量后，Mc 就对哈希表进行扩容处理。</p>
<p>Mc 的哈希扩容是通过哈希维护线程进行处理的。</p>
<p>准备开始扩容时，哈希维护线程会首先将所有 IO 工作线程和辅助线程进行<strong>暂停</strong>，其中辅助线程包括 LRU 维护线程、slab 维护线程、LRU 爬虫线程。待这些线程暂停后，哈希维护线程会将当前的主哈希表设为旧哈希表，然后将新的主哈希表<strong>扩容</strong>之前的 2 倍容量。然后，工作线程及辅助线程<strong>继续</strong>工作，同时哈希维护线程开始逐步将 Item 元素从旧哈希表<strong>迁移</strong>到主哈希表。</p>
<p><strong>锁哈希表</strong></p>
<p>Mc 在启动时，会根据设置的工作线程数，来构建 一个 Item 锁哈希表，线程越多，构建的锁哈希表越大，Mc 的锁哈希表中，每个桶对应一个 Item 锁，Item 锁哈希表最多有 32k 个桶，所以 Mc 最多只有 32768 个 Item 锁。</p>
<p>Mc 哈希表在读取、变更以及扩容迁移过程中，先将 key hash 定位到 Item 锁哈希表的锁桶，然后对 Item 锁进行加锁，然后再进行实际操作。实际上，除了在哈希表，在其他任何时候，只要涉及到在对 Item 的操作，都会根据 Item 中的 key，进行 Item 哈希锁桶加锁，以避免 Item 被同时读写而产生脏数据。</p>
<h2 id="Mc协议"><a href="#Mc协议" class="headerlink" title="Mc协议"></a>Mc协议</h2><h3 id="异常错误响应"><a href="#异常错误响应" class="headerlink" title="异常错误响应"></a>异常错误响应</h3><p>首先看一下Mc在发现异常后，如何进行异常错误响应的，这里是<strong>返回三种错误信息</strong>：</p>
<ul>
<li><strong>协议错误</strong>：一个”ERROR\r\n”的字符串。表明 client 发送了一个非法命令。</li>
<li><strong>client 错误</strong>：格式为”CLIENT_ERROR &lt;error-描述信息&gt;\r\n”。这个错误信息表明 ，client 发送的协议命令格式有误，比如少了字段、多了非法字段等。</li>
<li><strong>server 错误</strong>：格式为”SERVER_ERROR &lt;error-描述信息&gt;\r\n”。这个错误信息表明 Mc server 端，在处理命令时出现的错误。比如在给 key/value 分配 Item 空间失败后，会返回”SERVER_ERROR out of memory storing object” 错误信息。</li>
</ul>
<p>除了错误响应外，还有四种正常的响应，分别为：</p>
<ul>
<li>“<strong>STORED\r\n</strong>”：存储修改成功</li>
<li>“<strong>EXISTS\r\n</strong>”：待 cas 的key 已经被修改过了</li>
<li>“<strong>NOT_STORED\r\n</strong>“：数据没有存储成功，但并不是遇到错误或异常</li>
<li>“<strong>NOT_FOUND\r\n</strong>“：待 cas 的 key 在 Mc 中不存在</li>
</ul>
<h3 id="协议分类"><a href="#协议分类" class="headerlink" title="协议分类"></a>协议分类</h3><p>Mc 协议对应着相应的<strong>操作指令</strong>，主要分为三种：</p>
<ul>
<li>存储协议：Mc 存储指令分 2 行。第一行是<strong>报文首部</strong>，第二行是 <strong>value 的 data block 块</strong>。这两部分用 \r\n 来进行分割和收尾。存储协议指令共有6个：<ul>
<li><strong>Set</strong> 指令用于存储一个 key/value；</li>
<li><strong>Add</strong> 指令是在当 key 不存在时，才存储这个 key/value；</li>
<li><strong>Replace</strong> 指令，是当 key 存在时，才存储这个 key/value；</li>
<li><strong>Append</strong> 指令，是当 key 存在时，追加 data 到 value 的尾部；</li>
<li><strong>Prepend</strong> 指令，是当 key 存在时，将 data 加到 value 的头部</li>
<li><strong>cas</strong> 指令，是指只有当这个 key 存在，且从本 client 获取以来，没有其他任何人修改过时，才进行修改，cas 的英文含义是 compare and set，即比较成功后设置的意思。</li>
</ul>
</li>
<li>获取协议：<ul>
<li><strong>get</strong> 指令：get 指令只获取 key 的 flag 及 value</li>
<li><strong>gets</strong> 指令： gets 会额外多获取一个 cas unique id值。gets 主要是为 cas 指令服务的。</li>
</ul>
</li>
<li>其他协议：Mc 的其他协议指令包括 delete、incr、decr、touch、gat、gats、slabs、lru、stats 这 9 种指令。<ul>
<li><strong>delete</strong> 用于删除一个 key。</li>
<li><strong>incr/decr</strong> 用于对一个无符号长整型数字进行加或减。</li>
<li><strong>touch、gat、gats</strong> 都可以用来修改 key 的过期时间。不同点是 touch 只修改 key 的过期时间，不获取 key对应的value。而 gat、gats 指令，不仅会修改 key 的过期时间，还会获取 key 对应的 flag 和 value 数据。gats 同 gets，还会额外获取 cas 唯一 id 值。</li>
<li><strong>slabs automove</strong> 是一个开关指令，当打开时，就允许 Mc 后台线程自行决定何时将 slab 在slabclass 之间重新分配。</li>
<li><strong>lru</strong> 指令用于 Mc LRU 的设置和调优。</li>
<li><strong>stats</strong> 指令用于获取 Mc 的各种统计数据。</li>
</ul>
</li>
</ul>
<h2 id="Mc常见问题"><a href="#Mc常见问题" class="headerlink" title="Mc常见问题"></a>Mc常见问题</h2><p>Mc 在互联网企业应用广泛，热门语言基本都有 Mc client 的实现。</p>
<h3 id="Java-Mc-Client-实现对比"><a href="#Java-Mc-Client-实现对比" class="headerlink" title="Java Mc Client 实现对比"></a>Java Mc Client 实现对比</h3><ul>
<li>Memcached-Java-Client：推出时间早，性能一般，但足够稳定，不过这个 client 几年前就停止了更新。</li>
<li>SpyMemcached：出现的比较晚，性能较好，但高并发访问场景，稳定性欠缺。近几年变更很少，基本停止了更新。</li>
<li><strong>Xmemcached</strong>： <strong>性能较好，综合表现最佳。</strong>而且社区活跃度高，近些年也一直在持续更新中。Java 新项目启动，推荐使用 Xmemcached。</li>
</ul>
<h3 id="通用调优方案"><a href="#通用调优方案" class="headerlink" title="通用调优方案"></a>通用调优方案</h3><ul>
<li>读写的 key/value 较大，需要设置更大的缓冲 buf，以提高性能。</li>
<li>一些业务场景中，需要启用 TCP_NODELAY，避免 40ms 的延迟问题。</li>
<li>存取的 key/value size 较大，可以设置一个压缩阀值，超过阀值，就对value 进行压缩算法，减少读写及存储的空间。</li>
<li>为了避免缓存雪崩，并更好地应对极热 key 及洪水流量的问题，还可以对 Mc client 进行封装，加入多副本、多层级策略，使 Mc 缓存系统在任何场景下，都可做到高可用、高性能。</li>
</ul>
<h3 id="大数据时代-Mc-经典问题"><a href="#大数据时代-Mc-经典问题" class="headerlink" title="大数据时代 Mc 经典问题"></a><strong>大数据时代 Mc 经典问题</strong></h3><ul>
<li><strong>容量问题</strong>：大数据时代，互联网系统中的很多核心业务，需要缓存的热数据在 300~500GB 以上，远远超过单机物理内存的容量。</li>
<li><strong>性能瓶颈</strong>：线上访问QPS过大，单个物理机、单个资源池很难达到线上的业务要求。</li>
<li><strong>连接瓶颈</strong>：业务实例的连接数远超过单个机器的稳定支撑范围。</li>
<li><strong>硬件资源局部故障</strong>：对于数以万计的硬件设备，随时都有可能出现机器故障，从而导致 Mc 节点访问性能下降、宕机，海量访问穿透到 DB，引发 DB 过载，最终导致整个系统无法访问，引发雪崩现象。</li>
<li><strong>流量洪峰下快速扩展</strong>：大数据时代，由于信息扩散的扁平化，突发事件、重大活动发生时，海量用户同时蜂拥而至，短时间引发巨大流量，很容易出现 CPU 飙升、带宽打满、机器负荷严重过载的现象。</li>
</ul>
<h3 id="Mc-常用架构"><a href="#Mc-常用架构" class="headerlink" title="Mc 常用架构"></a>Mc 常用架构</h3><p><strong>为了解决大中型互联网系统在使用 Mc 时的这些问题。我们可以使用下面的解决方案。</strong></p>
<ul>
<li><p><strong>Memcached 分拆缓存池</strong> ：对系统内的核心业务数据进行分拆，让访问量大的数据，使用独立的缓存池。    对于缓存池的<strong>分布策略</strong>，可以采用<strong>一致性哈希分布</strong>和<strong>哈希取模分布</strong>。Mc 节点故障不可避免，在 Mc 节点故障下线后，如果采用一致性 hash 分布，可以方便的通过 <strong>rehash 策略</strong>，将该 Mc 节点的 hash 点、访问量，均匀分散到其他 Mc 节点。如果采用取模分布，则会直接导致 1/N 的访问 miss，N 是 Mc 资源池的节点数。</p>
</li>
<li><p><strong>Master-Slave 两级架构</strong>：如果某些缓存服务器短期多次故障，反复上下线，多次 rehash 还会产生脏数据。对此，可以采用 Master-Slave 的两级架构方案。</p>
<p>对于读操作，直接访问 master，如果访问 miss，再访问 slave。如果 slave 命中，就将读取到的 key 回写到 master。对于写操作，set、touch 等覆盖类指令，直接更新master 和 slave；而 cas、append 等，以 master 为准，master 在 cas、add 成功后，再将 key 直接 set 到 slave，以保持 master、slave 的数据一致性。</p>
</li>
<li><p><strong>M-S-L1 架构</strong>：80% 的请求会集中在 20% 的数据上，这种现象在互联网系统中广泛存在，我们可以通过在Master-Slave 两级架构基础上增加 L1 层来解决。<strong>L1 层用来缓存日常峰值的热数据</strong>。</p>
<p>读请求时，首先随机选择一个 L1 进行读取，如果 miss 则访问 master，如果 master 也 miss，最后访问 slave。中途，只要任何一层命中，则对上一层资源池进行回写。</p>
</li>
</ul>
<blockquote>
<p>笔记来源：陈波 老师的 《300分钟吃透分布式缓存》课程</p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Memcached/" rel="tag">Memcached</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BC%93%E5%AD%98/" rel="tag">缓存</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0/" rel="tag">面试复习</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
    <article id="post-缓存（一）-基础概念" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%80%EF%BC%89-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"
    >缓存（一）- 基础概念</a> 
</h2>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%80%EF%BC%89-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/" class="article-date">
  <time datetime="2021-03-15T07:36:45.000Z" itemprop="datePublished">2021-03-15</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a>
  </div>

      
      
      
    </div>
    

    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h1 id="缓存（一）-基础概念"><a href="#缓存（一）-基础概念" class="headerlink" title="缓存（一）- 基础概念"></a>缓存（一）- 基础概念</h1><ul>
<li><p>概念：缓存思想、优缺点、读写模式、缓存分类</p>
</li>
<li><p>缓存设计：组件选择、数据结构设计、数据分布设计、缓存架构部署及运维管理、设计考量点</p>
</li>
<li><p>缓存问题：缓存失效、缓存穿透、缓存雪崩、数据不一致、数据并发竞争、Hot key 、Big key 问题</p>
</li>
</ul>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><strong>缓存</strong>最初的含义，是指用于加速 <strong>CPU</strong> 数据交换的 <strong>RAM</strong>，即随机存取存储器，通常这种存储器使用更昂贵但快速的静态 <strong>RAM</strong>（<strong>SRAM</strong>）技术，用以对 <strong>DRAM</strong>进行加速。这是一个狭义缓存的定义。</p>
<p>而广义缓存的定义则更宽泛，<strong>任何可以用于数据高速交换的存储介质都是缓存</strong>，可以是硬件也可以是软件。</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><h4 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h4><p><strong>缓存构建的基本思想</strong>是利用时间局限性原理，通过空间换时间来达到加速数据获取的目的，同时由于缓存空间的成本较高，在实际设计架构中还要考虑访问延迟和成本的权衡问题。</p>
<ul>
<li>时间局限性原理：即被获取过一次的数据在未来会被多次引用；</li>
<li>空间换时间：因为原始数据获取太慢，所以我们开辟一块高速独立空间，提供高效访问，来达到数据获取加速的目的；</li>
<li>性能成本：性能越高延迟越小，成本也会越高，所以在系统架构设计时，你需要在系统性能和开发运行成本之间做取舍。</li>
</ul>
<h4 id="优势与代价"><a href="#优势与代价" class="headerlink" title="优势与代价"></a>优势与代价</h4><p><strong>优点：</strong></p>
<ul>
<li><strong>提升访问性能</strong>：高速独立空间，提升访问效率。</li>
<li><strong>降低网络拥堵</strong>：在实际业务场景中，缓存中存储的往往是需要频繁访问的中间数据甚至最终结果，这些数据相比 DB 中的原始数据小很多，这样就可以减少网络流量，降低网络拥堵。</li>
<li><strong>减轻服务器负载</strong>：由于中间数据复用，减少了解析和计算，调用方和存储服务的负载也可以大幅降低。</li>
<li><strong>增强可扩展性</strong>：缓存的读写性能很高，预热快，在数据访问存在性能瓶颈或遇到突发流量，系统读写压力大增时，可以快速部署上线，同时在流量稳定后，也可以随时下线，从而使系统的可扩展性大大增强。</li>
</ul>
<p>任何事情都有两面性，缓存也不例外，我们在享受缓存带来一系列好处的同时，也注定需要付出一定的代价。</p>
<p><strong>代价</strong>：</p>
<ul>
<li><strong>增加系统复杂度</strong>：毫无疑问，引入缓存会增加系统复杂度，同时还面临许多新的问题，例如缓存不一致、缓存更新、缓存击穿、缓存雪崩等问题；</li>
<li><strong>费用成本高</strong>：缓存相比原始 <strong>DB</strong> 存储的成本更高，所以系统部署及运行的费用也会更高。</li>
<li><strong>学习投入</strong>：除了上面说的缓存一致性问题外，缓存体系本身也会存在可用性问题和分区的问题。这就需要我们加强对缓存原理、缓存组件以及优秀缓存体系实践的理解，从系统架构之初就对缓存进行良好设计，降低缓存引入的副作用。</li>
</ul>
<h4 id="缓存读写模式"><a href="#缓存读写模式" class="headerlink" title="缓存读写模式"></a>缓存读写模式</h4><p>业务系统读写缓存有 <strong>3 种</strong>模式：</p>
<ul>
<li><strong>Cache Aside</strong>（旁路缓存）</li>
<li><strong>Read/Write Through</strong>（读写穿透）</li>
<li><strong>Write Behind Caching</strong>（异步缓存写入）</li>
</ul>
<p><strong>Cache Aside</strong>（旁路缓存）</p>
<p><strong>Cache Aside</strong> 模式中，业务应用方对于写，是更新 <strong>DB</strong> 后，直接将 <strong>key</strong> 从 <strong>cache</strong> 中删除，然后由 <strong>DB</strong> 驱动缓存数据的更新（例如Trigger组件）；而对于读，是先读 <strong>cache</strong>，如果 <strong>cache</strong> 没有，则读 <strong>DB</strong>，同时将从 <strong>DB</strong> 中读取的数据回写到 <strong>cache</strong>。</p>
<p><img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%80%EF%BC%89-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/cache_02.png" alt="Cache Aside"></p>
<p><strong>特点：</strong></p>
<ul>
<li>适用于数据一致性要求比较高的业务；</li>
<li>适用于缓存更新比较复杂的业务；</li>
</ul>
<p><strong>Read/Write Through</strong>（读写穿透）</p>
<p>相对于 <strong>Cache Aside</strong> 模式，业务应用需要同时维护 <strong>cache</strong> 和 <strong>DB</strong> 两个数据存储方，过于繁琐，于是就有了 <strong>Read/Write Through</strong> 模式。</p>
<p>在这种模式下，业务应用<strong>只关注一个存储服务</strong>即可，业务方的读写 <strong>cache</strong> 和 <strong>DB</strong> 的操作，都由存储服务代理。存储服务收到业务应用的写请求时，会首先查 <strong>cache</strong>，如果数据在 <strong>cache</strong> 中不存在，则只更新 <strong>DB</strong>，如果数据在 <strong>cache</strong> 中存在，则先更新 <strong>cache</strong>，然后更新 <strong>DB</strong>。而存储服务收到读请求时，如果命中 <strong>cache</strong> 直接返回，否则先从 <strong>DB</strong> 加载，回种到 <strong>cache</strong> 后返回响应。</p>
<p><img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%80%EF%BC%89-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/cache_03.png" alt="Read/Write Throuth"></p>
<p><strong>特点：</strong></p>
<ul>
<li><p>存储服务封装了所有的数据处理细节，业务应用端代码只用关注业务逻辑本身，系统的隔离性更佳。</p>
</li>
<li><p>进行写操作时，如果 cache 中没有数据则不更新，有缓存数据才更新，内存效率更高。</p>
</li>
</ul>
<p><strong>Write Behind Caching</strong>（异步缓存写入）</p>
<p><strong>Write Behind Caching</strong> 模式与 <strong>Read/Write Through</strong> 模式类似，也由数据存储服务来管理 <strong>cache</strong> 和 <strong>DB</strong> 的读写。不同点是，数据更新时，<strong>Read/write Through</strong> 是<strong>同步更新</strong> <strong>cache</strong> 和 <strong>DB</strong>，而 <strong>Write Behind Caching</strong> 则是<strong>只更新缓存，不直接更新 DB</strong>，而是改为<strong>异步</strong>批量的方式来更新 <strong>DB</strong>。</p>
<p><img src="/2021/03/15/%E7%BC%93%E5%AD%98%EF%BC%88%E4%B8%80%EF%BC%89-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/cache_04.png" alt="Write Behind Caching"></p>
<p><strong>特点：</strong></p>
<ul>
<li><p>数据存储的写性能最高，非常适合一些变更特别频繁的业务；</p>
</li>
<li><p>非常适合<strong>合并写</strong>请求的业务，比如对一些计数业务，一条 Feed 被点赞 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作；</p>
</li>
<li><p>缺点是数据一致性变差，<strong>DB</strong>如果更新不成功可能会有数据丢失。</p>
</li>
</ul>
<h3 id="缓存分类"><a href="#缓存分类" class="headerlink" title="缓存分类"></a>缓存分类</h3><h4 id="宿主层次分类"><a href="#宿主层次分类" class="headerlink" title="宿主层次分类"></a>宿主层次分类</h4><ul>
<li><strong>本地缓存：</strong>是指业务进程内的缓存，这类缓存由于在业务系统进程内，所以读写性能超高且无任何网络开销，但不足是会随着业务系统重启而丢失</li>
<li><strong>进程间缓存</strong>：是本机独立运行的缓存，这类缓存读写性能较高，不会随着业务系统重启丢数据，并且可以大幅减少网络开销，但不足是业务系统和缓存都在相同宿主机，运维复杂，且存在资源竞争，受宿主机资源限制。</li>
<li><strong>远程缓存</strong>：指跨机器部署的缓存，这类缓存因为独立设备部署，容量大且易扩展，在互联网企业使用最广泛。不过远程缓存需要跨机访问，在高读写压力下，带宽容易成为瓶颈。例如分布式缓存。</li>
</ul>
<h4 id="存储介质分类"><a href="#存储介质分类" class="headerlink" title="存储介质分类"></a>存储介质分类</h4><ul>
<li><strong>内存型缓存</strong>：将数据存储在内存，读写性能很高，但缓存系统重启或 <strong>Crash</strong> 后，内存数据会丢失；</li>
<li><strong>持久化型缓存</strong>：将数据存储到 <strong>SSD/Fusion-IO</strong> 硬盘中，相同成本下，这种缓存的容量会比内存型缓存大 1 个数量级以上，而且数据会持久化落地，重启不丢失，但读写性能相对低 1～2 个数量级。<strong>Memcached</strong> 是典型的内存型缓存。</li>
</ul>
<h3 id="缓存设计考虑因素"><a href="#缓存设计考虑因素" class="headerlink" title="缓存设计考虑因素"></a>缓存设计考虑因素</h3><h4 id="缓存组件选择"><a href="#缓存组件选择" class="headerlink" title="缓存组件选择"></a><strong>缓存组件选择</strong></h4><p>在设计架构缓存时，你首先要选定缓存组件，比如要用 <strong>Local-Cache</strong>，还是 <strong>Redis</strong>、<strong>Memcached</strong>、<strong>Pika</strong> 等开源缓存组件，需要根据业务需求做出相应选择。</p>
<h4 id="数据结构设计"><a href="#数据结构设计" class="headerlink" title="数据结构设计"></a><strong>数据结构设计</strong></h4><p>对于直接简单 <strong>KV</strong> 读写的业务，你可以将这些业务数据封装为 <strong>String</strong>、<strong>Json</strong>、<strong>Protocol Buffer</strong> 等格式，序列化成字节序列，然后直接写入缓存中。读取时，先从缓存组件获取到数据的字节序列，再进行反序列化操作即可。</p>
<p>对于只需要存取部分字段或需要在缓存端进行计算的业务，你可以把数据设计为 <strong>Hash</strong>、<strong>Set</strong>、<strong>List</strong>、<strong>Geo</strong> 等结构，存储到支持复杂集合数据类型的缓存中，如 <strong>Redis</strong>、<strong>Pika</strong> 等。</p>
<h4 id="数据分布设计"><a href="#数据分布设计" class="headerlink" title="数据分布设计"></a><strong>数据分布设计</strong></h4><ul>
<li><strong>确认数据分布算法</strong>，例如<strong>取模</strong>或者<strong>一致性hash</strong>分布。取模分布的方案简单，每个 key 只会存在确定的缓存节点，一致性 Hash 分布的方案相对复杂，一个 key 对应的缓存节点不确定。但一致性 Hash 分布，可以在部分缓存节点异常时，将失效节点的数据访问均衡分散到其他正常存活的节点，从而更好地保证了缓存系统的稳定性。</li>
<li><strong>分布读写访问方式</strong>，一种是由缓存 <strong>Client</strong> 直接进行 <strong>Hash</strong> 分布定位读写，另一种是通过 Proxy 代理来进行读写路由。前者是Client 直接读写，读写性能最佳，但需要 Client 感知分布策略。在缓存部署发生在线变化时，也需要及时通知所有缓存 Client，对业务系统侵入较强；后者通过 Proxy 路由，Client 只需直接访问 Proxy，分布逻辑及部署变更都由 Proxy 来处理，对业务应用开发最友好，但业务访问多一跳，访问性能会有一定的损失。</li>
<li><strong>缓存节点动态拆分</strong>，缓存系统运行过程中，如果待缓存的数据量增长过快，会导致大量缓存数据被剔除，缓存命中率会下降，数据访问性能会随之降低，这样就需要将数据从缓存节点进行动态拆分，把部分数据水平迁移到其他缓存节点。这个迁移过程需要考虑，是由 Proxy 进行迁移还是缓存 Server 自身进行迁移，甚至根本就不支持迁移。</li>
</ul>
<h4 id="缓存架构部署及运维管理"><a href="#缓存架构部署及运维管理" class="headerlink" title="缓存架构部署及运维管理"></a><strong>缓存架构部署及运维管理</strong></h4><ul>
<li><strong>分池：</strong>核心的、高并发访问的不同数据，需要分别分拆到独立的缓存池中，进行分别访问，避免相互影响；访问量较小、非核心的业务数据，则可以混存；</li>
<li><strong>分层：</strong>对海量数据、访问超过 10～100万 级的业务数据，要考虑分层访问，并且要分摊访问量，避免缓存过载。</li>
<li><strong>跨IDC部署</strong>：由于实际场景下，业务系统可能需要多IDC（互联网数据中心）部署，则需要对缓存体系也进行多 IDC 部署，跨 IDC 缓存数据更新，可以采用直接跨 IDC 读写，也可以采用 DataBus 配合队列机进行不同 IDC 的消息同步，然后由消息处理机进行缓存更新，还可以由各个 IDC 的 DB Trigger 进行缓存更新。</li>
</ul>
<h4 id="常见考量点"><a href="#常见考量点" class="headerlink" title="常见考量点"></a><strong>常见考量点</strong></h4><ul>
<li><p><strong>读写方式</strong>：全部读写，还是部分读写，或者缓存服务器负责部分计算等；</p>
</li>
<li><p><strong>KV size</strong>：单个业务的 <strong>KV size</strong> 过大，需要分拆成多个 <strong>KV</strong> 来缓存；不同缓存数据的 <strong>KV size</strong> 如果差异过大，也不能缓存在一起，避免缓存效率的低下和相互影响。</p>
</li>
<li><p><strong>key 数量</strong>：<strong>key</strong>数量不大，则缓存全量数据，不存在也不需要再查数据库；<strong>key</strong> 数量较大，则冷热数据分离，缓存中尽可能只保留频繁访问的热数据，对于冷数据直接访问 <strong>DB</strong>。</p>
</li>
<li><p><strong>读写峰值</strong>：峰值过大，如果小于 10万 级别，简单分拆到独立 Cache 池即可；超过 10万 甚至到达 100万 级的QPS，则需要对 Cache 进行分层处理，可以同时使用 Local-Cache 配合远程 cache，甚至远程缓存内部继续分层叠加分池进行处理。</p>
</li>
<li><p><strong>命中率</strong>：缓存的命中率对整个服务体系的性能影响甚大。对于核心高并发访问的业务，需要预留足够的容量，确保核心业务缓存维持较高的命中率。为了持续保持缓存的命中率，缓存体系需要持续监控，及时进行故障处理或故障转移。同时在部分缓存节点异常、命中率下降时，故障转移方案，需要考虑是采用一致性 <strong>Hash</strong> 分布的访问漂移策略，还是采用数据多层备份策略。</p>
</li>
<li><p><strong>淘汰策略：</strong></p>
<ul>
<li><strong>FIFO</strong>: 先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用FIFO,使最先进入的数据(最晚的数据)被淘汰。</li>
<li><strong>LFU</strong>: 最少使用策略：<br>无论是否过期，根据元素被使用次数判断，清除使用次数较少的元素释放空间。算法主要比较元素的hitcount(命中次数)，在保证高频数据有效性的场景下，可是使用这类策略。</li>
<li><strong>LRU</strong>(Least Recently Used): 最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次访问时间举例现在最远的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。</li>
<li>根据过期时间判断，清理过期时间最长的元素；（可以使用较短过期时间或者key 带时间戳的方式）</li>
<li>根据过期时间判断，清理最近要过期的元素；</li>
<li>随机清理；</li>
</ul>
</li>
<li><p><strong>缓存可以运维性</strong>：对于缓存的可运维性考虑，则需要考虑缓存体系的集群管理，如何进行一键扩缩容，如何进行缓存组件的升级和变更，如何快速发现并定位问题，如何持续监控报警，最好有一个完善的运维平台，将各种运维工具进行集成。</p>
</li>
<li><p><strong>缓存安全性</strong>：对于缓存的安全性考虑，一方面可以限制来源 IP，只允许内网访问，同时对于一些关键性指令，需要增加访问权限，避免被攻击或误操作时，导致重大后果。</p>
</li>
</ul>
<h3 id="缓存常见问题"><a href="#缓存常见问题" class="headerlink" title="缓存常见问题"></a>缓存常见问题</h3><p>缓存常见七大问题：</p>
<ul>
<li>缓存失效</li>
<li>缓存穿透</li>
<li>缓存雪崩</li>
<li>数据一致性</li>
<li>数据并发竞争</li>
<li>Hot Key</li>
<li>Big Key</li>
</ul>
<h4 id="缓存失效"><a href="#缓存失效" class="headerlink" title="缓存失效"></a>缓存失效</h4><p><strong>问题描述：</strong>大量缓存同时失效（DB批量更新缓存，设置相同过期时间），查询穿透到DB，DB短时间内查询量过大，导致性能问题。</p>
<p><strong>解决方案：</strong>将过期时间设置为：<strong>过期时间 = baes 时间 + 随机时间</strong>，即相同业务数据写缓存时，在基础过期时间之上，再加一个随机的过期时间，让数据在未来一段时间内慢慢过期，避免瞬时全部过期，对 DB 造成过大压力。</p>
<h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><p><strong>问题描述</strong>：批量查询一个不存在的<strong>key</strong>，导致每次查询都会穿透到 <strong>DB</strong>，<strong>DB</strong>压力过大，影响正常服务。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li><strong>缓存非法key</strong>：查询这些不存在的数据时，第一次查 DB，虽然没查到结果返回 NULL，仍然记录这个 key 到缓存，只是这个 key 对应的 value 是一个特殊设置的值。但是如果不存在的 key 数量过多，会占用大量缓存空间，可以设置较短的过期时间，防止非法 key 占用过多缓存空间；也可以设立独立缓存空间存储非法key，从缓存查找时，先查正常的缓存组件，如果 miss，则查一下公共的非法 key 的缓存，如果后者命中，直接返回，否则穿透 DB，如果查出来是空，则回种到非法 key 缓存，否则回种到正常缓存。</li>
<li><strong>布隆过滤器（BloomFilter）</strong>：构建一个 BloomFilter 缓存过滤器，访问数据时，可以直接通过 BloomFilter 判断这个 key 是否存在，如果不存在直接返回即可，根本无需查缓存和 DB。BloomFilter 可以缓存全量数据key，但是数量不宜过多，也可以用来缓存非法key集合，但是累计非法 key 数量会持续增长，可以用过设置过期时间定期清理。</li>
</ul>
<h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h4><p><strong>问题描述</strong>： 缓存雪崩是指部分缓存节点不可用，导致整个缓存体系甚至甚至服务系统不可用的情况。</p>
<ul>
<li><strong>缓存节点不支持 rehash</strong>，较多缓存节点不可用时，大量 Cache 访问会失败，根据缓存读写模型，这些请求会进一步访问 DB，造成 DB 过载，大量慢查询，最终阻塞甚至 Crash，从而导致服务异常。</li>
<li><strong>缓存节点支持 rehash</strong>，一致性 Hash 分布方式中，在部分节点异常时，采用 rehash 策略，即把异常节点请求平均分散到其他缓存节点。但在较大的流量洪峰到临之时，如果大流量 key 比较集中，正好在某 1～2 个缓存节点，很容易将这些缓存节点的内存、网卡过载，缓存节点异常 Crash，然后这些异常节点下线，这些大流量 key 请求又被 rehash 到其他缓存节点，进而导致其他缓存节点也被过载 Crash，缓存异常持续扩散，最终导致整个缓存体系异常，无法对外提供服务。</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ul>
<li>针对 DB 增加读写开关，当发现 DB 请求变慢、阻塞，慢请求超过阀值时，就会关闭读开关，部分或所有读 DB 的请求进行 failfast 立即返回，待 DB 恢复后再打开读开关；</li>
<li>增加缓存副本，缓存异常或请求 miss 后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务；</li>
<li>对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。</li>
</ul>
<h4 id="数据不一致"><a href="#数据不一致" class="headerlink" title="数据不一致"></a>数据不一致</h4><p><strong>问题描述</strong>：DB 和 缓存数据不一致（缓存更新异常，缓存多次rehash 也可能导致节点脏数据）。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>cache 更新失败后，可以进行重试，如果重试失败，则将失败的 key 写入队列机服务，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性。</li>
<li>缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。</li>
<li>不采用 rehash 漂移策略，而采用缓存分层策略，尽量避免脏数据产生。</li>
</ul>
<h4 id="数据并发竞争"><a href="#数据并发竞争" class="headerlink" title="数据并发竞争"></a>数据并发竞争</h4><p><strong>问题描述</strong>：是指在高并发访问场景，一旦缓存访问没有找到数据，大量请求就会并发查询 DB，导致 DB 压力大增的现象。主要是由于多个进程/线程中，有大量并发请求获取相同的数据，而这个数据 key 因为正好过期、被剔除等各种原因在缓存中不存在，这些进程/线程之间没有任何协调，然后一起并发查询 DB，请求那个相同的 key，最终导致 DB 压力大增。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li><strong>加全局锁</strong>：当缓存请求 miss 后，先尝试加全局锁，只有加全局锁成功的线程，才可以到 DB 去加载数据。其他进程/线程在读取缓存数据 miss 时，如果发现这个 key 有全局锁，就进行等待，待之前的线程将数据从 DB 回种到缓存后，再从缓存获取。</li>
<li><strong>增加缓存备份</strong>：对缓存数据保持多个备份，即便其中一个备份中的数据过期或被剔除了，还可以访问其他备份。</li>
</ul>
<h4 id="Hot-key"><a href="#Hot-key" class="headerlink" title="Hot key"></a>Hot key</h4><p><strong>问题描述</strong>：大多数互联网系统，数据是分冷热的，当超大量的请求同时访问热点数据对应的缓存节点（比如微博热点新闻），缓存机器很容易被打到物理网卡、带宽、CPU 的极限，从而导致缓存访问变慢、卡顿。</p>
<p><strong>解决方案</strong>：</p>
<p><strong>Hot key</strong> 问题的关键是先找到 <strong>Hot key</strong> ，然后对 <strong>Hot key</strong> 进行分散处理，可以被分散为 hotkey#1、hotkey#2、hotkey#3，……hotkey#n，这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载。</p>
<p>根据现实场景，<strong>Hot key</strong> 可以分为 <strong>可以预知的Hot key</strong>（例如重要节假日、线上促销活动等） ，和 <strong>突发的Hot key</strong> （例如突发事件）</p>
<ul>
<li>对于可预知的 Hot key ，可以提前部署，对 Hot key 缓存分散处理。</li>
<li>对于不可预知的Hot key，可以通过 Spark，对应流任务进行实时分析，及时发现新发布的热点 key。</li>
</ul>
<h4 id="Big-key"><a href="#Big-key" class="headerlink" title="Big key"></a>Big key</h4><p><strong>问题描述</strong>：大 key，是指在缓存访问时，部分 Key 的 Value 过大，读写、加载易超时的现象。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>压缩，阈值预警，当 value 的长度超过阀值，则对内容启用压缩。</li>
<li>大 key 拆分，尽量减少大 key 的存在。</li>
<li>尽量不淘汰：由于大 key 一旦穿透到 DB，加载耗时很大，所以可以对这些大 key 进行特殊照顾，比如设置较长的过期时间，比如缓存内部在淘汰 key 时，同等条件下，尽量不淘汰这些大 key。</li>
</ul>
<blockquote>
<p>笔记来源：陈波 老师的 《300分钟吃透分布式缓存》课程</p>
</blockquote>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BC%93%E5%AD%98/" rel="tag">缓存</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0/" rel="tag">面试复习</a></li></ul>


    </footer>

  </div>

  

  
  
  

  
  
  

</article>
    
  </article>
  

  
  <nav class="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020-2023
        <i class="ri-heart-fill heart_icon"></i> CharleyZZZZ
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/timg.jpg" alt="Hello World !"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E7%94%9F%E6%B4%BB/">生活</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/about">关于</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Subtitle -->

<script>
  try {
    var typed = new Typed("#subtitle", {
      strings: ['面朝大海，春暖花开', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
      startDelay: 0,
      typeSpeed: 200,
      loop: true,
      backSpeed: 100,
      showCursor: true
    });
  } catch (err) {
    console.log(err)
  }
</script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->


<script src="/js/clickLove.js"></script>


<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>



    
  </div>
</body>

</html>